<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Bigdata,">





  <link rel="alternate" href="/atom.xml" title="Just do it" type="application/atom+xml">






<meta name="description" content="Manage tool: Ambari+BigtopHDFS/YARN/MapReduce2/Tez/Hive/HBase/ZooKeeper/Spark/Zeppelin/Flink Flink-cdc/datax/seatunnel/dolphinscheduler">
<meta name="keywords" content="Bigdata">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop Ecosystem">
<meta property="og:url" content="http://blog.gcalls.cn/2023/08/hadoop-Ecosystem.html">
<meta property="og:site_name" content="Just do it">
<meta property="og:description" content="Manage tool: Ambari+BigtopHDFS/YARN/MapReduce2/Tez/Hive/HBase/ZooKeeper/Spark/Zeppelin/Flink Flink-cdc/datax/seatunnel/dolphinscheduler">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126170051565.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135203700.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135223713.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135244714.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135334426.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135423779.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135020759.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135601938.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135618321.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126135722313.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126170432588.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140249679.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140316800.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140615094.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140704271.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140727419.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126140814011.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126142114186.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126142047951.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126142210706.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126142018520.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240222165123099.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240222165153627.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240222165214472.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240222165256791.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20231229175659553.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20231229175620829.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20231229175739306.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20230914181613864.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20230914181838644.png">
<meta property="og:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20230915163923171.png">
<meta property="og:updated_time" content="2024-07-25T07:36:00.053Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hadoop Ecosystem">
<meta name="twitter:description" content="Manage tool: Ambari+BigtopHDFS/YARN/MapReduce2/Tez/Hive/HBase/ZooKeeper/Spark/Zeppelin/Flink Flink-cdc/datax/seatunnel/dolphinscheduler">
<meta name="twitter:image" content="http://blog.gcalls.cn/images/2023-08-25-hadoop-Ecosystem/image-20240126170051565.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.gcalls.cn/2023/08/hadoop-Ecosystem.html">





  <title>hadoop Ecosystem | Just do it</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0af0c9cfcd648be735ccf119d51ae564";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Just do it</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            站点地图
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.gcalls.cn/2023/08/hadoop-Ecosystem.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zhaoxunyong">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Just do it">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">hadoop Ecosystem</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-08-25T08:32:11+08:00">
                2023-08-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2023/08/hadoop-Ecosystem.html" class="leancloud_visitors" data-flag-title="hadoop Ecosystem">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Manage tool: Ambari+Bigtop<br>HDFS/YARN/MapReduce2/Tez/Hive/HBase/ZooKeeper/Spark/Zeppelin/Flink</p>
<p>Flink-cdc/datax/seatunnel/dolphinscheduler</p>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Recommend: <a href="https://github.com/heibaiying/BigData-Notes" target="_blank" rel="noopener">heibaiying/BigData-Notes: 大数据入门指南 :star: (github.com)</a></p>
<h2 id="Bigtop"><a href="#Bigtop" class="headerlink" title="Bigtop"></a>Bigtop</h2><p>Bigtop is an Apache Foundation project for Infrastructure Engineers and Data Scientists looking for comprehensive packaging, testing, and configuration of the leading open source big data components.** Bigtop supports a wide range of components/projects, including, but not limited to, Hadoop, HBase and Spark.</p>
<p>There are 2 ways to install bigtop:</p>
<h3 id="build-package-from-source"><a href="#build-package-from-source" class="headerlink" title="build package from source"></a>build package from source</h3><p>***Not recommend, it’s very complicate. especially in China mainland.</p>
<p>Prerequisite:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Jdk</span></span><br><span class="line">nvm install v12.22.1</span><br><span class="line"></span><br><span class="line">cat /etc/profile.d/java.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/Developer/jdk1.8.0_371</span><br><span class="line"><span class="built_in">export</span> M2_HOME=/Developer/apache-maven-3.6.3</span><br><span class="line"><span class="built_in">export</span> _JAVA_OPTIONS=<span class="string">"-Xms4g -Xmx4g -Djava.awt.headless=true"</span></span><br><span class="line"><span class="built_in">export</span> PATH=/root/.nvm/versions/node/v12.22.1/bin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$M2_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">. /etc/profile</span><br></pre></td></tr></table></figure>
<p>Building:</p>
<p><strong><em>Notice: Need a non-root to compile.</em></strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo su - hadoop</span><br><span class="line">wget https://dlcdn.apache.org/bigtop/bigtop-3.2.0/bigtop-3.2.0-project.tar.gz (use the suggested mirror from above)</span><br><span class="line">tar xfvz bigtop-3.2.0-project.tar.gz</span><br><span class="line">cd bigtop-3.2.0</span><br><span class="line">#only for rpm packages</span><br><span class="line">./gradlew bigtop-groovy-rpm bigtop-jsvc-rpm bigtop-select-rpm bigtop-utils-rpm \</span><br><span class="line">flink-rpm hadoop-rpm hbase-rpm hive-rpm kafka-rpm solr-rpm spark-rpm \</span><br><span class="line">tez-rpm zeppelin-rpm zookeeper-rpm -Dbuildwithdeps=true -PparentDir=/usr/bigtop -PpkgSuffix | tee -a log.txt</span><br><span class="line">#it&apos;ll clean all of packages located inbuild/, be careful!</span><br><span class="line">#./gradlew allclean</span><br></pre></td></tr></table></figure>
<p>Troubleshooting:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#lacking some of jars</span><br><span class="line">wget https://www.zhangjc.com/images/20210817/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar</span><br><span class="line">mvn install:install-file -Dfile=./pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar -DgroupId=org.pentaho -DartifactId=pentaho-aggdesigner-algorithm -Dversion=5.1.5-jhyde -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">wget https://packages.confluent.io/maven/io/confluent/kafka-schema-registry-client/6.2.2/kafka-schema-registry-client-6.2.2.jar</span><br><span class="line">mvn install:install-file -Dfile=./kafka-schema-registry-client-6.2.2.jar -DgroupId=io.confluent -DartifactId=kafka-schema-registry-client -Dversion=6.2.2 -Dpackaging=jar</span><br><span class="line">mvn install:install-file -Dfile=./kafka-clients-2.8.1.jar -DgroupId=org.apache.kafka -DartifactId=kafka-clients -Dversion=2.8.1 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">wget https://packages.confluent.io/maven/io/confluent/kafka-avro-serializer/6.2.2/kafka-avro-serializer-6.2.2.jar</span><br><span class="line">mvn install:install-file -Dfile=./kafka-avro-serializer-6.2.2.jar -DgroupId=io.confluent -DartifactId=kafka-avro-serializer -Dversion=6.2.2 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd dl/</span><br><span class="line">tar zxf flink-1.15.3.tar.gz</span><br><span class="line">rm -fr flink-1.15.3/flink-formats/flink-avro-confluent-registry/src/test/</span><br><span class="line">rm -fr flink-1.15.3/flink-end-to-end-tests/flink-end-to-end-tests-common-kafka/src/test</span><br><span class="line">rm -fr flink-1.15.3.tar.gz</span><br><span class="line">tar -zcf flink-1.15.3.tar.gz flink-1.15.3</span><br><span class="line">rm -fr flink-1.15.3</span><br><span class="line">rm -fr /Developer/bigtop-3.2.0/build/flink/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tar zxf hadoop-3.3.4.tar.gz</span><br><span class="line">vim hadoop-3.3.4-src/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/hadoop-yarn-applications-catalog-webapp/pom.xm</span><br><span class="line">&lt;nodejs.version&gt;v14.0.0&lt;/nodejs.version&gt;</span><br><span class="line">rm -fr hadoop-3.3.4.tar.gz &amp;&amp; tar -zcf hadoop-3.3.4.tar.gz hadoop-3.3.4-src &amp;&amp; rm -fr hadoop-3.3.4-src</span><br><span class="line">rm -fr /Developer/bigtop-3.2.0/build/hadoop/</span><br></pre></td></tr></table></figure>
<h3 id="bigtop-Repositories"><a href="#bigtop-Repositories" class="headerlink" title="bigtop Repositories"></a>bigtop Repositories</h3><p>It’s a easy way to install, including ambari packages:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Clone to local repository:</span></span><br><span class="line">wget https://dlcdn.apache.org/bigtop/bigtop-3.2.1/repos/centos-7/bigtop.repo -O /etc/yum.repos.d/bigtop.repo</span><br><span class="line">reposync --gpgcheck -1 --repoid=bigtop --download_path=/data/bigtop</span><br><span class="line"><span class="built_in">cd</span> /data/bigtop/bigtop</span><br><span class="line">yum install createrepo</span><br><span class="line">createrepo .</span><br><span class="line"></span><br><span class="line">tree ./</span><br><span class="line">.</span><br><span class="line">├── bigtop</span><br><span class="line">│   ├── alluxio</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       └── alluxio-2.8.0-2.el7.x86_64.rpm</span><br><span class="line">│   ├── ambari</span><br><span class="line">│   │   ├── noarch</span><br><span class="line">│   │   │   ├── ambari-agent-2.7.5.0-1.el7.noarch.rpm</span><br><span class="line">│   │   │   └── ambari-server-2.7.5.0-1.el7.noarch.rpm</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       ├── ambari-metrics-collector-2.7.5.0-0.x86_64.rpm</span><br><span class="line">│   │       ├── ambari-metrics-grafana-2.7.5.0-0.x86_64.rpm</span><br><span class="line">│   │       ├── ambari-metrics-hadoop-sink-2.7.5.0-0.x86_64.rpm</span><br><span class="line">│   │       └── ambari-metrics-monitor-2.7.5.0-0.x86_64.rpm</span><br><span class="line">│   ├── bigtop-ambari-mpack</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── bigtop-ambari-mpack-2.7.5.0-1.el7.noarch.rpm</span><br><span class="line">│   ├── bigtop-groovy</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── bigtop-groovy-2.5.4-1.el7.noarch.rpm</span><br><span class="line">│   ├── bigtop-jsvc</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       ├── bigtop-jsvc-1.2.4-1.el7.x86_64.rpm</span><br><span class="line">│   │       └── bigtop-jsvc-debuginfo-1.2.4-1.el7.x86_64.rpm</span><br><span class="line">│   ├── bigtop-utils</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── bigtop-utils-3.2.1-1.el7.noarch.rpm</span><br><span class="line">│   ├── flink</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── flink-1.15.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── flink-jobmanager-1.15.3-1.el7.noarch.rpm</span><br><span class="line">│   │       └── flink-taskmanager-1.15.3-1.el7.noarch.rpm</span><br><span class="line">│   ├── gpdb</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       └── gpdb-5.28.5-1.el7.x86_64.rpm</span><br><span class="line">│   ├── hadoop</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       ├── hadoop-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-client-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-conf-pseudo-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-debuginfo-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-doc-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-datanode-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-dfsrouter-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-fuse-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-journalnode-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-namenode-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-secondarynamenode-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-hdfs-zkfc-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-httpfs-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-kms-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-libhdfs-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-libhdfs-devel-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-libhdfspp-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-libhdfspp-devel-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-mapreduce-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-mapreduce-historyserver-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-yarn-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-yarn-nodemanager-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-yarn-proxyserver-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-yarn-resourcemanager-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hadoop-yarn-router-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   │       └── hadoop-yarn-timelineserver-3.3.5-1.el7.x86_64.rpm</span><br><span class="line">│   ├── hbase</span><br><span class="line">│   │   ├── noarch</span><br><span class="line">│   │   │   └── hbase-doc-2.4.13-2.el7.noarch.rpm</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       ├── hbase-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hbase-master-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hbase-regionserver-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hbase-rest-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   │       ├── hbase-thrift2-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   │       └── hbase-thrift-2.4.13-2.el7.x86_64.rpm</span><br><span class="line">│   ├── hive</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── hive-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-hbase-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-hcatalog-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-hcatalog-server-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-jdbc-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-metastore-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-server2-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── hive-webhcat-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   │       └── hive-webhcat-server-3.1.3-1.el7.noarch.rpm</span><br><span class="line">│   ├── kafka</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── kafka-2.8.1-2.el7.noarch.rpm</span><br><span class="line">│   │       └── kafka-server-2.8.1-2.el7.noarch.rpm</span><br><span class="line">│   ├── livy</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── livy-0.7.1-1.el7.noarch.rpm</span><br><span class="line">│   ├── oozie</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── oozie-5.2.1-2.el7.noarch.rpm</span><br><span class="line">│   │       └── oozie-client-5.2.1-2.el7.noarch.rpm</span><br><span class="line">│   ├── phoenix</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── phoenix-5.1.2-1.el7.noarch.rpm</span><br><span class="line">│   ├── solr</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── solr-8.11.2-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── solr-doc-8.11.2-1.el7.noarch.rpm</span><br><span class="line">│   │       └── solr-server-8.11.2-1.el7.noarch.rpm</span><br><span class="line">│   ├── spark</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       ├── spark-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-core-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-datanucleus-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-external-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-history-server-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-master-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-python-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-sparkr-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-thriftserver-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       ├── spark-worker-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   │       └── spark-yarn-shuffle-3.2.3-1.el7.noarch.rpm</span><br><span class="line">│   ├── tez</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── tez-0.10.1-1.el7.noarch.rpm</span><br><span class="line">│   ├── ycsb</span><br><span class="line">│   │   └── noarch</span><br><span class="line">│   │       └── ycsb-0.17.0-2.el7.noarch.rpm</span><br><span class="line">│   ├── zeppelin</span><br><span class="line">│   │   └── x86_64</span><br><span class="line">│   │       └── zeppelin-0.10.1-1.el7.x86_64.rpm</span><br><span class="line">│   └── zookeeper</span><br><span class="line">│       └── x86_64</span><br><span class="line">│           ├── zookeeper-3.5.9-2.el7.x86_64.rpm</span><br><span class="line">│           ├── zookeeper-debuginfo-3.5.9-2.el7.x86_64.rpm</span><br><span class="line">│           ├── zookeeper-native-3.5.9-2.el7.x86_64.rpm</span><br><span class="line">│           ├── zookeeper-rest-3.5.9-2.el7.x86_64.rpm</span><br><span class="line">│           └── zookeeper-server-3.5.9-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<h2 id="Ambari"><a href="#Ambari" class="headerlink" title="Ambari"></a>Ambari</h2><p>The Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.</p>
<p><strong><em>Notice: Bigtop repository has included all of ambari packages, you don’t need to build. just need to build the latest version that bigtop not included.</em></strong></p>
<p>For installation, please follow this instructions: <a href="https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.8.0" target="_blank" rel="noopener">Installation Guide for Ambari 2.8.0 - Apache Ambari - Apache Software Foundation</a></p>
<h3 id="Build-package-from-source"><a href="#Build-package-from-source" class="headerlink" title="Build  package from source"></a>Build  package from source</h3><p>Prerequisite:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Jdk</span></span><br><span class="line">nvm install v12.22.1</span><br><span class="line"></span><br><span class="line">cat /etc/profile.d/java.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/Developer/jdk1.8.0_371</span><br><span class="line"><span class="built_in">export</span> M2_HOME=/Developer/apache-maven-3.6.3</span><br><span class="line"><span class="built_in">export</span> _JAVA_OPTIONS=<span class="string">"-Xms4g -Xmx4g -Djava.awt.headless=true"</span></span><br><span class="line"><span class="built_in">export</span> PATH=/root/.nvm/versions/node/v12.22.1/bin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$M2_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">. /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment">#OS environment:</span></span><br><span class="line"><span class="comment">#swap&gt;=6G:</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=/myswap.swp bs=1k count=4194304 <span class="comment">#The vm has been included 2g memory. </span></span><br><span class="line">mkswap /myswap.swp</span><br><span class="line">swapon /myswap.swp</span><br><span class="line">free -m</span><br><span class="line">chmod +x /etc/rc.local</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"swapon /myswap.swp"</span> &gt;&gt; /etc/rc.local</span><br><span class="line"></span><br><span class="line">groupadd hadoop</span><br><span class="line">useradd -m -g hadoop hadoop</span><br><span class="line">passwd hadoop</span><br><span class="line">chmod +w /etc/sudoers</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hadoop ALL=(ALL)NOPASSWD: ALL"</span> &gt;&gt; /etc/sudoers</span><br><span class="line">chmod -w /etc/sudoers</span><br></pre></td></tr></table></figure>
<p>Build package from source</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.8.0</span><br><span class="line">Centos 7.9:</span><br><span class="line">yum install -y git python-devel rpm-build gcc-c++</span><br><span class="line"></span><br><span class="line">wget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea</span><br><span class="line">sh setuptools-0.6c11-py2.7.egg</span><br><span class="line"></span><br><span class="line">wget https://dlcdn.apache.org/ambari/ambari-2.8.0/apache-ambari-2.8.0-src.tar.gz (use the suggested mirror from above)</span><br><span class="line">tar xfvz apache-ambari-2.8.0-src.tar.gz</span><br><span class="line">cd apache-ambari-2.8.0-src</span><br><span class="line">mvn clean install rpm:rpm -DskipTests -Drat.skip=true</span><br></pre></td></tr></table></figure>
<p>Build your yum repository:</p>
<p>See: <a href="#Bigtop">bigtop Section</a></p>
<h3 id="Installing-Ambari"><a href="#Installing-Ambari" class="headerlink" title="Installing Ambari"></a>Installing Ambari</h3><p>Performence:</p>
<table>
<thead>
<tr>
<th>IP地址</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.80.225</td>
<td>NameNode     ResourceManager     HBase Master     MySQL     Zeppelin Server     Grafana     flume     ds-master ds-api   ds-alert     Ambari Server     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.226</td>
<td>SNameNode     HBase Master     JobHistory Server     Flink History Server     Spark History Server     Spark Thrift Server     Hive Metastore     HiveServer2     WebHCat Server     Datax-webui     flume     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.227</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     RegionServer     ds-worker     Datax worknode     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.228</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     RegionServer     ds-worker     Datax worknode     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.229</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     RegionServer     ds-worker     Datax worknode     Ambari Metrics Collectors     Ambari Agant</td>
</tr>
</tbody>
</table>
<p>HA:</p>
<table>
<thead>
<tr>
<th>IP地址</th>
<th>Role</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.80.225</td>
<td>NameNode     ResourceManager(Single)     JobHistory Server(Single)     HBase Master     Flink History Server     Spark History Server     Hive Metastore     HiveServer2     WebHCat Server(Single)     Zeppelin Server(Single)     MySQL(Single)     Grafana(Single)     flume     ds-master      ds-api      ds-alert     Ambari Metrics Collectors     Ambari Server     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.226</td>
<td>SNameNode     HBase Master     Flink History Server     Spark History Server     Hive Metastore     HiveServer2     ds-master     Ambari Metrics Collectors     flume     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.227</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     Kafka Broker     Spark Thrift Server     RegionServer     ds-worker     Datax worknode     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.228</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     Kafka Broker     Spark Thrift Server     RegionServer     ds-worker     Datax worknode     Ambari Agant</td>
</tr>
<tr>
<td>192.168.80.229</td>
<td>DataNode     NodeManager     Zookeeper     JournalNode     Kafka Broker     Spark Thrift Server     RegionServer     ds-worker     Datax worknode     Ambari Agant</td>
</tr>
</tbody>
</table>
<h4 id="Vagrant-Docker"><a href="#Vagrant-Docker" class="headerlink" title="Vagrant Docker"></a>Vagrant Docker</h4><h5 id="Dockerfile-centos"><a href="#Dockerfile-centos" class="headerlink" title="Dockerfile.centos"></a>Dockerfile.centos</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /works/tools/vagrant</span><br><span class="line"></span><br><span class="line">cat Dockerfile.centos </span><br><span class="line"><span class="comment">#version: 1.0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> WORK_SHELL /startup</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /works</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> script.sh docker-entrypoint.sh <span class="variable">$WORK_SHELL</span>/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x <span class="variable">$WORK_SHELL</span>/*.sh</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="variable">$WORK_SHELL</span>/script.sh</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/startup/docker-entrypoint.sh"</span>]</span></span><br><span class="line"><span class="comment">#CMD ["bash", "-c" ,"$WORK_SHELL/init.sh"]</span></span><br></pre></td></tr></table></figure>
<h5 id="docker-entrypoint-sh"><a href="#docker-entrypoint-sh" class="headerlink" title="docker-entrypoint.sh"></a>docker-entrypoint.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat docker-entrypoint.sh </span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># run the command given as arguments from CMD</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure>
<h5 id="script-sh"><a href="#script-sh" class="headerlink" title="script.sh"></a>script.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">cat script.sh </span><br><span class="line"><span class="comment">#!/bin/bash -x</span></span><br><span class="line"><span class="comment">#http://www.360doc.com/content/14/1125/19/7044580_428024359.shtml</span></span><br><span class="line"><span class="comment">#http://blog.csdn.net/54powerman/article/details/50684844</span></span><br><span class="line"><span class="comment">#http://c.biancheng.net/cpp/view/2739.html</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"scripting......"</span></span><br><span class="line"></span><br><span class="line">yum -y install net-tools iproute iproute-doc wget sudo</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s;SELINUX=.*;SELINUX=disabled;'</span> /etc/selinux/config</span><br><span class="line">setenforce 0</span><br><span class="line">getenforce</span><br><span class="line"></span><br><span class="line"><span class="comment">#LANG="en_US.UTF-8"</span></span><br><span class="line"><span class="comment">#sed -i 's;LANG=.*;LANG="zh_CN.UTF-8";' /etc/locale.conf</span></span><br><span class="line"></span><br><span class="line">cat /etc/NetworkManager/NetworkManager.conf|grep <span class="string">"dns=none"</span> &gt; /dev/null</span><br><span class="line"><span class="keyword">if</span> [[ $? != 0 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"dns=none"</span> &gt;&gt; /etc/NetworkManager/NetworkManager.conf</span><br><span class="line">    systemctl restart NetworkManager.service</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">disable</span> iptables</span><br><span class="line">systemctl stop iptables</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">systemctl stop firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment">#ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line">timedatectl <span class="built_in">set</span>-timezone Asia/Shanghai</span><br><span class="line"></span><br><span class="line"><span class="comment">#logined limit</span></span><br><span class="line">cat /etc/security/limits.conf|grep <span class="string">"^root"</span> &gt; /dev/null</span><br><span class="line"><span class="keyword">if</span> [[ $? != 0 ]]; <span class="keyword">then</span></span><br><span class="line">                cat &gt;&gt; /etc/security/limits.conf  &lt;&lt; EOF</span><br><span class="line">root            -    nofile             100000</span><br><span class="line">root            -    nproc              100000</span><br><span class="line">*               -    nofile             100000</span><br><span class="line">*               -    nproc              100000</span><br><span class="line">EOF</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#systemd service limit</span></span><br><span class="line">cat /etc/systemd/system.conf|egrep <span class="string">'^DefaultLimitNOFILE'</span> &gt; /dev/null</span><br><span class="line"><span class="keyword">if</span> [[ $? != 0 ]]; <span class="keyword">then</span></span><br><span class="line">                cat &gt;&gt; /etc/systemd/system.conf &lt;&lt; EOF</span><br><span class="line">DefaultLimitCORE=infinity</span><br><span class="line">DefaultLimitNOFILE=100000</span><br><span class="line">DefaultLimitNPROC=100000</span><br><span class="line">EOF</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment">#user service limit</span></span><br><span class="line">cat /etc/systemd/user.conf|egrep <span class="string">'^DefaultLimitNOFILE'</span> &gt; /dev/null</span><br><span class="line"><span class="keyword">if</span> [[ $? != 0 ]]; <span class="keyword">then</span></span><br><span class="line">                cat &gt;&gt; /etc/systemd/system.conf &lt;&lt; EOF</span><br><span class="line">DefaultLimitCORE=infinity</span><br><span class="line">DefaultLimitNOFILE=100000</span><br><span class="line">DefaultLimitNPROC=100000</span><br><span class="line">EOF</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">cat /etc/sysctl.conf|grep <span class="string">"net.ipv4.ip_local_port_range"</span> &gt; /dev/null</span><br><span class="line"><span class="keyword">if</span> [[ $? != 0 ]]; <span class="keyword">then</span></span><br><span class="line">cat &gt;&gt; /etc/sysctl.conf  &lt;&lt; EOF</span><br><span class="line">net.ipv4.tcp_fin_timeout = 30</span><br><span class="line">net.ipv4.tcp_keepalive_time = 300</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.ip_local_port_range = 1024 65535</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"><span class="comment">#k8s</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl -p</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">su - root -c <span class="string">"ulimit -a"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#echo "192.168.10.6   k8s-master</span></span><br><span class="line"><span class="comment">#192.168.10.7   k8s-node1</span></span><br><span class="line"><span class="comment">#192.168.10.8   k8s-node2" &gt;&gt; /etc/hosts</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#tee /etc/resolv.conf &lt;&lt; EOF</span></span><br><span class="line"><span class="comment">#search myk8s.com</span></span><br><span class="line"><span class="comment">#nameserver 114.114.114.114</span></span><br><span class="line"><span class="comment">#nameserver 8.8.8.8</span></span><br><span class="line"><span class="comment">#EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#yum -y install gcc kernel-devel</span></span><br><span class="line">mv -f /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"><span class="comment"># wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">wget -O /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line"></span><br><span class="line">yum -y install epel-release</span><br><span class="line"></span><br><span class="line">sudo mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backup</span><br><span class="line">sudo mv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo.backup</span><br><span class="line"></span><br><span class="line">cat &gt; /etc/yum.repos.d/epel.repo  &lt;&lt; EOF</span><br><span class="line">[epel]</span><br><span class="line">name=Extra Packages <span class="keyword">for</span> Enterprise Linux 7 - \<span class="variable">$basearch</span></span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\<span class="variable">$basearch</span></span><br><span class="line"><span class="comment">#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=\$basearch</span></span><br><span class="line">failovermethod=priority</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7</span><br><span class="line">[epel-debuginfo]</span><br><span class="line">name=Extra Packages <span class="keyword">for</span> Enterprise Linux 7 - \<span class="variable">$basearch</span> - Debug</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/\<span class="variable">$basearch</span>/debug</span><br><span class="line"><span class="comment">#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-7&amp;arch=\$basearch</span></span><br><span class="line">failovermethod=priority</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7</span><br><span class="line">gpgcheck=1</span><br><span class="line">[epel-source]</span><br><span class="line">name=Extra Packages <span class="keyword">for</span> Enterprise Linux 7 - \<span class="variable">$basearch</span> - Source</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/SRPMS</span><br><span class="line"><span class="comment">#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-7&amp;arch=\$basearch</span></span><br><span class="line">failovermethod=priority</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7</span><br><span class="line">gpgcheck=1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line"></span><br><span class="line"><span class="comment">#yum -y install createrepo rpm-sign rng-tools yum-utils </span></span><br><span class="line">yum -y install htop <span class="built_in">bind</span>-utils bridge-utils ntpdate setuptool iptables system-config-securitylevel-tui system-config-network-tui \</span><br><span class="line"> ntsysv net-tools lrzsz telnet lsof vim dos2unix unix2dos zip unzip \</span><br><span class="line"> lsof openssl openssh-server openssh-clients expect</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s;#PasswordAuthentication yes;PasswordAuthentication yes;g'</span> /etc/ssh/sshd_config</span><br><span class="line">sed -i <span class="string">'s;#PermitRootLogin yes;PermitRootLogin yes;g'</span> /etc/ssh/sshd_config</span><br><span class="line"><span class="comment">#systemctl enable sshd</span></span><br><span class="line"><span class="comment">#systemctl restart sshd</span></span><br></pre></td></tr></table></figure>
<h5 id="buildImages-sh"><a href="#buildImages-sh" class="headerlink" title="buildImages.sh"></a>buildImages.sh</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat buildImages.sh </span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">DOCKER_BUILDKIT=<span class="number">0</span> docker build -t <span class="string">"registry.zerofinance.net/library/centos:7"</span> . -f Dockerfile.centos</span><br></pre></td></tr></table></figure>
<h5 id="Push-image"><a href="#Push-image" class="headerlink" title="Push image"></a>Push image</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker login registry.zerofinance.net</span><br><span class="line">admin</span><br><span class="line">********</span><br><span class="line"></span><br><span class="line">docker push registry.zerofinance.net/library/centos:7</span><br></pre></td></tr></table></figure>
<h5 id="Vagrantfile"><a href="#Vagrantfile" class="headerlink" title="Vagrantfile"></a>Vagrantfile</h5><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">cat Vagrantfile</span><br><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># All Vagrant configuration is done below. The "2" in Vagrant.configure</span></span><br><span class="line"><span class="comment"># configures the configuration version (we support older styles for</span></span><br><span class="line"><span class="comment"># backwards compatibility). Please don't change it unless you know what</span></span><br><span class="line"><span class="comment"># you're doing.</span></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  config.vm.hostname = <span class="string">"namenode01-test.zerofinance.net"</span></span><br><span class="line">  config.vm.network <span class="string">"public_network"</span>, <span class="symbol">ip:</span> <span class="string">"192.168.80.225"</span>, <span class="symbol">netmask:</span> <span class="string">"255.255.255.0"</span>, <span class="symbol">gateway:</span> <span class="string">"192.168.80.254"</span>, <span class="symbol">bridge:</span> <span class="string">"em1"</span></span><br><span class="line">  config.vm.provider <span class="string">"docker"</span> <span class="keyword">do</span> <span class="params">|d|</span></span><br><span class="line">    d.image = <span class="string">"registry.zerofinance.net/library/centos:7"</span></span><br><span class="line">    d.create_args = [<span class="string">"--hostname=namenode01-test.zerofinance.net"</span>, <span class="string">"--cpus=12"</span>, <span class="string">"--cpu-shares=12000"</span>, <span class="string">"-m=30g"</span>, <span class="string">"--memory-reservation=1g"</span>, <span class="string">"-v"</span>, <span class="string">"/etc/hosts:/etc/hosts"</span>, <span class="string">"-v"</span>, <span class="string">"/data:/data"</span>, <span class="string">"-v"</span>, <span class="string">"/sys/fs/cgroup:/sys/fs/cgroup"</span>]</span><br><span class="line">    d.privileged = <span class="literal">true</span></span><br><span class="line">    d.cmd = [<span class="string">"/usr/sbin/init"</span>]</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  config.vm.provision <span class="string">"shell"</span>, <span class="symbol">run:</span> <span class="string">"always"</span>, <span class="symbol">inline:</span> &lt;&lt;-SHELL</span><br><span class="line">    <span class="comment">#yum -y install net-tools &gt; /dev/null</span></span><br><span class="line">    route del default gw <span class="number">172.17</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">    route add default gw <span class="number">192.168</span>.<span class="number">80.254</span></span><br><span class="line">    chmod +x /etc/rc.local</span><br><span class="line">    chmod +x /etc/rc.d/rc.local</span><br><span class="line">    echo <span class="string">"route del default gw 172.17.0.1</span></span><br><span class="line"><span class="string">    route add default gw 192.168.80.254"</span> &gt;&gt; <span class="regexp">/etc/rc</span>.local</span><br><span class="line">  SHELL</span><br><span class="line"></span><br><span class="line">  <span class="comment">#config.vm.provision "shell",</span></span><br><span class="line">  <span class="comment">#  run: "always",</span></span><br><span class="line">  <span class="comment">#  inline: "route del default gw 172.17.0.1"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#config.vm.provision "shell" do |s|</span></span><br><span class="line">  <span class="comment">#  s.path = "script.sh"</span></span><br><span class="line">  <span class="comment">#  #s.args = ["--bip=10.1.10.1/24"]</span></span><br><span class="line">  <span class="comment">#end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h5 id="Vagrant-start"><a href="#Vagrant-start" class="headerlink" title="Vagrant start"></a>Vagrant start</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">vagrant up</span><br><span class="line"><span class="comment">#When it's done, you need to change root passwd</span></span><br><span class="line"><span class="comment">#https://developer.hashicorp.com/vagrant/docs/providers/docker/commands</span></span><br><span class="line">vagrant docker-exec -it -- /bin/bash</span><br><span class="line"><span class="comment">#Change password:</span></span><br><span class="line">passwd</span><br><span class="line"></span><br><span class="line"><span class="comment">#If multiple nodes in Vagrantfile:</span></span><br><span class="line"><span class="comment">#node1 can be shown with command: vagrant status</span></span><br><span class="line"><span class="comment">#vagrant docker-exec node1 -it -- /bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Or using nature docker command </span></span><br><span class="line">docker <span class="built_in">exec</span> -it &lt;ContainerId&gt; /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment">#shutdown</span></span><br><span class="line">vagrant halt</span><br><span class="line"></span><br><span class="line"><span class="comment">#start</span></span><br><span class="line">vagrant up</span><br><span class="line"></span><br><span class="line"><span class="comment">#restart</span></span><br><span class="line">vagrant restart</span><br><span class="line"></span><br><span class="line"><span class="comment">#More usuage can be found: https://blog.gcalls.cn/2022/04/A-Guide-to-Vagrant.html</span></span><br></pre></td></tr></table></figure>
<h4 id="Initiation"><a href="#Initiation" class="headerlink" title="Initiation"></a>Initiation</h4><h5 id="SSH-Without-Password"><a href="#SSH-Without-Password" class="headerlink" title="SSH Without Password"></a>SSH Without Password</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Working all machines:</span></span><br><span class="line">groupadd hadoop</span><br><span class="line">useradd -m -g hadoop hadoop</span><br><span class="line">passwd hadoop</span><br><span class="line">chmod +w /etc/sudoers</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hadoop ALL=(ALL)NOPASSWD: ALL"</span> &gt;&gt; /etc/sudoers</span><br><span class="line">chmod -w /etc/sudoers</span><br><span class="line">mkdir -p ~/.ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Working on 192.168.80.225</span></span><br><span class="line">sudo su - hadoop</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="comment">#Writing to ~/.ssh/authorized_keys：</span></span><br><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@192.168.80.225</span><br><span class="line"><span class="comment">#cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></span><br><span class="line">sudo chmod 700 ~/.ssh</span><br><span class="line">sudo chmod 600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#All machine can ssh without password: </span></span><br><span class="line">scp ~/.ssh/* hadoop@192.168.80.84:~/.ssh/</span><br><span class="line">scp ~/.ssh/* hadoop@192.168.80.85:~/.ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Just need 80.225 can ssh without password:</span></span><br><span class="line"><span class="comment">#scp ~/.ssh/authorized_keys hadoop@192.168.80.226:~/.ssh/</span></span><br><span class="line"><span class="comment">#scp ~/.ssh/authorized_keys hadoop@192.168.80.227:~/.ssh/</span></span><br><span class="line"><span class="comment">#scp ~/.ssh/authorized_keys hadoop@192.168.80.228:~/.ssh/</span></span><br><span class="line"><span class="comment">#scp ~/.ssh/authorized_keys hadoop@192.168.80.229:~/.ssh/</span></span><br></pre></td></tr></table></figure>
<h5 id="Optional-Docker-CentOS"><a href="#Optional-Docker-CentOS" class="headerlink" title="Optional: Docker CentOS"></a>Optional: Docker CentOS</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#If your centos is installed on docker:</span></span><br><span class="line"><span class="comment">#For example: 192.168.80.225, vice versa:</span></span><br><span class="line">route del default gw 172.17.0.1</span><br><span class="line">route add default gw 192.168.80.254</span><br><span class="line">chmod +x /etc/rc.local</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"ifconfig eth0 down</span></span><br><span class="line"><span class="string">route del default gw 172.17.0.1</span></span><br><span class="line"><span class="string">route add default gw 192.168.80.254"</span> &gt;&gt; /etc/rc.local</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"192.168.80.225   localhost localhost.localdomain localhost4 localhost4.localdomain4</span></span><br><span class="line"><span class="string">#::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">192.168.80.225 namenode01-test.zerofinance.net namenode01-test</span></span><br><span class="line"><span class="string">192.168.80.226 namenode02-test.zerofinance.net namenode02-test</span></span><br><span class="line"><span class="string">192.168.80.227 datanode01-test.zerofinance.net datanode01-test</span></span><br><span class="line"><span class="string">192.168.80.228 datanode02-test.zerofinance.net datanode02-test</span></span><br><span class="line"><span class="string">192.168.80.229 datanode03-test.zerofinance.net datanode03-test"</span> &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>
<h5 id="NTP"><a href="#NTP" class="headerlink" title="NTP"></a>NTP</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://www.cnblogs.com/Sungeek/p/10197345.html</span></span><br><span class="line"><span class="comment">#Working on all:</span></span><br><span class="line">sudo yum -y install ntp</span><br><span class="line">sudo timedatectl <span class="built_in">set</span>-timezone Asia/Shanghai</span><br><span class="line"></span><br><span class="line">192.168.80.225：</span><br><span class="line">vim /etc/ntp.conf</span><br><span class="line">restrict 0.0.0.0 mask 0.0.0.0 nomodify notrap</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge  127.127.1.0 stratum 10</span><br><span class="line"></span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br><span class="line">server 0.cn.pool.ntp.org iburst</span><br><span class="line">server 1.cn.pool.ntp.org iburst</span><br><span class="line">server 2.cn.pool.ntp.org iburst</span><br><span class="line">server 3.cn.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line"><span class="comment">#start</span></span><br><span class="line">systemctl <span class="built_in">enable</span> ntpd</span><br><span class="line">systemctl start ntpd</span><br><span class="line"></span><br><span class="line"><span class="comment">#check</span></span><br><span class="line">ntpq -p</span><br><span class="line"></span><br><span class="line"><span class="comment">#NTP Client Config on：192.168.80.&#123;226,227,228,229&#125;</span></span><br><span class="line">vim /etc/ntp.conf</span><br><span class="line"></span><br><span class="line">restrict 192.168.80.225 nomodify notrap noquery</span><br><span class="line"></span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br><span class="line">server 192.168.80.225</span><br><span class="line"></span><br><span class="line"><span class="comment">#start</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl <span class="built_in">enable</span> ntpd</span><br><span class="line"></span><br><span class="line"><span class="comment">#check</span></span><br><span class="line">ntpdate -u 192.168.80.225</span><br><span class="line">sudo ntpstat</span><br></pre></td></tr></table></figure>
<h5 id="Environment-variables"><a href="#Environment-variables" class="headerlink" title="Environment variables"></a>Environment variables</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/profile.d/my_env.sh </span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/works/app/jdk/jdk1.8.0_371</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/bigtop/current/hadoop-client</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/bigtop/current/hadoop-client/etc/hadoop/</span><br><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/bigtop/current/spark-client</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/bigtop/current/hive-client</span><br><span class="line"><span class="built_in">export</span> FLINK_HOME=/usr/bigtop/current/flink-client</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/bigtop/current/zookeeper-client</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$FLINK_HOME</span>/bin:<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<h5 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h5><h6 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install on 80.225</span></span><br><span class="line"><span class="comment">#https://blog.csdn.net/weixin_43967842/article/details/124515431</span></span><br><span class="line"><span class="comment">#https://docs.cloudera.com/HDPDocuments/Ambari-latest/administering-ambari/content/amb_using_ambari_with_mysql_or_mariadb.html</span></span><br><span class="line">wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">yum -y install ./mysql57-community-release-el7-10.noarch.rpm</span><br><span class="line">vim /etc/yum.repos.d/mysql-community.repo</span><br><span class="line">[mysql57-community]</span><br><span class="line">...</span><br><span class="line">gpgcheck=0</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">yum -y install mysql-community-server</span><br><span class="line"></span><br><span class="line">vim /etc/my.cnf</span><br><span class="line">max_connections=2000</span><br><span class="line"></span><br><span class="line">character-set-server=utf8</span><br><span class="line">collation-server=utf8_general_ci</span><br><span class="line">lower_case_table_names=1</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br><span class="line">systemctl start mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment">#temporary password：</span></span><br><span class="line">grep <span class="string">'temporary password'</span> /var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line"></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="built_in">set</span> global validate_password_policy=0;</span><br><span class="line">alter user <span class="string">'root'</span>@<span class="string">'localhost'</span> identified by <span class="string">'Aa123456'</span>;</span><br><span class="line">CREATE USER <span class="string">'ambari'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'Aa123456'</span>;</span><br><span class="line">GRANT ALL PRIVILEGES ON ambari.* TO <span class="string">'ambari'</span>@<span class="string">'%'</span>;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<h6 id="Ambari-Server"><a href="#Ambari-Server" class="headerlink" title="Ambari Server"></a>Ambari Server</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#192.168.80.225 With Root:</span></span><br><span class="line"><span class="comment">#https://cloud.tencent.com/works/app/jdk/article/1375511</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /vagrant</span><br><span class="line">sudo yum install ./ambari-server-2.8.0.0-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#Troubleshooting</span></span><br><span class="line">/usr/sbin/ambari-server: line 34: buildNumber: unbound variable</span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s;$&#123;buildNumber&#125;;$&#123;VERSION&#125;;g'</span> /usr/sbin/ambari-server</span><br><span class="line">sed -i <span class="string">'s;$&#123;buildNumber&#125;;$&#123;VERSION&#125;;g'</span> /etc/rc.d/init.d/ambari-server</span><br><span class="line"></span><br><span class="line">ambari-server setup --jdbc-db=mysql --jdbc-driver=/vagrant/mysql-connector-j-8.0.31.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#Init MySQL</span></span><br><span class="line">&gt; mysql -u ambari -p</span><br><span class="line">CREATE DATABASE ambari;</span><br><span class="line">USE ambari;</span><br><span class="line">SOURCE /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql;</span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line">&gt; mysql -uroot -p</span><br><span class="line">CREATE DATABASE hive;</span><br><span class="line">CREATE USER <span class="string">'hive'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'Aa123456'</span>;</span><br><span class="line">GRANT ALL PRIVILEGES ON hive.* TO <span class="string">'hive'</span>@<span class="string">'%'</span>;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line">&gt; ambari-server setup</span><br><span class="line">Using python  /usr/bin/python</span><br><span class="line">Setup ambari-server</span><br><span class="line">Checking SELinux...</span><br><span class="line">WARNING: Could not run /usr/sbin/sestatus: OK</span><br><span class="line">Customize user account <span class="keyword">for</span> ambari-server daemon [y/n] (n)? y</span><br><span class="line">Enter user account <span class="keyword">for</span> ambari-server daemon (root):hadoop</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Checking firewall status...</span><br><span class="line">Checking JDK...</span><br><span class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</span><br><span class="line">[2] Custom JDK</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (1): 2</span><br><span class="line">WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.</span><br><span class="line">WARNING: JCE Policy files are required <span class="keyword">for</span> configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.</span><br><span class="line">Path to JAVA_HOME: /works/app/jdk/jdk1.8.0_371</span><br><span class="line">Validating JDK on Ambari Server...done.</span><br><span class="line">Check JDK version <span class="keyword">for</span> Ambari Server...</span><br><span class="line">JDK version found: 8</span><br><span class="line">Minimum JDK version is 8 <span class="keyword">for</span> Ambari. Skipping to setup different JDK <span class="keyword">for</span> Ambari Server.</span><br><span class="line">Checking GPL software agreement...</span><br><span class="line">GPL License <span class="keyword">for</span> LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html</span><br><span class="line">Enable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? y</span><br><span class="line">Completing setup...</span><br><span class="line">Configuring database...</span><br><span class="line">Enter advanced database configuration [y/n] (n)? y</span><br><span class="line">Configuring database...</span><br><span class="line">==============================================================================</span><br><span class="line">Choose one of the following options:</span><br><span class="line">[1] - PostgreSQL (Embedded)</span><br><span class="line">[2] - Oracle</span><br><span class="line">[3] - MySQL / MariaDB</span><br><span class="line">[4] - PostgreSQL</span><br><span class="line">[5] - Microsoft SQL Server (Tech Preview)</span><br><span class="line">[6] - SQL Anywhere</span><br><span class="line">[7] - BDB</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (1): 3</span><br><span class="line">Hostname (localhost): namenode01-test.zerofinance.net</span><br><span class="line">Port (3306): </span><br><span class="line">Database name (ambari): </span><br><span class="line">Username (ambari): </span><br><span class="line">Enter Database Password (bigdata): </span><br><span class="line">Re-enter password: </span><br><span class="line">Configuring ambari database...</span><br><span class="line">Enter full path to custom jdbc driver: /var/lib/ambari-server/resources/mysql-connector-java.jar</span><br><span class="line">Copying /var/lib/ambari-server/resources/mysql-connector-java.jar to /usr/share/java</span><br><span class="line">Configuring remote database connection properties...</span><br><span class="line">WARNING: Before starting Ambari Server, you must run the following DDL directly from the database shell to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql</span><br><span class="line">Proceed with configuring remote database connection properties [y/n] (y)? y</span><br><span class="line">Extracting system views...</span><br><span class="line">ambari-admin-2.8.0.0.0.jar</span><br><span class="line"></span><br><span class="line">Ambari repo file doesn<span class="string">'t contain latest json url, skipping repoinfos modification</span></span><br><span class="line"><span class="string">Adjusting ambari-server permissions and ownership...</span></span><br><span class="line"><span class="string">Ambari Server '</span>setup<span class="string">' completed successfully.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#Troubleshooting</span></span><br><span class="line"><span class="string">rm -fr /usr/share/java &amp;&amp; mkdir -p /usr/share/java</span></span><br><span class="line"><span class="string">cp -a /vagrant/mysql-connector-j-8.0.31.jar /usr/share/java/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#Start</span></span><br><span class="line"><span class="string">systemctl enable ambari-server</span></span><br><span class="line"><span class="string">systemctl start ambari-server</span></span><br></pre></td></tr></table></figure>
<h6 id="Ambari-Agent"><a href="#Ambari-Agent" class="headerlink" title="Ambari Agent"></a>Ambari Agent</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Install ambari angent on all machines:</span><br><span class="line">cd /vagrant/</span><br><span class="line">yum install ./ambari-agent-2.8.0.0-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line">sed -i &apos;s;$&#123;buildNumber&#125;;$&#123;VERSION&#125;;g&apos; /var/lib/ambari-agent/bin/ambari-agent</span><br><span class="line">systemctl enable ambari-agent.service</span><br><span class="line">systemctl start ambari-agent.service</span><br></pre></td></tr></table></figure>
<h6 id="bigtop-repo"><a href="#bigtop-repo" class="headerlink" title="bigtop repo"></a>bigtop repo</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#bigtop repo(192.168.80.225): </span><br><span class="line">cd /vagrant/bigdatarepo</span><br><span class="line">yum install createrepo</span><br><span class="line">createrepo .</span><br><span class="line">nohup python -m SimpleHTTPServer &amp;</span><br><span class="line">http://192.168.80.225:8000/</span><br></pre></td></tr></table></figure>
<h6 id="Install-Hadoop-Ecosystem"><a href="#Install-Hadoop-Ecosystem" class="headerlink" title="Install Hadoop Ecosystem"></a>Install Hadoop Ecosystem</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">web portal:</span><br><span class="line">http://192.168.80.225:8080/</span><br><span class="line">admin/admin</span><br><span class="line"></span><br><span class="line"><span class="comment">#input machine informations:</span></span><br><span class="line">namenode01-test.zerofinance.net</span><br><span class="line">namenode02-test.zerofinance.net</span><br><span class="line">datanode01-test.zerofinance.net</span><br><span class="line">datanode02-test.zerofinance.net</span><br><span class="line">datanode03-test.zerofinance.net</span><br><span class="line"></span><br><span class="line"><span class="comment">#Using .ssh-key to setup</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Notice:</span></span><br><span class="line">Cluster Name : dwh</span><br><span class="line"><span class="comment">#Chose the hdfs account as "hadoop" not "hdfs"</span></span><br><span class="line"></span><br><span class="line">Repositories:</span><br><span class="line">http://192.168.80.225:8000/</span><br></pre></td></tr></table></figure>
<h6 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">1.hive went wrong by:</span><br><span class="line">Sys DB and Information Schema not created yet</span><br><span class="line"></span><br><span class="line"><span class="comment">#Login on specific machine：</span></span><br><span class="line"><span class="built_in">cd</span> /etc/hive/</span><br><span class="line">touch /etc/hive/sys.db.created</span><br><span class="line"><span class="comment">#restart ambari-server</span></span><br><span class="line">sudo systemctl restart ambari-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Add new component, an error was caucse:</span></span><br><span class="line">ambari 500 status code received on POST method <span class="keyword">for</span> API:</span><br><span class="line"><span class="comment">#https://www.jianshu.com/p/3b54ba251c9e</span></span><br><span class="line">chown -R hadoop:hadoop /var/run/ambari-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Cannot create /var/run/ambari-server/stack-recommendations:</span></span><br><span class="line">chown -R hadoop:hadoop /var/run/ambari-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Web Portal：</span></span><br><span class="line">HDFS---&gt;CONFIGS: </span><br><span class="line">search <span class="keyword">for</span> hive, changed hadoop.proxyuser.hive.hosts to *</span><br><span class="line"></span><br><span class="line"><span class="comment">#mkdir: Permission denied: user=root, access=WRITE, inode="/":hdfs:hdfs:drwxr-xr-x</span></span><br><span class="line">https://blog.csdn.net/gdkyxy2013/article/details/105254907</span><br><span class="line"></span><br><span class="line"><span class="comment">#zeppelin cannot ran flink 1.15.3：</span></span><br><span class="line"><span class="built_in">cd</span> /usr/bigtop/current/flink-client/lib</span><br><span class="line">mv flink-dist-1.15.3.jar flink-dist_2.12-1.15.3.jar</span><br><span class="line"><span class="comment">#zeppelin does not support with flink 1.15.3, see: </span></span><br><span class="line"><span class="comment">#https://github.com/apache/zeppelin/blob/v0.10.1/flink/flink-shims/src/main/java/org/apache/zeppelin/flink/FlinkShims.java</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#zeppelin open job function:</span></span><br><span class="line">Ambari---&gt;Zeppelin---&gt;Custom zeppelin-site:</span><br><span class="line">zeppelin.jobmanager.enable: <span class="literal">true</span></span><br><span class="line"><span class="comment">#reboot zeppelin.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Get version error by command: flink -v</span></span><br><span class="line"><span class="comment">#Version: &lt;unknown&gt;, Commit ID: DeadD0d0</span></span><br><span class="line"><span class="comment">#Downloading flink-1.15.3-bin-scala_2.12.tgz from official web site, extract flink-dist-1.15.3.jar from lib, then:</span></span><br><span class="line">cp -a flink-dist-1.15.3.jar /usr/bigtop/current/flink-client/lib/flink-dist_2.12-1.15.3.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#Troubleshooting ambari metric</span></span><br><span class="line"><span class="comment">#https://cwiki.apache.org/confluence/display/AMBARI/Cleaning+up+Ambari+Metrics+System+Data</span></span><br><span class="line"><span class="comment">#https://www.jianshu.com/p/3fa7a23818a1</span></span><br><span class="line"><span class="comment">#https://xieshaohu.wordpress.com/2021/06/15/ambari-metrics%E5%90%AF%E5%8A%A8%E5%90%8E%E8%87%AA%E5%8A%A8%E5%81%9C%E6%AD%A2/</span></span><br><span class="line"></span><br><span class="line">CONFIG:</span><br><span class="line">hbase.tmp.dir---&gt;/var/lib/ambari-metrics-collector/hbase-tmp</span><br><span class="line"></span><br><span class="line">zkCli.sh</span><br><span class="line">deleteall /ams-hbase-unsecure /ambari-metrics-cluster</span><br><span class="line"></span><br><span class="line">sudo -u hadoop hadoop fs -mv /user/ams/hbase /user/ams/hbase.bak</span><br><span class="line">sudo -u hadoop hadoop fs -mkdir /user/ams/hbase</span><br><span class="line">rm -fr /var/lib/ambari-metrics-collector/*</span><br><span class="line">rm -fr  /vagrant/var/</span><br><span class="line"><span class="comment">#restart Ambari Metrics on web ui.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Ambari Metrics Grafana password creation failed. PUT request status: 401 Unauthorized</span></span><br><span class="line">ambari-metrics-monitor status</span><br><span class="line">ambari-metrics-collector status</span><br><span class="line">mv /var/lib/ambari-metrics-grafana/grafana.db /tmp/</span><br><span class="line">or:</span><br><span class="line"><span class="comment">#https://blog.csdn.net/qq_37865420/article/details/104040970</span></span><br><span class="line"><span class="comment">#https://cloud.tencent.com/developer/ask/sof/114883574</span></span><br><span class="line">sqlite3 /var/lib/ambari-metrics-grafana/grafana.db</span><br><span class="line"></span><br><span class="line">sqlite&gt; update user <span class="built_in">set</span> password = <span class="string">'59acf18b94d7eb0694c61e60ce44c110c7a683ac6a8f09580d626f90f4a242000746579358d77dd9e570e83fa24faa88a8a6'</span>, salt = <span class="string">'F3FAxVm33R'</span> <span class="built_in">where</span> login = <span class="string">'admin'</span>;</span><br><span class="line"></span><br><span class="line">sqlite&gt; .<span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<h2 id="dolphinscheduler"><a href="#dolphinscheduler" class="headerlink" title="dolphinscheduler"></a>dolphinscheduler</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://dolphinscheduler.apache.org/zh-cn/docs/3.1.8/guide/installation/pseudo-cluster</span></span><br><span class="line"><span class="comment">#Must install with hadoop account:</span></span><br><span class="line">sudo su - hadoop</span><br><span class="line"><span class="comment">#docker env: need to shutdown eth0 or cannot register the actual ip to zokeeper: </span></span><br><span class="line">ifconfig eth0 down</span><br><span class="line"></span><br><span class="line"><span class="comment">#https://blog.csdn.net/Keyuchen_01/article/details/128653687</span></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="built_in">set</span> global validate_password_policy=0;</span><br><span class="line">CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</span><br><span class="line">CREATE USER <span class="string">'ds'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'Aa123456'</span>;</span><br><span class="line">GRANT ALL PRIVILEGES ON dolphinscheduler.* TO <span class="string">'ds'</span>@<span class="string">'%'</span>;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line"><span class="comment">#mkdir lib</span></span><br><span class="line"><span class="comment">#cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/lib/</span></span><br><span class="line">cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/api-server/libs/</span><br><span class="line">cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/alert-server/libs/</span><br><span class="line">cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/master-server/libs/</span><br><span class="line">cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/worker-server/libs/</span><br><span class="line">cp mysql-connector-j-8.0.31.jar ./apache-dolphinscheduler-3.1.2-bin/tools/libs/</span><br><span class="line"></span><br><span class="line">vim bin/env/install_env.sh</span><br><span class="line">ips=<span class="variable">$&#123;ips:-"namenode01-test.zerofinance.net,namenode02-test.zerofinance.net,datanode01-test.zerofinance.net,datanode02-test.zerofinance.net,datanode03-test.zerofinance.net"&#125;</span></span><br><span class="line">masters=<span class="variable">$&#123;masters:-"namenode01-test.zerofinance.net,namenode02-test.zerofinance.net"&#125;</span></span><br><span class="line">workers=<span class="variable">$&#123;workers:-"datanode01-test.zerofinance.net:default,datanode02-test.zerofinance.net:default,datanode03-test.zerofinance.net:default"&#125;</span></span><br><span class="line">alertServer=<span class="variable">$&#123;alertServer:-"namenode01-test.zerofinance.net"&#125;</span></span><br><span class="line">apiServers=<span class="variable">$&#123;apiServers:-"namenode01-test.zerofinance.net"&#125;</span></span><br><span class="line">deployUser=<span class="variable">$&#123;deployUser:-"hadoop"&#125;</span></span><br><span class="line">installPath=<span class="variable">$&#123;installPath:-"/works/app/dolphinscheduler"&#125;</span></span><br><span class="line"></span><br><span class="line">vim bin/env/dolphinscheduler_env.sh</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME:-/works/app/jdk/jdk1.8.0_371&#125;</span></span><br><span class="line"><span class="built_in">export</span> DATABASE=<span class="variable">$&#123;DATABASE:-mysql&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_PROFILES_ACTIVE=<span class="variable">$&#123;DATABASE&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_URL=jdbc:mysql://192.168.80.225:3306/dolphinscheduler?useUnicode=<span class="literal">true</span>&amp;characterEncoding=UTF-8&amp;useSSL=<span class="literal">false</span></span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_USERNAME=ds</span><br><span class="line"><span class="built_in">export</span> SPRING_DATASOURCE_PASSWORD=Aa123456</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> REGISTRY_ZOOKEEPER_CONNECT_STRING=$&#123;REGISTRY_ZOOKEEPER_CONNECT_STRING:-datanode01-test.zerofinance.net:2181,datanode02-test.zerofinance.net:2181,datanode03-test.zerofinanc</span><br><span class="line">e.net:2181&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=<span class="variable">$&#123;HADOOP_HOME:-/usr/bigtop/current/hadoop-client&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_CONF_DIR:-/usr/bigtop/current/hadoop-client/etc/hadoop/&#125;</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME1=<span class="variable">$&#123;SPARK_HOME1:-/usr/bigtop/current/spark-client&#125;</span></span><br><span class="line"><span class="comment">#export SPARK_HOME2=$&#123;SPARK_HOME2:-/opt/soft/spark2&#125;</span></span><br><span class="line"><span class="built_in">export</span> PYTHON_HOME=<span class="variable">$&#123;PYTHON_HOME:-/usr&#125;</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=<span class="variable">$&#123;HIVE_HOME:-/usr/bigtop/current/hive-client&#125;</span></span><br><span class="line"><span class="built_in">export</span> FLINK_HOME=<span class="variable">$&#123;FLINK_HOME:-/usr/bigtop/current/flink-client&#125;</span></span><br><span class="line"><span class="built_in">export</span> DATAX_HOME=<span class="variable">$&#123;DATAX_HOME:-/opt/soft/datax&#125;</span></span><br><span class="line"><span class="built_in">export</span> SEATUNNEL_HOME=<span class="variable">$&#123;SEATUNNEL_HOME:-/opt/soft/seatunnel&#125;</span></span><br><span class="line"><span class="built_in">export</span> CHUNJUN_HOME=<span class="variable">$&#123;CHUNJUN_HOME:-/opt/soft/chunjun&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /vagrant/apache-dolphinscheduler-3.1.2-bin</span><br><span class="line">bash tools/bin/upgrade-schema.sh</span><br><span class="line">sh bin/install.sh</span><br><span class="line"></span><br><span class="line">Web Portal:</span><br><span class="line">http://namenode01-test.zerofinance.net:12345/dolphinscheduler/ui</span><br></pre></td></tr></table></figure>
<p>Summary</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Components:                  </span><br><span class="line">  HDFS/YARN/MapReduce2/Tez/Hive/Hbase/ZooKeeper/Spark/Zeppelin/Flink/Datax/Dolphinscheduler/Flume</span><br><span class="line">Compoments path:        </span><br><span class="line">  /usr/bigtop/current/&#123;hadoop-client,spark-client,hive-client,flink-client&#125;</span><br><span class="line">Vagrant root folder:      </span><br><span class="line">  /works/tools/vagrant</span><br><span class="line"></span><br><span class="line">Ambari UI:                       </span><br><span class="line">  http://namenode01-test.zerofinance.net:8080/                      </span><br><span class="line">  admin/admin</span><br><span class="line">Dolphinescheduler UI:   </span><br><span class="line">  http://namenode01-test.zerofinance.net:12345/dolphinscheduler/ui                 </span><br><span class="line">  admin/dolphinscheduler123</span><br><span class="line">Kafka Brokers:                </span><br><span class="line">  192.168.65.107:9092,192.168.65.108:9092,192.168.66.110:9092</span><br><span class="line">Kafka UI:                          </span><br><span class="line">  https://kafka-ui-test.zerofinance.net/     admin/admin</span><br></pre></td></tr></table></figure>
<p><strong><em>Notice: dolphinscheduler 3.1.2 seems having a bug by working with Flink-Stream, the error as follows. I have no idea to resolve it:</em></strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] 2023-09-22 09:47:30.455 +0000 - Task execute failed, due to meet an exception</span><br><span class="line">java.lang.RuntimeException: The jar for the task is required.</span><br><span class="line">	at org.apache.dolphinscheduler.plugin.task.api.AbstractYarnTask.getResourceNameOfMainJar(AbstractYarnTask.java:133)</span><br><span class="line">	at org.apache.dolphinscheduler.plugin.task.flink.FlinkStreamTask.setMainJarName(FlinkStreamTask.java:86)</span><br><span class="line">	at org.apache.dolphinscheduler.plugin.task.flink.FlinkStreamTask.init(FlinkStreamTask.java:61)</span><br><span class="line">	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecuteRunnable.beforeExecute(WorkerTaskExecuteRunnable.java:231)</span><br><span class="line">	at org.apache.dolphinscheduler.server.worker.runner.WorkerTaskExecuteRunnable.run(WorkerTaskExecuteRunnable.java:170)</span><br><span class="line">	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:131)</span><br><span class="line">	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:74)</span><br><span class="line">	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:82)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:750)</span><br><span class="line">[ERROR] 2023-09-22 09:47:30.456 +0000 - can not get appId, taskInstanceId:573</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><p>The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.</p>
<p>The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.</p>
<p>Introduction: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-HDFS.md" target="_blank" rel="noopener">BigData-Notes/notes/Hadoop-HDFS.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<p>Shell: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/HDFS常用Shell命令.md" target="_blank" rel="noopener">BigData-Notes/notes/HDFS常用Shell命令.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<p>​           <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html" target="_blank" rel="noopener">FileSystemShell</a></p>
<p>HDFS: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-HDFS.md" target="_blank" rel="noopener">BigData-Notes/notes/Hadoop-HDFS.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<p>MapReduce2: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-MapReduce.md" target="_blank" rel="noopener">BigData-Notes/notes/Hadoop-MapReduce.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<p>YARN: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-YARN.md" target="_blank" rel="noopener">BigData-Notes/notes/Hadoop-YARN.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<p>JavaAPI: <a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/HDFS-Java-API.md" target="_blank" rel="noopener">BigData-Notes/notes/HDFS-Java-API.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<h3 id="Windows-Client"><a href="#Windows-Client" class="headerlink" title="Windows Client"></a>Windows Client</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://gitcode.net/mirrors/cdarlint/winutils</span><br><span class="line">cp -a winutils/hadoop-3.3.5 /Developer/</span><br><span class="line"><span class="comment">#Set variable in environment:</span></span><br><span class="line"><span class="built_in">set</span> HADOOP_HOME=D:\Developer\hadoop-3.3.5</span><br><span class="line">Add PATH as: %HADOOP_HOME%\bin</span><br></pre></td></tr></table></figure>
<h3 id="Configuation"><a href="#Configuation" class="headerlink" title="Configuation"></a>Configuation</h3><p>Put core-site.xml and hdfs-site.xml to resources folder of your java project:</p>
<h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>  <span class="attr">xmlns:xi</span>=<span class="string">"http://www.w3.org/2001/XInclude"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">xmlns:xi</span>=<span class="string">"http://www.w3.org/2001/XInclude"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.internal.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode01-test.zerofinance.net:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode02-test.zerofinance.net:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.https-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode01-test.zerofinance.net:50470<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.https-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode02-test.zerofinance.net:50470<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode01-test.zerofinance.net:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>namenode02-test.zerofinance.net:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><p>The Apache Hive ™ is a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale and facilitates reading, writing, and managing petabytes of data residing in distributed storage using SQL.</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="noopener">GettingStarted</a></p>
<h3 id="internal-table"><a href="#internal-table" class="headerlink" title="internal table"></a>internal table</h3><p>If table has beed deleted, all data will be delete accordingly, including meta data and file data.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML</span><br><span class="line">#LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</span><br><span class="line">#filepath can be:</span><br><span class="line">#a relative path, such as project/data1</span><br><span class="line">#an absolute path, such as /user/hive/project/data1</span><br><span class="line">#a full URI with scheme and (optionally) an authority, such as hdfs://namenode:9000/user/hive/project/data1</span><br><span class="line">The keyword &apos;OVERWRITE&apos; signifies that existing data in the table is deleted. If the &apos;OVERWRITE&apos; keyword is omitted, data files are appended to existing data sets.</span><br><span class="line"></span><br><span class="line">#default as internal table: </span><br><span class="line">CREATE TABLE pokes (foo INT, bar STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos; &apos; STORED AS TEXTFILE;</span><br><span class="line"></span><br><span class="line">sudo -u hive hadoop fs -put -f /tmp/kv1.txt /user/hive/demo/</span><br><span class="line">LOAD DATA INPATH &apos;./demo/kv1.txt&apos; OVERWRITE INTO TABLE pokes;</span><br><span class="line">#When it&apos;s done, the file located in hdfs will be deleted.</span><br><span class="line">select * from pokes;</span><br></pre></td></tr></table></figure>
<h3 id="external-table"><a href="#external-table" class="headerlink" title="external table"></a>external table</h3><p>If table has beed deleted, just meta data will be deleted. once you create table again, the data will be restored, no need load again.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#sudo -u hdfs hadoop fs -chown -R hive:hive /works/test/</span><br><span class="line">#sudo -u hive hadoop fs -cp  /user/hive/demo/kv1.txt /works/test/</span><br><span class="line">sudo -u hive hadoop fs -put -f /tmp/kv1.txt /works/demo/</span><br><span class="line">create external table mytest ( id int, myfields string ) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos; &apos; STORED AS TEXTFILE location &apos;/works/test/&apos;;</span><br><span class="line">LOAD DATA INPATH &apos;/works/demo/kv1.txt&apos; OVERWRITE INTO TABLE mytest;</span><br><span class="line">describe formatted mytest;</span><br></pre></td></tr></table></figure>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos; &apos; STORED AS TEXTFILE;</span><br><span class="line">#sudo -u hive hadoop fs -put -f /tmp/kv1.txt /user/hive/demo/</span><br><span class="line">LOAD DATA INPATH &apos;./demo/kv1.txt&apos; OVERWRITE INTO TABLE invites PARTITION (ds=&apos;2008-08-15&apos;);</span><br><span class="line">select * from invites;</span><br><span class="line">SELECT a.foo FROM invites a WHERE a.ds=&apos;2008-08-15&apos;;</span><br></pre></td></tr></table></figure>
<h3 id="Insert-Directory"><a href="#Insert-Directory" class="headerlink" title="Insert Directory"></a>Insert Directory</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#selects all rows from partition ds=2008-08-15 of the invites table into an HDFS directory. The result data is in files (depending on the number of mappers) in that directory.</span><br><span class="line">NOTE: partition columns if any are selected by the use of *. They can also be specified in the projection clauses.</span><br><span class="line"></span><br><span class="line">INSERT OVERWRITE DIRECTORY &apos;/tmp/hdfs_out&apos; SELECT a.* FROM invites a WHERE a.ds=&apos;2008-08-15&apos;;</span><br><span class="line">#local dirctory located on the same node of hiveserver2.</span><br><span class="line">INSERT OVERWRITE LOCAL DIRECTORY &apos;/tmp/local_out&apos; SELECT a.* FROM pokes a;</span><br></pre></td></tr></table></figure>
<h3 id="Insert-Table"><a href="#Insert-Table" class="headerlink" title="Insert Table"></a>Insert Table</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE events (foo INT, bar STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos; &apos; STORED AS TEXTFILE;</span><br><span class="line">INSERT OVERWRITE TABLE events SELECT a.* FROM pokes a;</span><br><span class="line">FROM invites a INSERT OVERWRITE TABLE events SELECT a.bar, count(*) WHERE a.foo &gt; 0 GROUP BY a.bar;</span><br><span class="line">INSERT OVERWRITE TABLE events SELECT a.bar, count(*) FROM invites a WHERE a.foo &gt; 0 GROUP BY a.bar;</span><br></pre></td></tr></table></figure>
<h3 id="Date-Type"><a href="#Date-Type" class="headerlink" title="Date Type"></a>Date Type</h3><p><a href="https://hadoopdoc.com/hive/hive-data-type" target="_blank" rel="noopener">Hive 数据类型 | Hive 教程 (hadoopdoc.com)</a></p>
<p>A complex demo for data type.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> students(</span><br><span class="line"> <span class="keyword">name</span>     <span class="keyword">STRING</span>,   <span class="comment">-- 姓名</span></span><br><span class="line"> age       <span class="built_in">INT</span>,      <span class="comment">-- 年龄</span></span><br><span class="line"> subject   <span class="built_in">ARRAY</span>&lt;<span class="keyword">STRING</span>&gt;,   <span class="comment">--学科</span></span><br><span class="line"> score     <span class="keyword">MAP</span>&lt;<span class="keyword">STRING</span>,<span class="built_in">FLOAT</span>&gt;,  <span class="comment">--各个学科考试成绩</span></span><br><span class="line"> address   <span class="keyword">STRUCT</span>&lt;houseNumber:<span class="built_in">int</span>, street:<span class="keyword">STRING</span>, city:<span class="keyword">STRING</span>, province:<span class="keyword">STRING</span>&gt;  <span class="comment">--家庭居住地址</span></span><br><span class="line">) <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">"\t"</span> </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>
<h4 id="STRUCT"><a href="#STRUCT" class="headerlink" title="STRUCT"></a>STRUCT</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS person_1 (id int,info struct&lt;name:string,country:string&gt;)  </span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &apos;:&apos; </span><br><span class="line">STORED AS TEXTFILE;</span><br><span class="line"></span><br><span class="line">//创建一个文本文件test_struct.txt</span><br><span class="line">1,&apos;dd&apos;:&apos;jp&apos;</span><br><span class="line">2,&apos;ee&apos;:&apos;cn&apos;</span><br><span class="line">3,&apos;gg&apos;:&apos;jp&apos;</span><br><span class="line">4,&apos;ff&apos;:&apos;cn&apos;</span><br><span class="line">5,&apos;tt&apos;:&apos;jp&apos;</span><br><span class="line"></span><br><span class="line">sudo -u hive hadoop fs -put /works/test/test_struct.txt /user/hive/demo/</span><br><span class="line">LOAD DATA INPATH &apos;./demo/test_struct.txt&apos; OVERWRITE INTO TABLE person_1;</span><br><span class="line"></span><br><span class="line">select * from person_1;</span><br><span class="line">+--------------+-----------------------------------+</span><br><span class="line">| person_1.id  |           person_1.info           |</span><br><span class="line">+--------------+-----------------------------------+</span><br><span class="line">| 1            | &#123;&quot;name&quot;:&quot;&apos;dd&apos;&quot;,&quot;country&quot;:&quot;&apos;jp&apos;&quot;&#125;  |</span><br><span class="line">| 2            | &#123;&quot;name&quot;:&quot;&apos;ee&apos;&quot;,&quot;country&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">| 3            | &#123;&quot;name&quot;:&quot;&apos;gg&apos;&quot;,&quot;country&quot;:&quot;&apos;jp&apos;&quot;&#125;  |</span><br><span class="line">| 4            | &#123;&quot;name&quot;:&quot;&apos;ff&apos;&quot;,&quot;country&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">| 5            | &#123;&quot;name&quot;:&quot;&apos;tt&apos;&quot;,&quot;country&quot;:&quot;&apos;jp&apos;&quot;&#125;  |</span><br><span class="line">+--------------+------------------------</span><br><span class="line"></span><br><span class="line">select id,info.name,info.country from person_1 where info.name=&apos;\&apos;dd\&apos;&apos;;</span><br><span class="line">+-----+-------+----------+</span><br><span class="line">| id  | name  | country  |</span><br><span class="line">+-----+-------+----------+</span><br><span class="line">| 1   | &apos;dd&apos;  | &apos;jp&apos;     |</span><br><span class="line">+-----+-------+----------+</span><br><span class="line">1 row selected (0.316 seconds)</span><br></pre></td></tr></table></figure>
<h4 id="ARRAY"><a href="#ARRAY" class="headerlink" title="ARRAY"></a>ARRAY</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS array_1 (id int,name array&lt;STRING&gt;)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &apos;:&apos; </span><br><span class="line">STORED AS TEXTFILE;</span><br><span class="line">//导入数据</span><br><span class="line">sudo -u hive hadoop fs -put /works/test/test_struct.txt /user/hive/demo/test_array.txt</span><br><span class="line">LOAD DATA INPATH &apos;./demo/test_array.txt&apos; OVERWRITE INTO TABLE array_1;</span><br><span class="line">//查询数据</span><br><span class="line">hive&gt; select * from array_1;</span><br><span class="line">OK</span><br><span class="line">1   [&quot;dd&quot;,&quot;jp&quot;]</span><br><span class="line">2   [&quot;ee&quot;,&quot;cn&quot;]</span><br><span class="line">3   [&quot;gg&quot;,&quot;jp&quot;]</span><br><span class="line">4   [&quot;ff&quot;,&quot;cn&quot;]</span><br><span class="line">5   [&quot;tt&quot;,&quot;jp&quot;]</span><br><span class="line">Time taken: 0.041 seconds, Fetched: 5 row(s)</span><br><span class="line">hive&gt; select id,name[0],name[1] from array_1 where name[1]=&apos;\&apos;cn\&apos;&apos;;</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">| id  |  _c1  |  _c2  |</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">| 2   | &apos;ee&apos;  | &apos;cn&apos;  |</span><br><span class="line">| 4   | &apos;ff&apos;  | &apos;cn&apos;  |</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">2 rows selected (0.317 seconds)</span><br></pre></td></tr></table></figure>
<h4 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS map_1 (id int,name map&lt;STRING,STRING&gt;)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;|&apos; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &apos;,&apos; </span><br><span class="line">MAP KEYS TERMINATED BY &apos;:&apos;</span><br><span class="line">STORED AS TEXTFILE;</span><br><span class="line"></span><br><span class="line">cat test_map.txt    </span><br><span class="line">1|&apos;name&apos;:&apos;jp&apos;,&apos;country&apos;:&apos;cn&apos;</span><br><span class="line">2|&apos;name&apos;:&apos;jp&apos;,&apos;country&apos;:&apos;cn&apos;</span><br><span class="line"></span><br><span class="line">sudo -u hive hadoop fs -put /works/test/test_map.txt /user/hive/demo/test_map.txt</span><br><span class="line">//加载数据</span><br><span class="line">LOAD DATA INPATH &apos;./demo/test_map.txt&apos; OVERWRITE INTO TABLE map_1;</span><br><span class="line"></span><br><span class="line">//查询数据</span><br><span class="line">hive&gt; select * from map_1;</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| map_1.id  |              map_1.name               |</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| 1         | &#123;&quot;&apos;name&apos;&quot;:&quot;&apos;jp&apos;&quot;,&quot;&apos;country&apos;&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">| 2         | &#123;&quot;&apos;name&apos;&quot;:&quot;&apos;jp&apos;&quot;,&quot;&apos;country&apos;&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">+-----------+-----------------------------------</span><br><span class="line">hive&gt; select id,name[&quot;&apos;name&apos;&quot;],name[&quot;&apos;country&apos;&quot;] from map_1;</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">| id  |  _c1  |  _c2  |</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">| 1   | &apos;jp&apos;  | &apos;cn&apos;  |</span><br><span class="line">| 2   | &apos;jp&apos;  | &apos;cn&apos;  |</span><br><span class="line">+-----+-------+-------+</span><br><span class="line">hive&gt; select * from map_1 where name[&quot;&apos;country&apos;&quot;]=&apos;\&apos;cn\&apos;&apos;;</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| map_1.id  |              map_1.name               |</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| 1         | &#123;&quot;&apos;name&apos;&quot;:&quot;&apos;jp&apos;&quot;,&quot;&apos;country&apos;&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">| 2         | &#123;&quot;&apos;name&apos;&quot;:&quot;&apos;jp&apos;&quot;,&quot;&apos;country&apos;&quot;:&quot;&apos;cn&apos;&quot;&#125;  |</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">2 rows selected (0.287 seconds)</span><br><span class="line"></span><br><span class="line">hive&gt; insert into map_1(id,name)values(1, str_to_map(&quot;name:jp1,country:cn1&quot;)),(2, str_to_map(&quot;name:jp2,country:cn2&quot;));</span><br><span class="line">No rows affected (11.664 seconds)</span><br><span class="line">hive&gt; select * from map_1;</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| map_1.id  |              map_1.name               |</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">| 1         | &#123;&quot;name&quot;:&quot;jp1&quot;,&quot;country&quot;:&quot;cn1&quot;&#125;        |</span><br><span class="line">| 2         | &#123;&quot;name&quot;:&quot;jp2&quot;,&quot;country&quot;:&quot;cn2&quot;&#125;        |</span><br><span class="line">+-----------+---------------------------------------+</span><br><span class="line">4 rows selected (0.482 seconds)</span><br></pre></td></tr></table></figure>
<p>UINON</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">//创建DUAL表，插入一条记录，用于生成数据</span><br><span class="line">create table dual(d string);</span><br><span class="line">insert into dual values(&apos;X&apos;);</span><br><span class="line">//创建UNION表</span><br><span class="line">CREATE TABLE IF NOT EXISTS uniontype_1 </span><br><span class="line">(</span><br><span class="line">id int,</span><br><span class="line">info map&lt;STRING,array&lt;int&gt;&gt;</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &apos;-&apos;</span><br><span class="line">MAP KEYS TERMINATED BY &apos;:&apos;</span><br><span class="line">STORED AS TEXTFILE;</span><br><span class="line"></span><br><span class="line">//Insert</span><br><span class="line">insert overwrite table uniontype_1</span><br><span class="line">select 1 as id,map(&apos;english&apos;,array(99,21,33)) as info from dual</span><br><span class="line">union all</span><br><span class="line">select 2 as id,map(&apos;english&apos;,array(44,33,76)) as info from dual</span><br><span class="line">union all</span><br><span class="line">select 3 as id,map(&apos;english&apos;,array(76,88,66)) as info from dual;</span><br><span class="line"></span><br><span class="line">select * from uniontype_1;</span><br><span class="line">+-----------------+-------------------------+</span><br><span class="line">| uniontype_1.id  |    uniontype_1.info     |</span><br><span class="line">+-----------------+-------------------------+</span><br><span class="line">| 1               | &#123;&quot;english&quot;:[99,21,33]&#125;  |</span><br><span class="line">| 2               | &#123;&quot;english&quot;:[44,33,76]&#125;  |</span><br><span class="line">| 3               | &#123;&quot;english&quot;:[76,88,66]&#125;  |</span><br><span class="line">+-----------------+-------------------------+</span><br><span class="line">3 rows selected (0.432 seconds)</span><br><span class="line"></span><br><span class="line">select * from uniontype_1 where info[&apos;english&apos;][2]&gt;30;</span><br><span class="line">+-----------------+-------------------------+</span><br><span class="line">| uniontype_1.id  |    uniontype_1.info     |</span><br><span class="line">+-----------------+-------------------------+</span><br><span class="line">| 1               | &#123;&quot;english&quot;:[99,21,33]&#125;  |</span><br><span class="line">| 2               | &#123;&quot;english&quot;:[44,33,76]&#125;  |</span><br><span class="line">| 3               | &#123;&quot;english&quot;:[76,88,66]&#125;  |</span><br><span class="line">+-----------------+-------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="ES"><a href="#ES" class="headerlink" title="ES"></a>ES</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.zerofinance.net/library/elasticsearch:7.6.2</span><br><span class="line">docker pull registry.zerofinance.net/library/kibana:7.6.2</span><br><span class="line"></span><br><span class="line">mkdir -p /works/data/esdata-dev</span><br><span class="line">chmod -R 777 /works/data/esdata-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#https://www.cnblogs.com/baoshu/p/16128127.html</span></span><br><span class="line">docker network create es-network</span><br><span class="line"></span><br><span class="line">docker run -d --name elastic-dev  --restart always --<span class="built_in">log</span>-driver json-file --<span class="built_in">log</span>-opt max-size=200m --<span class="built_in">log</span>-opt max-file=3 --net es-network -p 9200:9200 -p 9300:9300 -v /works/data/esdata-dev:/usr/share/elasticsearch/data -e <span class="string">"discovery.type=single-node"</span> --<span class="built_in">ulimit</span> nofile=65535:65535 registry.zerofinance.net/library/elasticsearch:7.6.2</span><br><span class="line"></span><br><span class="line">curl http://192.168.63.102:9200/_cat</span><br><span class="line"></span><br><span class="line">docker run -d --name kibana-dev --net es-network -p 5601:5601 -e <span class="string">"ELASTICSEARCH_HOSTS=http://192.168.63.102:9200"</span>  registry.zerofinance.net/library/kibana:7.6.2</span><br><span class="line"></span><br><span class="line">http://192.168.63.102:5601/app/kibana<span class="comment">#/dev_tools/console</span></span><br></pre></td></tr></table></figure>
<h2 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h2><p><a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Flink核心概念综述.md" target="_blank" rel="noopener">BigData-Notes/notes/Flink核心概念综述.md at master · heibaiying/BigData-Notes (github.com)</a></p>
<h3 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h3><p><a href="https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_大数据/01_数据仓库/01_实时数仓/02_数据内容建设/03_one-engine/01_计算引擎/01_flink/01_flink-sql/20_史上最全干货！FlinkSQL成神之路（全文6万字、110个知识点、160张图）/" target="_blank" rel="noopener">史上最全干货！Flink SQL 成神之路（全文 18 万字、138 个案例、42 张图） | antigeneral’s blog (yangyichao-mango.github.io)</a></p>
<h3 id="Deployment-Modes"><a href="#Deployment-Modes" class="headerlink" title="Deployment Modes"></a>Deployment Modes</h3><p>See this Overview to understand: <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/overview/#deployment-modes" target="_blank" rel="noopener">deployment-modes</a></p>
<h4 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h4><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/overview/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/standalone/overview/</a></p>
<h5 id="Session-Mode"><a href="#Session-Mode" class="headerlink" title="Session Mode"></a>Session Mode</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># we assume to be in the root directory of the unzipped Flink distribution</span><br><span class="line"></span><br><span class="line"># (1) Start Cluster</span><br><span class="line">$ ./bin/start-cluster.sh</span><br><span class="line"></span><br><span class="line"># (2) You can now access the Flink Web Interface on http://localhost:8081</span><br><span class="line"></span><br><span class="line"># (3) Submit example job</span><br><span class="line">$ ./bin/flink run ./examples/streaming/TopSpeedWindowing.jar</span><br><span class="line"></span><br><span class="line"># (4) Stop the cluster again</span><br><span class="line">$ ./bin/stop-cluster.sh</span><br></pre></td></tr></table></figure>
<p>In step <code>(1)</code>, we’ve started 2 processes: A JVM for the JobManager, and a JVM for the TaskManager. The JobManager is serving the web interface accessible at <a href="http://localhost:8081/" target="_blank" rel="noopener">localhost:8081</a>. In step <code>(3)</code>, we are starting a Flink Client (a short-lived JVM process) that submits an application to the JobManager.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#Troubleshooting: 8081 can be visited only for localhost</span><br><span class="line">cat /etc/hosts</span><br><span class="line">192.168.80.225   localhost</span><br></pre></td></tr></table></figure>
<h5 id="Application-Mode"><a href="#Application-Mode" class="headerlink" title="Application Mode"></a>Application Mode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">To start a Flink JobManager with an embedded application, we use the bin/standalone-job.sh script. We demonstrate this mode by locally starting the TopSpeedWindowing.jar example, running on a single TaskManager.</span><br><span class="line"></span><br><span class="line">The application jar file needs to be available <span class="keyword">in</span> the classpath. The easiest approach to achieve that is putting the jar into the lib/ folder:</span><br><span class="line"></span><br><span class="line">$ cp ./examples/streaming/TopSpeedWindowing.jar lib/</span><br><span class="line">Then, we can launch the JobManager:</span><br><span class="line"></span><br><span class="line">$ ./bin/standalone-job.sh start --job-classname org.apache.flink.streaming.examples.windowing.TopSpeedWindowing</span><br><span class="line">The web interface is now available at localhost:8081. However, the application won’t be able to start, because there are no TaskManagers running yet:</span><br><span class="line"></span><br><span class="line">$ ./bin/taskmanager.sh start</span><br><span class="line">Note: You can start multiple TaskManagers, <span class="keyword">if</span> your application needs more resources.</span><br><span class="line"></span><br><span class="line">Stopping the services is also supported via the scripts. Call them multiple <span class="built_in">times</span> <span class="keyword">if</span> you want to stop multiple instances, or use stop-all:</span><br><span class="line"></span><br><span class="line">$ ./bin/taskmanager.sh stop</span><br><span class="line">$ ./bin/standalone-job.sh stop</span><br></pre></td></tr></table></figure>
<h4 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h4><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/</a></p>
<h5 id="Session-Mode-1"><a href="#Session-Mode-1" class="headerlink" title="Session Mode"></a>Session Mode</h5><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/#starting-a-flink-session-on-yarn" target="_blank" rel="noopener">starting-a-flink-session-on-yarn</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"><span class="comment"># we assume to be in the root directory of </span></span><br><span class="line"><span class="comment"># the unzipped Flink distribution</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (0) export HADOOP_CLASSPATH</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"></span><br><span class="line"><span class="comment"># (1) Start YARN Session</span></span><br><span class="line">./bin/yarn-session.sh --detached</span><br><span class="line"></span><br><span class="line"><span class="comment"># (2) You can now access the Flink Web Interface through the</span></span><br><span class="line"><span class="comment"># URL printed in the last lines of the command output, or through</span></span><br><span class="line"><span class="comment"># the YARN ResourceManager web UI.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (3) Submit example job</span></span><br><span class="line">./bin/flink run ./examples/streaming/TopSpeedWindowing.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># (4) Stop YARN session (replace the application id based </span></span><br><span class="line"><span class="comment"># on the output of the yarn-session.sh command)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"stop"</span> | ./bin/yarn-session.sh -id application_XXXXX_XXX</span><br></pre></td></tr></table></figure>
<p>Congratulations! You have successfully run a Flink application by deploying Flink on YARN.</p>
<p>We describe deployment with the Session Mode in the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/#getting-started" target="_blank" rel="noopener">Getting Started</a> guide at the top of the page.</p>
<p>The Session Mode has two operation modes:</p>
<ul>
<li><strong>attached mode</strong> (default): The <code>yarn-session.sh</code> client submits the Flink cluster to YARN, but the client keeps running, tracking the state of the cluster. If the cluster fails, the client will show the error. If the client gets terminated, it will signal the cluster to shut down as well.</li>
<li><strong>detached mode</strong> (<code>-d</code> or <code>--detached</code>): The <code>yarn-session.sh</code> client submits the Flink cluster to YARN, then the client returns. Another invocation of the client, or YARN tools is needed to stop the Flink cluster.</li>
</ul>
<p>The session mode will create a hidden YARN properties file in <code>/tmp/.yarn-properties-&lt;username&gt;</code>, which will be picked up for cluster discovery by the command line interface when submitting a job.</p>
<p>You can also <strong>manually specify the target YARN cluster</strong> in the command line interface when submitting a Flink job. Here’s an example:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -t yarn-session \</span><br><span class="line">  -Dyarn.application.id=application_XXXX_YY \</span><br><span class="line">  ./examples/streaming/TopSpeedWindowing.jar</span><br></pre></td></tr></table></figure>
<p>You can <strong>re-attach to a YARN session</strong> using the following command:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/yarn-session.sh -id application_XXXX_YY</span><br></pre></td></tr></table></figure>
<p>Besides passing <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/config/" target="_blank" rel="noopener">configuration</a> via the <code>conf/flink-conf.yaml</code> file, you can also pass any configuration at submission time to the <code>./bin/yarn-session.sh</code> client using <code>-Dkey=value</code> arguments.</p>
<p>The YARN session client also has a few “shortcut arguments” for commonly used settings. They can be listed with <code>./bin/yarn-session.sh -h</code>.</p>
<h5 id="Application-Mode-1"><a href="#Application-Mode-1" class="headerlink" title="Application Mode"></a>Application Mode</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Application Mode will launch a Flink cluster on YARN, <span class="built_in">where</span> the main() method of the application jar gets executed on the JobManager <span class="keyword">in</span> YARN. The cluster will shut down as soon as the application has finished. You can manually stop the cluster using yarn application -<span class="built_in">kill</span> &lt;ApplicationId&gt; or by cancelling the Flink job.</span><br><span class="line"></span><br><span class="line">./bin/flink run-application -t yarn-application ./examples/streaming/TopSpeedWindowing.jar</span><br><span class="line"></span><br><span class="line">Once an Application Mode cluster is deployed, you can interact with it <span class="keyword">for</span> operations like cancelling or taking a savepoint.</span><br><span class="line"></span><br><span class="line"><span class="comment"># List running job on the cluster</span></span><br><span class="line">./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cancel running job</span></span><br><span class="line">./bin/flink cancel -t yarn-application -Dyarn.application.id=application_XXXX_YY &lt;jobId&gt;</span><br><span class="line"></span><br><span class="line">Note that cancelling your job on an Application Cluster will stop the cluster.</span><br><span class="line"></span><br><span class="line">To unlock the full potential of the application mode, consider using it with the yarn.provided.lib.dirs configuration option and pre-upload your application jar to a location accessible by all nodes <span class="keyword">in</span> your cluster. In this <span class="keyword">case</span>, the <span class="built_in">command</span> could look like:</span><br><span class="line"></span><br><span class="line">./bin/flink run-application -t yarn-application \</span><br><span class="line">	-Dyarn.provided.lib.dirs=<span class="string">"hdfs://myhdfs/my-remote-flink-dist-dir"</span> \</span><br><span class="line">	hdfs://myhdfs/jars/my-application.jar</span><br><span class="line">	</span><br><span class="line">The above will allow the job submission to be extra lightweight as the needed Flink jars and the application jar are going to be picked up by the specified remote locations rather than be shipped to the cluster by the client.</span><br></pre></td></tr></table></figure>
<h4 id="Native-kubernetes"><a href="#Native-kubernetes" class="headerlink" title="Native_kubernetes"></a>Native_kubernetes</h4><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/filesystems/oss/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/filesystems/oss/</a></p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/native_kubernetes/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/native_kubernetes/</a></p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/overview/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/overview/</a></p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/kubernetes_ha/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/kubernetes_ha/</a></p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/config/#kubernetes" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/config/#kubernetes</a></p>
<h5 id="K8s-On-Session"><a href="#K8s-On-Session" class="headerlink" title="K8s On Session"></a>K8s On Session</h5><p>Creating service account:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#https://blog.csdn.net/yy8623977/article/details/124989262</span><br><span class="line"></span><br><span class="line">#创建namespace、service账号和给账号授权</span><br><span class="line">kubectl create ns flink-test</span><br><span class="line">kubectl create serviceaccount flink-test -n flink-test</span><br><span class="line">kubectl create clusterrolebinding flink-role-bind --clusterrole=edit --serviceaccount=flink-test:flink-test</span><br><span class="line"></span><br><span class="line">#Resolved: configmaps is forbidden: User &quot;system:serviceaccount:flink-test:default&quot;</span><br><span class="line">#https://blog.csdn.net/wangmiaoyan/article/details/103254006</span><br><span class="line">kubectl create clusterrolebinding flink-test:flink-test --clusterrole=cluster-admin --user=system:serviceaccount:flink-test:default</span><br></pre></td></tr></table></figure>
<p>Building required jars into docker image(Or mount a folder from NAS).</p>
<p>Dockerfile:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">FROM apache/flink:1.17.2-scala_2.12</span><br><span class="line"></span><br><span class="line">USER root</span><br><span class="line"># Pod的时区默认是UTC，时间会比我们的少八小时。修改时区为Asia/Shanghai</span><br><span class="line">#RUN rm -f /etc/localtime &amp;&amp; ln -sv /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone</span><br><span class="line">RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"></span><br><span class="line">#解决不能写日志到dev下的问题</span><br><span class="line">RUN groupmod -g 1001 flink</span><br><span class="line">RUN usermod -u 1001 flink</span><br><span class="line">RUN chown -R 1001:1001 $FLINK_HOME/</span><br><span class="line"></span><br><span class="line">USER flink</span><br><span class="line">RUN mkdir -p $FLINK_HOME/usrlib</span><br><span class="line"></span><br><span class="line"># Copying libs</span><br><span class="line">COPY ./lib-1.17/* $FLINK_HOME/lib/</span><br></pre></td></tr></table></figure>
<p>ll ./lib-1.17/</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-rw-r--r--  1 root  root    266420 Jun 15  2023 flink-connector-jdbc-3.1.1-1.17.jar</span><br><span class="line">-rw-r--r--  1 root  root  25743957 Nov 10 16:32 flink-oss-fs-hadoop-1.17.2.jar</span><br><span class="line">-rw-r--r--  1 root  root  28440546 Apr 13  2023 flink-sql-connector-elasticsearch7-3.0.1-1.17.jar</span><br><span class="line">-rw-r--r--  1 root  root   5566107 Oct 26 04:26 flink-sql-connector-kafka-3.0.1-1.17.jar</span><br><span class="line">-rw-r--r--  1 root  root  23715175 Jan 19 12:07 flink-sql-connector-mysql-cdc-3.0.1.jar</span><br><span class="line">-rw-r--r--  1 root  root   2515447 Jan 18 15:01 mysql-connector-j-8.0.31.jar</span><br></pre></td></tr></table></figure>
<p>Build and push to registry:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t registry.zerofinance.net/library/flink:1.17.2 .</span><br><span class="line">docker push registry.zerofinance.net/library/flink:1.17.2</span><br></pre></td></tr></table></figure>
<p>Starting flink job manager:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#For 1.15.x 1.16.x</span></span><br><span class="line">bin/kubernetes-session.sh \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink-test \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-cluster \</span><br><span class="line"> -Dakka.ask.timeout=100s \</span><br><span class="line"> -Dfs.oss.endpoint=https://oss-cn-hongkong.aliyuncs.com \</span><br><span class="line"> -Dfs.oss.accessKeyId=xxx \</span><br><span class="line"> -Dfs.oss.accessKeySecret=yyy \</span><br><span class="line"> -Dkubernetes.container.image=registry.zerofinance.net/library/flink:1.17.2 \</span><br><span class="line"> -Dkubernetes.container.image.pull-policy=Always \</span><br><span class="line"> -Dhigh-availability=org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory \</span><br><span class="line"> -Dhigh-availability.storageDir=oss://flink-ha-test/recovery \</span><br><span class="line"> -Dstate.backend=rocksdb \</span><br><span class="line"> -Dstate.backend.incremental=<span class="literal">true</span> \</span><br><span class="line"> -Dstate.checkpoints.dir=oss://flink-ha-test/flink-checkpoints \</span><br><span class="line"> -Dstate.savepoints.dir=oss://flink-ha-test/flink-savepoints \</span><br><span class="line"> -Dkubernetes.container.image.pull-secrets=zzz \</span><br><span class="line"> -Dkubernetes.jobmanager.replicas=2 \</span><br><span class="line"> -Dkubernetes.jobmanager.cpu=0.2 \</span><br><span class="line"> -Djobmanager.memory.process.size=1024m \</span><br><span class="line"> -Dresourcemanager.taskmanager-timeout=3600000 \</span><br><span class="line"> -Dkubernetes.taskmanager.node-selector=flink-env:<span class="built_in">test</span> \</span><br><span class="line"> -Dkubernetes.taskmanager.tolerations=flink-env:<span class="built_in">test</span>,operator:Exists,effect:NoSchedule \</span><br><span class="line"> -Dkubernetes.taskmanager.cpu=0.2 \</span><br><span class="line"> -Dtaskmanager.memory.process.size=4096m \</span><br><span class="line"> -Denv.java.opts.jobmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Denv.java.opts.taskmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dtaskmanager.numberOfTaskSlots=4</span><br><span class="line"></span><br><span class="line"><span class="comment">#For 1.17.x</span></span><br><span class="line">bin/kubernetes-session.sh \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink-test \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-test \</span><br><span class="line">-Dkubernetes.rest-service.exposed.type=NodePort \</span><br><span class="line"> -Dakka.ask.timeout=100s \</span><br><span class="line"> -Dfs.oss.endpoint=https://oss-cn-hongkong.aliyuncs.com \</span><br><span class="line"> -Dfs.oss.accessKeyId=xxx \</span><br><span class="line"> -Dfs.oss.accessKeySecret=yyy \</span><br><span class="line"> -Dkubernetes.container.image.ref=registry.zerofinance.net/library/flink:1.17.2 \</span><br><span class="line"> -Dkubernetes.container.image.pull-policy=Always \</span><br><span class="line"> -Dhigh-availability.type=kubernetes \</span><br><span class="line"> -Dhigh-availability.storageDir=oss://flink-cluster-test/recovery \</span><br><span class="line"> -Dstate.backend=rocksdb \</span><br><span class="line"> -Dstate.backend.incremental=<span class="literal">true</span> \</span><br><span class="line"> -Dstate.checkpoints.dir=oss://flink-cluster-test/flink-checkpoints \</span><br><span class="line"> -Dstate.savepoints.dir=oss://flink-cluster-test/flink-savepoints \</span><br><span class="line"> -Dkubernetes.container.image.pull-secrets=zzz \</span><br><span class="line"> -Dkubernetes.jobmanager.replicas=2 \</span><br><span class="line"> -Dkubernetes.jobmanager.cpu.amount=0.2 \</span><br><span class="line"> -Djobmanager.memory.process.size=1024m \</span><br><span class="line"> -Dresourcemanager.taskmanager-timeout=3600000 \</span><br><span class="line"> -Dkubernetes.taskmanager.node-selector=flink-env:<span class="built_in">test</span> \</span><br><span class="line"> -Dkubernetes.taskmanager.tolerations=flink-env:<span class="built_in">test</span>,operator:Exists,effect:NoSchedule \</span><br><span class="line"> -Dkubernetes.taskmanager.cpu.amount=0.2 \</span><br><span class="line"> -Dtaskmanager.memory.process.size=1024m \</span><br><span class="line"> -Denv.java.opts.jobmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Denv.java.opts.taskmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dtaskmanager.numberOfTaskSlots=2</span><br></pre></td></tr></table></figure>
<p>Enable cluster-rest ingress:</p>
<p>flink-cluster-rest-ingress.yml:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flink-cluster-rest-ingress</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">flink-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span> <span class="string">[]</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">flink-rest-test.zerofinance.net</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">flink-cluster-rest</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">8081</span></span><br></pre></td></tr></table></figure>
<p>Submits a new job:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -m flink-rest-test.zerofinance.net examples/batch/WordCount.jar</span><br></pre></td></tr></table></figure>
<p>Or:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run \</span><br><span class="line"> -e kubernetes-session \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.rest-service.exposed.type=NodePort \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-cluster \</span><br><span class="line"> examples/batch/WordCount.jar</span><br></pre></td></tr></table></figure>
<p>Destroy a existing cluster:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n flink-test delete deploy flink-cluster</span><br></pre></td></tr></table></figure>
<h5 id="K8s-On-Application"><a href="#K8s-On-Application" class="headerlink" title="K8s On Application"></a>K8s On Application</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Starting:</span></span><br><span class="line"><span class="comment">#For 1.15.x 1.16.x</span></span><br><span class="line">bin/flink run-application \</span><br><span class="line"> --target kubernetes-application \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink \</span><br><span class="line"> -Dkubernetes.rest-service.exposed.type=NodePort \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-application-cluster \</span><br><span class="line"> -Dkubernetes.container.image=registry.zerofinance.net/library/flink:1.17.2 \</span><br><span class="line"> -Dkubernetes.container.image.pull-policy=Always \</span><br><span class="line"> -Dfs.oss.endpoint=https://oss-cn-hongkong.aliyuncs.com \</span><br><span class="line"> -Dfs.oss.accessKeyId=xxx \</span><br><span class="line"> -Dfs.oss.accessKeySecret=yyy \</span><br><span class="line"> -Dhigh-availability=org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory \</span><br><span class="line"> -Dhigh-availability.storageDir=oss://flink-ha-test/native-recovery \</span><br><span class="line"> -Dstate.backend=rocksdb \</span><br><span class="line"> -Dstate.backend.incremental=<span class="literal">true</span> \</span><br><span class="line"> -Dstate.checkpoints.dir=oss://flink-ha-test/flink-application-checkpoints \</span><br><span class="line"> -Dstate.savepoints.dir=oss://flink-ha-test/flink-application-savepoints \</span><br><span class="line"> -Dkubernetes.container.image.pull-secrets=zzz \</span><br><span class="line"> -Dkubernetes.jobmanager.replicas=1 \</span><br><span class="line"> -Denv.java.opts.jobmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dkubernetes.jobmanager.cpu=0.2 \</span><br><span class="line"> -Djobmanager.memory.process.size=1024m \</span><br><span class="line"> -Dresourcemanager.taskmanager-timeout=3600000 \</span><br><span class="line"> -Denv.java.opts.taskmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dkubernetes.taskmanager.node-selector=flink-env:<span class="built_in">test</span> \</span><br><span class="line"> -Dkubernetes.taskmanager.cpu=0.2 \</span><br><span class="line"> -Dtaskmanager.memory.process.size=4096m \</span><br><span class="line"> -Dtaskmanager.numberOfTaskSlots=4 \</span><br><span class="line"> <span class="built_in">local</span>:///opt/flink/examples/streaming/TopSpeedWindowing.jar \</span><br><span class="line"> --output /opt/flink/<span class="built_in">log</span>/topSpeedWindowing-output</span><br><span class="line"></span><br><span class="line"><span class="comment">#For 1.17.x</span></span><br><span class="line">bin/flink run-application \</span><br><span class="line"> --target kubernetes-application \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink \</span><br><span class="line"> -Dkubernetes.rest-service.exposed.type=NodePort \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-application-cluster \</span><br><span class="line"> -Dkubernetes.container.image.ref=registry.zerofinance.net/library/flink:1.17.2 \</span><br><span class="line"> -Dkubernetes.container.image.pull-policy=Always \</span><br><span class="line"> -Dfs.oss.endpoint=https://oss-cn-hongkong.aliyuncs.com \</span><br><span class="line"> -Dfs.oss.accessKeyId=xxx \</span><br><span class="line"> -Dfs.oss.accessKeySecret=yyy \</span><br><span class="line"> -Dhigh-availability.type=kubernetes \</span><br><span class="line"> -Dhigh-availability.storageDir=oss://flink-ha-test/native-recovery \</span><br><span class="line"> -Dstate.backend=rocksdb \</span><br><span class="line"> -Dstate.backend.incremental=<span class="literal">true</span> \</span><br><span class="line"> -Dstate.checkpoints.dir=oss://flink-ha-test/flink-application-checkpoints \</span><br><span class="line"> -Dstate.savepoints.dir=oss://flink-ha-test/flink-application-savepoints \</span><br><span class="line"> -Dkubernetes.container.image.pull-secrets=zzz \</span><br><span class="line"> -Dkubernetes.jobmanager.replicas=1 \</span><br><span class="line"> -Denv.java.opts.jobmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dkubernetes.jobmanager.cpu.amount=0.2 \</span><br><span class="line"> -Djobmanager.memory.process.size=1024m \</span><br><span class="line"> -Dresourcemanager.taskmanager-timeout=3600000 \</span><br><span class="line"> -Denv.java.opts.taskmanager=-Duser.timezone=GMT+08 \</span><br><span class="line"> -Dkubernetes.taskmanager.node-selector=flink-env:<span class="built_in">test</span> \</span><br><span class="line"> -Dkubernetes.taskmanager.cpu.amount=0.2 \</span><br><span class="line"> -Dtaskmanager.memory.process.size=4096m \</span><br><span class="line"> -Dtaskmanager.numberOfTaskSlots=4 \</span><br><span class="line"> <span class="built_in">local</span>:///opt/flink/examples/streaming/TopSpeedWindowing.jar \</span><br><span class="line"> --output /opt/flink/<span class="built_in">log</span>/topSpeedWindowing-output</span><br><span class="line"> </span><br><span class="line"><span class="comment">#list running jobs:</span></span><br><span class="line">bin/flink list \</span><br><span class="line"> --target kubernetes-application \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-application-cluster</span><br><span class="line"></span><br><span class="line"><span class="comment">#Delete job:</span></span><br><span class="line">bin/flink cancel \</span><br><span class="line"> --target kubernetes-application \</span><br><span class="line"> -Dkubernetes.namespace=flink-test \</span><br><span class="line"> -Dkubernetes.jobmanager.service-account=flink \</span><br><span class="line"> -Dkubernetes.cluster-id=flink-application-cluster \</span><br><span class="line"> 5d7a3c36c7d40ceeb8b83fd8a563ded5</span><br></pre></td></tr></table></figure>
<h4 id="Sql-Client"><a href="#Sql-Client" class="headerlink" title="Sql Client"></a>Sql Client</h4><p><a href="https://www.jianshu.com/p/266449b9a0f4" target="_blank" rel="noopener">Flink 使用之 SQL Client - 简书 (jianshu.com)</a></p>
<h5 id="Standalone-1"><a href="#Standalone-1" class="headerlink" title="Standalone"></a>Standalone</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">start-cluster.sh</span><br><span class="line"></span><br><span class="line">sql-client.sh embedded</span><br><span class="line"></span><br><span class="line">#https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sqlclient/</span><br><span class="line">#Submit sql via sql-client.sh</span><br><span class="line">./flink-1.17.2/bin/sql-client.sh -f ./test.sql</span><br></pre></td></tr></table></figure>
<h5 id="On-yarn-Session"><a href="#On-yarn-Session" class="headerlink" title="On yarn Session"></a>On yarn Session</h5><p><a href="https://blog.csdn.net/lsr40/article/details/113398830" target="_blank" rel="noopener">SQL-Client On Yarn Session</a></p>
<p><a href="https://docs.cloudera.com/csa/1.2.0/sql-client/topics/csa-sql-client-session-config.html" target="_blank" rel="noopener">Configuring SQL Client for session mode | CDP Private Cloud (cloudera.com)</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Start a yarn session</span></span><br><span class="line"><span class="comment">#提交yarn session和启动sql client需要使用同一个系统用户，否则会找不到yarn session对应的application id。</span></span><br><span class="line">sudo su - hadoop</span><br><span class="line"><span class="comment">#yarn-session.sh -d</span></span><br><span class="line">yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">cat /works/demo.csv </span><br><span class="line">1,a,11</span><br><span class="line">2,b,22</span><br><span class="line">3,c,33</span><br><span class="line">4,d,44</span><br><span class="line"></span><br><span class="line">sudo -u hdfs hadoop fs -put /works/demo.csv /works/test/demo.csv</span><br><span class="line"></span><br><span class="line">sql-client.sh embedded -s yarn-session</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在专门的界面展示，使用分页table格式。可按照界面下方说明，使用快捷键前后翻页和退出到SQL命令行</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">sql</span>-client.execution.result-<span class="keyword">mode</span> = <span class="keyword">table</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># changelog格式展示，可展示数据增(I)删(D)改(U)</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">sql</span>-client.execution.result-<span class="keyword">mode</span> = changelog;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接近传统数据库的展示方式，不使用专门界面</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">sql</span>-client.execution.result-<span class="keyword">mode</span> = tableau;</span><br><span class="line"></span><br><span class="line">Flink SQL&gt; CREATE TABLE MyTable(</span><br><span class="line">  a INT,</span><br><span class="line">  b STRING,</span><br><span class="line">  c STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'filesystem'</span>,</span><br><span class="line">  <span class="string">'path'</span> = <span class="string">'hdfs:///works/test/demo.csv'</span>,</span><br><span class="line">  <span class="string">'format'</span> = <span class="string">'csv'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">Flink SQL&gt; select * from MyTable;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Kill an existing yarn-session</span></span><br><span class="line">yarn application -list</span><br><span class="line">echo "<span class="keyword">stop</span><span class="string">" | yarn-session.sh -id &lt;application_id&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#kafka Connector:</span></span><br><span class="line"><span class="string">wget https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-kafka/1.15.3/flink-sql-connector-kafka-1.15.3.jar</span></span><br><span class="line"><span class="string">wget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/1.15.3/flink-connector-jdbc-1.15.3.jar</span></span><br><span class="line"><span class="string">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.226:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.227:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.228:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.229:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Hive Connector:</span></span><br><span class="line"><span class="string">wget https://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar</span></span><br><span class="line"><span class="string">wget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-hive_2.12/1.15.3/flink-connector-hive_2.12-1.15.3.jar</span></span><br><span class="line"><span class="string">wget https://repo1.maven.org/maven2/org/apache/hive/hive-exec/2.3.4/hive-exec-2.3.4.jar</span></span><br><span class="line"><span class="string">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.226:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.227:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.228:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.229:/usr/bigtop/current/flink-client/lib/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.226:/usr/bigtop/current/flink-client/conf/</span></span><br><span class="line"><span class="string">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.227:/usr/bigtop/current/flink-client/conf/</span></span><br><span class="line"><span class="string">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.228:/usr/bigtop/current/flink-client/conf/</span></span><br><span class="line"><span class="string">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.229:/usr/bigtop/current/flink-client/conf/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#java.lang.ClassNotFoundException: org.apache.flink.connector.jdbc.table.JdbcRowDataInputFormat</span></span><br><span class="line"><span class="string">#Has to reboot flink-cluster</span></span><br><span class="line"><span class="string">stop-cluster.sh</span></span><br><span class="line"><span class="string">start-cluster.sh</span></span><br></pre></td></tr></table></figure>
<h5 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h5><p>Flink doesn’t include  any connector depended libraries, you need to download them manually.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kafka Connector:</span></span><br><span class="line">wget https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-kafka/1.15.3/flink-sql-connector-kafka-1.15.3.jar</span><br><span class="line">wget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/1.15.3/flink-connector-jdbc-1.15.3.jar</span><br><span class="line">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.226:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.227:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.228:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-sql-connector-kafka-1.15.3.jar flink-connector-jdbc-1.15.3.jar mysql-connector-j-8.0.31.jar root@192.168.80.229:/usr/bigtop/current/flink-client/lib/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Hive Connector:</span></span><br><span class="line">wget https://repo1.maven.org/maven2/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar</span><br><span class="line">wget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-hive_2.12/1.15.3/flink-connector-hive_2.12-1.15.3.jar</span><br><span class="line">wget https://repo1.maven.org/maven2/org/apache/hive/hive-exec/2.3.4/hive-exec-2.3.4.jar</span><br><span class="line">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.226:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.227:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.228:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp antlr-runtime-3.5.2.jar flink-connector-hive_2.12-1.15.3.jar hive-exec-2.3.4.jar root@192.168.80.229:/usr/bigtop/current/flink-client/lib/</span><br><span class="line"></span><br><span class="line"><span class="comment">#For hdfs Connector:</span></span><br><span class="line">wget https://repo1.maven.org/maven2/org/apache/flink/flink-table-planner_2.12/1.15.3/flink-table-planner_2.12-1.15.3.jar</span><br><span class="line">scp flink-table-planner_2.12-1.15.3.jar root@192.168.80.226:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-table-planner_2.12-1.15.3.jar root@192.168.80.227:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-table-planner_2.12-1.15.3.jar root@192.168.80.228:/usr/bigtop/current/flink-client/lib/</span><br><span class="line">scp flink-table-planner_2.12-1.15.3.jar root@192.168.80.229:/usr/bigtop/current/flink-client/lib/</span><br><span class="line"></span><br><span class="line"><span class="comment">#delete flink-table-planner-loader-1.15.3.jar from each machines:</span></span><br><span class="line">rm flink-table-planner-loader-1.15.3.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Need to reboot flink cluster or flink on yarn.</span></span><br><span class="line"><span class="comment">#Kill an existing yarn-session</span></span><br><span class="line">yarn application -list</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"stop"</span> | yarn-session.sh -id &lt;application_id&gt;</span><br><span class="line">yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Copying them to all libs of machine:</span></span><br><span class="line">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.226:/usr/bigtop/current/flink-client/conf/</span><br><span class="line">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.227:/usr/bigtop/current/flink-client/conf/</span><br><span class="line">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.228:/usr/bigtop/current/flink-client/conf/</span><br><span class="line">scp /usr/bigtop/current/flink-client/conf/flink-conf.yaml root@192.168.80.229:/usr/bigtop/current/flink-client/conf/</span><br></pre></td></tr></table></figure>
<h5 id="Restore-job"><a href="#Restore-job" class="headerlink" title="Restore job"></a>Restore job</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://mp.weixin.qq.com/s/srUyvNr7KX1PSOaG1d8qdQ?poc_token=HGNqmWWjWqONGGyPVzyzKzDhIsyauXyJ8kOW8Bfl</span></span><br><span class="line"><span class="comment">#https://mp.weixin.qq.com/s/o8mL0UkH4j_h5mjyayn0XQ</span></span><br><span class="line"></span><br><span class="line">vim flink/conf/flink-conf.yaml</span><br><span class="line">state.savepoints.dir: file:///works/app/flink/flink-1.15.3/flink-savepoints</span><br><span class="line"><span class="comment">#Restart cluster</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Starting from the latest savepoints when restart the job:</span></span><br><span class="line">curl -X</span><br><span class="line">POST http://jobmanager-host:port/<span class="built_in">jobs</span>/jobId/savepoints</span><br><span class="line">curl -X PATCH  http://jobmanager-host:port/<span class="built_in">jobs</span>/jobId</span><br><span class="line"></span><br><span class="line">Dinky:</span><br><span class="line">经验证Dinky平台支持Savepoint机制。任务重启后仅消费最新的数据。</span><br><span class="line">前置条件：修改Flink家目录下 flink/conf/flink-conf.yaml 文件，指定savepoint目录位置</span><br><span class="line">操作步骤：</span><br><span class="line">        任务配置</span><br><span class="line">                开启右边 SavePoint 策略，选择 “最近一次”</span><br><span class="line">                </span><br><span class="line">        SavePoint 停止 FlinkSQL 作业</span><br><span class="line">                点击 Dinky 的运维中心菜单，在任务列表里点击上面运行的这个任务进入任务详情页面，在页面右上角点击三个点的省略号按钮，弹出框中点击 “SavePoint停止”</span><br><span class="line"></span><br><span class="line">        重启作业</span><br><span class="line">                在 Dinky 的运维中心，任务列表，任务详情页面，重启任务</span><br></pre></td></tr></table></figure>
<h5 id="Optimize"><a href="#Optimize" class="headerlink" title="Optimize"></a>Optimize</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">SET parallelism.default=1;</span><br><span class="line">SET execution.runtime-mode = streaming;</span><br><span class="line">SET table.local-time-zone =Asia/Shanghai;</span><br><span class="line"> -- 10分钟</span><br><span class="line">SET execution.checkpointing.interval = 10m;</span><br><span class="line"> -- 失败容忍度</span><br><span class="line">SET execution.checkpointing.tolerable-failed-checkpoints = 50;</span><br><span class="line"> -- 超时时间</span><br><span class="line">SET execution.checkpointing.timeout =10000;</span><br><span class="line"> -- 一次语义</span><br><span class="line">SET execution.checkpointing.mode = EXACTLY_ONCE;</span><br><span class="line"> -- 固定频次</span><br><span class="line">SET restart-strategy= fixed-delay;</span><br><span class="line"> -- 尝试5次</span><br><span class="line">SET restart-strategy.fixed-delay.attempts = 5;</span><br><span class="line"> -- 重启延时50s</span><br><span class="line">SET restart-strategy.fixed-delay.delay = 50s;</span><br><span class="line"></span><br><span class="line">-- 调优参数</span><br><span class="line">SET table.exec.mini-batch.enabled = true</span><br><span class="line">SET table.exec.mini-batch.allow-latency = 2s</span><br><span class="line">SET table.exec.mini-batch.size = 5000</span><br><span class="line">SET table.optimizer.distinct-agg.split.enabled = true</span><br></pre></td></tr></table></figure>
<h3 id="StreamPark"><a href="#StreamPark" class="headerlink" title="StreamPark"></a>StreamPark</h3><p>Recommend.</p>
<p><a href="https://streampark.apache.org/" target="_blank" rel="noopener">Apache StreamPark (incubating) | Apache StreamPark (incubating)</a></p>
<h4 id="Installation-1"><a href="#Installation-1" class="headerlink" title="Installation"></a>Installation</h4><h5 id="Standalone-2"><a href="#Standalone-2" class="headerlink" title="Standalone"></a>Standalone</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://streampark.apache.org/docs/user-guide/deployment</span></span><br><span class="line">tar zxvf apache-streampark_2.12-2.1.2-incubating-bin.tar.gz </span><br><span class="line">mv apache-streampark_2.12-2.1.2-incubating-bin apache-streampark_2.12</span><br><span class="line"><span class="built_in">cd</span> apache-streampark_2.12/</span><br><span class="line"><span class="built_in">cd</span> apache-streampark_2.12/script/schema/</span><br><span class="line"></span><br><span class="line">mysql -uroot -h127.0.0.1 -p</span><br><span class="line">CREATE USER <span class="string">'streampark'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'Aa123456'</span>;</span><br><span class="line">GRANT ALL PRIVILEGES ON streampark.* TO <span class="string">'streampark'</span>@<span class="string">'%'</span>;</span><br><span class="line"><span class="built_in">exit</span>;</span><br><span class="line"></span><br><span class="line">mysql -uroot -h127.0.0.1 -p &lt; mysql-schema.sql </span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> apache-streampark_2.12/script/data/</span><br><span class="line">mysql -uroot -h127.0.0.1 -p &lt; mysql-data.sql </span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> apache-streampark_2.12/conf/</span><br><span class="line"></span><br><span class="line">vim application.yml </span><br><span class="line">spring:</span><br><span class="line">  profiles.active: mysql</span><br><span class="line">  </span><br><span class="line">vim application-mysql.yml</span><br><span class="line">spring:</span><br><span class="line">  datasource:</span><br><span class="line">    username: root</span><br><span class="line">    password: xxxx</span><br><span class="line">    driver-class-name: com.mysql.cj.jdbc.Driver</span><br><span class="line">    url: jdbc:mysql://localhost:3306/streampark?useSSL=<span class="literal">false</span>&amp;useUnicode=<span class="literal">true</span>&amp;characterEncoding=UTF-8&amp;allowPublicKeyRetrieval=<span class="literal">false</span>&amp;useJDBCCompliantTimezoneShift=<span class="literal">true</span>&amp;useLegacyDatetimeCode=<span class="literal">false</span>&amp;serverTimezone=GMT%2B8</span><br><span class="line">mysql -uroot -h127.0.0.1 -p </span><br><span class="line"></span><br><span class="line">streampark:</span><br><span class="line">  <span class="comment"># HADOOP_USER_NAME If it is on yarn mode ( yarn-prejob | yarn-application | yarn-session), you need to configure hadoop-user-name</span></span><br><span class="line">  hadoop-user-name: hdfs</span><br><span class="line">  <span class="comment"># Local workspace, used to store project source code, build directory, etc.</span></span><br><span class="line">  workspace:</span><br><span class="line">    <span class="built_in">local</span>: /data/streampark_workspace</span><br><span class="line"></span><br><span class="line"><span class="comment">#Starting</span></span><br><span class="line">cp -a /works/app/flink/lib-1.17/mysql-connector-j-8.0.31.jar /works/app/flink/apache-streampark_2.12/lib/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> apache-streampark_2.12/bin</span><br><span class="line">bash startup.sh</span><br></pre></td></tr></table></figure>
<p>Noticed: In order to launch kubernetes flink environment, you must have config file of kubectl(~/.kube/config) installed.</p>
<h5 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h5><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126170051565.png" alt="image-20240126170051565"></p>
<p>Dockerfile</p>
<p><a href="https://raw.githubusercontent.com/apache/incubator-streampark/v2.1.2/deploy/docker/Dockerfile" target="_blank" rel="noopener">raw.githubusercontent.com/apache/incubator-streampark/v2.1.2/deploy/docker/Dockerfile</a></p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.16</span> as deps-stage</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p ~/.kube ~/.m2 /works/app/flink/ /data/streampark_workspace</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> apache-streampark_2.12.tar.gz /</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar xf apache-streampark_2.12.tar.gz &amp;&amp; mv apache-streampark_2.12 streampark </span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> rm -rf /apache-streampark_2.12.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> docker:dind</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /streampark</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=deps-stage /streampark /streampark</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> NODE_VERSION=<span class="number">16.1</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">ENV</span> NPM_VERSION=<span class="number">7.11</span>.<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk add openjdk8 \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add maven \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add wget \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add vim \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add bash \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add curl</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME=/usr/lib/jvm/java-<span class="number">1.8</span>-openjdk</span><br><span class="line"><span class="keyword">ENV</span> MAVEN_HOME=/usr/share/java/maven-<span class="number">3</span></span><br><span class="line"><span class="keyword">ENV</span> PATH $JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">ENV</span> PATH $MAVEN_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget <span class="string">"https://nodejs.org/dist/v<span class="variable">$NODE_VERSION</span>/node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.gz"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; tar zxvf <span class="string">"node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.gz"</span> -C /usr/<span class="built_in">local</span> --strip-components=1 \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm <span class="string">"node-v<span class="variable">$NODE_VERSION</span>-linux-x64.tar.gz"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ln -s /usr/<span class="built_in">local</span>/bin/node /usr/<span class="built_in">local</span>/bin/nodejs \</span></span><br><span class="line"><span class="bash">    &amp;&amp; curl -LO https://dl.k8s.io/release/v1.23.0/bin/linux/amd64/kubectl \</span></span><br><span class="line"><span class="bash">    &amp;&amp; install -o root -g root -m 0755 kubectl /usr/<span class="built_in">local</span>/bin/kubectl</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>Building</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_BUILDKIT=0 docker build -t <span class="string">"registry.zerofinance.net/flink/streampark:2.1.2"</span> .</span><br></pre></td></tr></table></figure>
<p>Creating docker</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name <span class="string">"streampark"</span> \</span><br><span class="line">--privileged=<span class="literal">true</span> \</span><br><span class="line">-v /works/app/flink/streampark/config:/root/.kube/config:ro \</span><br><span class="line">-v /works/app/flink/streampark/settings.xml:/Developer/apache-maven-3.5.4/conf/settings.xml:ro \</span><br><span class="line">-v /works/app/flink/streampark/flink-1.17.2:/works/app/flink/flink-1.17.2 \</span><br><span class="line">-v /works/app/flink/streampark/application.yml:/streampark/conf/application.yml \</span><br><span class="line">-v /works/app/flink/streampark/application-mysql.yml:/streampark/conf/application-mysql.yml \</span><br><span class="line">-p 10000:10000 \</span><br><span class="line">registry.zerofinance.net/flink/streampark:2.1.2</span><br></pre></td></tr></table></figure>
<p>Start streampark instance</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it streampark bash</span><br><span class="line">/streampark/bin/startup.sh</span><br></pre></td></tr></table></figure>
<h5 id="K8s"><a href="#K8s" class="headerlink" title="K8s"></a>K8s</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: streampark</span><br><span class="line">  name: streampark</span><br><span class="line">  namespace: flink-test</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: streampark</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 1</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: streampark</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: registry.zerofinance.net/flink/streampark:2.1.2</span><br><span class="line">        name: streampark</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;wget -P lib https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.31/mysql-connector-j-8.0.31.jar &amp;&amp; bash bin/streampark.sh start_docker &quot;]</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 10000</span><br><span class="line">          name: streampark</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;1&quot;</span><br><span class="line">            memory: 1024Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 500m</span><br><span class="line">            memory: 500Mi</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: flink</span><br><span class="line">          mountPath: /works/app/flink/flink-1.17.2</span><br><span class="line">        - name: maven-setting</span><br><span class="line">          mountPath: /root/.m2/settings.xml</span><br><span class="line">        - name: k8s-config</span><br><span class="line">          mountPath: /root/.kube/config</span><br><span class="line">        - name: application</span><br><span class="line">          mountPath: /streampark/conf/application.yml</span><br><span class="line">        - name: application-mysql</span><br><span class="line">          mountPath: /streampark/conf/application-mysql.yml</span><br><span class="line">        - name: workspace</span><br><span class="line">          mountPath: /data/streampark_workspace</span><br><span class="line">        - name: docker</span><br><span class="line">          mountPath: /var/run/docker.sock</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      volumes:</span><br><span class="line">      - name: flink</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/flink-1.17.2</span><br><span class="line">      - name: maven-setting</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/settings.xml</span><br><span class="line">      - name: k8s-config</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/kube/config</span><br><span class="line">      - name: application</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/application.yml</span><br><span class="line">      - name: application-mysql</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/application-mysql.yml</span><br><span class="line">      - name: workspace</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /data/data/streampark_flink/workspace</span><br><span class="line">      - name: docker</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /var/run/docker.sock</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: streampark</span><br><span class="line">  namespace: flink-test</span><br><span class="line">  labels:</span><br><span class="line">    app: streampark</span><br><span class="line">spec:</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: streampark</span><br><span class="line">    port: 10000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 10000</span><br><span class="line">  selector:</span><br><span class="line">    app: streampark</span><br><span class="line">  sessionAffinity: None</span><br></pre></td></tr></table></figure>
<h4 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h4><h5 id="System-Setting"><a href="#System-Setting" class="headerlink" title="System Setting"></a>System Setting</h5><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135203700.png" alt="image-20240126135203700"></p>
<p>First, you need creating a registry project named “flink” from menu: “Project Quotas”.</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135223713.png" alt="image-20240126135223713"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135244714.png" alt="image-20240126135244714"></p>
<h5 id="Flink-Cluster"><a href="#Flink-Cluster" class="headerlink" title="Flink Cluster"></a>Flink Cluster</h5><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135334426.png" alt="image-20240126135334426"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135423779.png" alt="image-20240126135423779"></p>
<h5 id="Flink-Home"><a href="#Flink-Home" class="headerlink" title="Flink Home"></a>Flink Home</h5><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135020759.png" alt="image-20240126135020759"></p>
<h4 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h4><h5 id="application-sql-Job"><a href="#application-sql-Job" class="headerlink" title="application sql Job"></a>application sql Job</h5><p>(Recommend)</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135601938.png" alt="image-20240126135601938"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135618321.png" alt="image-20240126135618321"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126135722313.png" alt="image-20240126135722313"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126170432588.png" alt="image-20240126170432588"></p>
<h5 id="session-sql-job"><a href="#session-sql-job" class="headerlink" title="session sql job"></a>session sql job</h5><p>You have to start the session instance from “Settings—&gt;Flink Cluster”</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140249679.png" alt="image-20240126140249679"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140316800.png" alt="image-20240126140316800"></p>
<h5 id="application-jar-job"><a href="#application-jar-job" class="headerlink" title="application jar job"></a>application jar job</h5><p>Create Project first:</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140615094.png" alt="image-20240126140615094"></p>
<p>Create a new jar job:</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140704271.png" alt="image-20240126140704271"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140727419.png" alt="image-20240126140727419"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126140814011.png" alt="image-20240126140814011"></p>
<h4 id="Pod-template"><a href="#Pod-template" class="headerlink" title="Pod template"></a>Pod template</h4><h5 id="Pod-Template"><a href="#Pod-Template" class="headerlink" title="Pod Template"></a>Pod Template</h5><p>In order to collect logs to Loki:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">taskmanager-pod-template</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="comment"># Do not change the main container name</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flink-main-container</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flink-logs</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/opt/flink/log</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flink-logs</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/works/log/hkloan/dev/la-loan-account</span></span><br></pre></td></tr></table></figure>
<h5 id="Dynamic-Properties"><a href="#Dynamic-Properties" class="headerlink" title="Dynamic Properties"></a>Dynamic Properties</h5><p>You can simplify “Dynamic Properties”:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-Dakka.ask.timeout=100s</span></span><br><span class="line"><span class="string">-Dfs.oss.endpoint=https://oss-cn-hongkong.aliyuncs.com</span></span><br><span class="line"><span class="string">-Dfs.oss.accessKeyId=xxx</span></span><br><span class="line"><span class="string">-Dfs.oss.accessKeySecret=yyy</span></span><br><span class="line"><span class="string">-Dkubernetes.container.image.pull-policy=IfNotPresent</span></span><br><span class="line"><span class="string">-Dhigh-availability.type=kubernetes</span></span><br><span class="line"><span class="string">-Dhigh-availability.storageDir=oss://flink-cluster-uat/recovery-application</span></span><br><span class="line"><span class="string">-Dstate.backend=rocksdb</span></span><br><span class="line"><span class="string">-Dstate.backend.incremental=true</span></span><br><span class="line"><span class="string">-Dstate.checkpoints.dir=oss://flink-cluster-uat/flink-application-checkpoints</span></span><br><span class="line"><span class="string">-Dstate.savepoints.dir=oss://flink-cluster-uat/flink-application-savepoints</span></span><br><span class="line"><span class="string">-Dkubernetes.container.image.pull-secrets=zzz</span></span><br><span class="line"><span class="string">-Dkubernetes.jobmanager.replicas=1</span></span><br><span class="line"><span class="string">-Dkubernetes.jobmanager.cpu.amount=0.5</span></span><br><span class="line"><span class="string">-Dresourcemanager.taskmanager-timeout=3600000</span></span><br><span class="line"><span class="string">-Dkubernetes.taskmanager.node-selector=flink-env:test</span></span><br><span class="line"><span class="string">-Dkubernetes.taskmanager.tolerations=flink-env:test,operator:Exists,effect:NoSchedule</span></span><br><span class="line"><span class="string">-Dkubernetes.taskmanager.cpu.amount=1</span></span><br><span class="line"><span class="string">-Denv.java.opts.jobmanager="-Duser.timezone=GMT+08"</span></span><br><span class="line"><span class="string">-Denv.java.opts.taskmanager="-Duser.timezone=GMT+08"</span></span><br></pre></td></tr></table></figure>
<h5 id="Clean-all-Jobs"><a href="#Clean-all-Jobs" class="headerlink" title="Clean all Jobs"></a>Clean all Jobs</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k -n flink-dev delete deploy myql2es-deploy-demo</span><br><span class="line">k -n flink-dev delete cm myql2es-deploy-demo-cluster-config-map</span><br></pre></td></tr></table></figure>
<h4 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h4><p>Create a project first:</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126142114186.png" alt="image-20240126142114186"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126142047951.png" alt="image-20240126142047951"></p>
<p>Adding dependency pom in a job:</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126142210706.png" alt="image-20240126142210706"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240126142018520.png" alt="image-20240126142018520"></p>
<h3 id="Dinky"><a href="#Dinky" class="headerlink" title="Dinky"></a>Dinky</h3><p>A alternative Flink stream platform, like StreamPark. But I recommend using StreamPark strongly.</p>
<p><a href="http://www.dlink.top/docs/0.7/get_started/docker_deploy" target="_blank" rel="noopener">http://www.dlink.top/docs/0.7/get_started/docker_deploy</a></p>
<p><a href="http://www.dlink.top/docs/0.7/deploy_guide/build" target="_blank" rel="noopener">http://www.dlink.top/docs/0.7/deploy_guide/build</a></p>
<p>Prerequisite: <a href="/files/2023-08-25-hadoop-Ecosystem/dinky.sql">dinky.sql</a> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p</span><br><span class="line">CREATE USER &apos;dinky&apos;@&apos;%&apos; IDENTIFIED BY &apos;Aa123456&apos;;</span><br><span class="line">GRANT ALL PRIVILEGES ON dinky.* TO &apos;dinky&apos;@&apos;%&apos;;</span><br><span class="line"></span><br><span class="line">mysql -udinky -h127.0.0.1 -p</span><br><span class="line">create database dinky;</span><br><span class="line">use dinky;</span><br><span class="line">source /works/app/flink/dinky-mysql.sql;</span><br></pre></td></tr></table></figure>
<h4 id="Linux-Install"><a href="#Linux-Install" class="headerlink" title="Linux Install"></a>Linux Install</h4><p>For 1.0.0 version:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#http://www.dinky.org.cn/docs/next/deploy_guide/normal_deploy</span></span><br><span class="line">wget https://github.com/DataLinkDC/dinky/releases/download/v1.0.0-rc4/dinky-release-1.17-1.0.0-rc4.tar.gz</span><br><span class="line">tar zxvf dinky-release-1.17-1.0.0-rc4.tar.gz </span><br><span class="line"><span class="built_in">cd</span> dinky-release-1.17-1.0.0-rc4/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Download sql file to local:</span></span><br><span class="line"><span class="built_in">cd</span> sql</span><br><span class="line">sz dinky-mysql.sql </span><br><span class="line"></span><br><span class="line"><span class="comment">#Edit application files</span></span><br><span class="line"><span class="built_in">cd</span> /works/app/dinky/dinky-release-1.17-1.0.0-rc4/</span><br><span class="line"><span class="built_in">cd</span> config/</span><br><span class="line">vim application.yml </span><br><span class="line">vim application-mysql.yml </span><br><span class="line"></span><br><span class="line"><span class="comment">#copy jdbc driver:</span></span><br><span class="line">cp -a /works/app/flink/lib-1.17/mysql-connector-j-8.0.31.jar /works/app/dinky/dinky-release-1.17-1.0.0-rc4/lib/</span><br><span class="line"><span class="comment">#Copy Flink dependency lib jars:</span></span><br><span class="line">cp -a /works/app/flink/flink-1.17.2/lib/flink-*.jar /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line"><span class="comment">#Copy Extra dependency lib jars:</span></span><br><span class="line">cp -a /works/app/flink/lib-1.17/* /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line">rm /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/flink-table-planner-loader-1.17.2.jar</span><br><span class="line">cp -a /works/app/flink/flink-1.17.2/opt/flink-table-planner_2.12-1.17.2.jar /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line"><span class="comment">#Mysql jdbc driver:</span></span><br><span class="line">cp -a /works/app/dinky/flink-1.17.2-lib/mysql-connector-j-8.0.31.jar /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line"><span class="comment">#Hadoop dependency lib jars:</span></span><br><span class="line"><span class="built_in">cd</span> /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line">wget https://repository.cloudera.com/artifactory/cloudera-repos/org/apache/flink/flink-shaded-hadoop-3-uber/3.1.1.7.2.9.0-173-9.0/flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#整库同步jar:</span></span><br><span class="line">cp -a /works/app/dinky/dinky-release-1.17-1.0.0-rc4/lib/dinky-client-base-1.0.0-rc4.jar /works/app/flink/flink-1.17.2/lib/</span><br><span class="line">cp -a /works/app/dinky/dinky-release-1.17-1.0.0-rc4/lib/dinky-common-1.0.0-rc4.jar /works/app/flink/flink-1.17.2/lib/</span><br><span class="line">cp -a /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/dinky/dinky-client-1.17-1.0.0-rc4.jar /works/app/flink/flink-1.17.2/lib/</span><br><span class="line"><span class="comment">#Need flink-cdc-common jar:</span></span><br><span class="line">wget https://repo1.maven.org/maven2/com/ververica/flink-cdc-common/3.0.1/flink-cdc-common-3.0.1.jar -P /works/app/flink/flink-1.17.2/lib/</span><br><span class="line">wget https://repo1.maven.org/maven2/com/ververica/flink-cdc-common/3.0.1/flink-cdc-common-3.0.1.jar -P /works/app/dinky/dinky-release-1.17-1.0.0-rc4/extends/flink1.17/</span><br><span class="line"></span><br><span class="line"><span class="comment">#https://blog.csdn.net/lisi1129/article/details/101453563</span></span><br><span class="line"><span class="comment">#在conf/flink-conf.yaml 添加如下内容并重启 flink.</span></span><br><span class="line">classloader.resolve-order: parent-first</span><br><span class="line"></span><br><span class="line"><span class="comment">#Start</span></span><br><span class="line">sh auto.sh start 1.17</span><br><span class="line"><span class="comment">#Stop</span></span><br><span class="line">sh auto.sh stop</span><br></pre></td></tr></table></figure>
<h4 id="Docker-1"><a href="#Docker-1" class="headerlink" title="Docker"></a>Docker</h4><p>For 1.0.0 version:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8u342-oracle as build-stage</span><br><span class="line"></span><br><span class="line">ARG DINKY_VERSION</span><br><span class="line">ENV DINKY_VERSION=<span class="variable">$&#123;DINKY_VERSION&#125;</span></span><br><span class="line"></span><br><span class="line">ARG FLINK_BIG_VERSION</span><br><span class="line">ENV FLINK_BIG_VERSION <span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span></span><br><span class="line"></span><br><span class="line">ADD ./build/dinky-release-<span class="variable">$&#123;DINKY_VERSION&#125;</span>.tar.gz  /opt/</span><br><span class="line"></span><br><span class="line">USER root</span><br><span class="line">RUN mv /opt/dinky-release-<span class="variable">$&#123;DINKY_VERSION&#125;</span> /opt/dinky/</span><br><span class="line">RUN mkdir /opt/dinky/conf</span><br><span class="line"></span><br><span class="line">COPY ./flink<span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span>-lib/*.jar /opt/dinky/extends/flink<span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span>/</span><br><span class="line"><span class="comment">##不复制的话dinky applicaition下显示不了日志</span></span><br><span class="line">COPY ./flink<span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span>-conf/* /opt/dinky/conf/</span><br><span class="line"></span><br><span class="line">ADD ./build/flink-python-1.17.2.jar /opt/dinky/lib/</span><br><span class="line">COPY ./flink<span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span>-lib/mysql-connector-j-8.0.31.jar /opt/dinky/lib/</span><br><span class="line"></span><br><span class="line">RUN mkdir -p /opt/dinky/run &amp;&amp; mkdir -p /opt/dinky/logs &amp;&amp;  touch /opt/dinky/logs/dinky.log</span><br><span class="line">RUN chmod -R 777 /opt/dinky/</span><br><span class="line"></span><br><span class="line">FROM openjdk:8u342-oracle as production-stage</span><br><span class="line">RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">RUN <span class="built_in">export</span> LANG=zh_CN.UTF-8</span><br><span class="line"></span><br><span class="line">COPY --from=build-stage /opt/dinky/ /opt/dinky/</span><br><span class="line">RUN microdnf install procps -y</span><br><span class="line"></span><br><span class="line">WORKDIR /opt/dinky/</span><br><span class="line"></span><br><span class="line">EXPOSE 8888</span><br><span class="line"></span><br><span class="line">CMD touch /opt/dinky/logs/dinky.log &amp;&amp; ./auto.sh restart <span class="variable">$&#123;FLINK_BIG_VERSION&#125;</span> &amp;&amp; tail -f /opt/dinky/logs/dinky.log</span><br></pre></td></tr></table></figure>
<p>All jars  in flink1.17-lib:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">ll build/</span><br><span class="line">总用量 208880</span><br><span class="line">-rw-rw-r-- 1 dev dev 180884317 1月  29 15:11 dinky-release-1.17-1.0.0-rc4.tar.gz</span><br><span class="line">-rw-r--r-- 1 dev dev  32998809 11月 13 12:47 flink-python-1.17.2.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ll flink1.17-lib/</span><br><span class="line">总用量 322180</span><br><span class="line">-rw-rw-r-- 1 dev dev    251405 1月  19 11:57 flink-cdc-common-3.0.1.jar</span><br><span class="line">-rw-r--r-- 1 dev dev    196491 11月 13 12:27 flink-cep-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev    542629 11月 13 12:33 flink-connector-files-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev    266420 6月  15 2023 flink-connector-jdbc-3.1.1-1.17.jar</span><br><span class="line">-rw-r--r-- 1 dev dev    102470 11月 13 12:40 flink-csv-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev 121809282 11月 13 12:57 flink-dist-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev    180246 11月 13 12:40 flink-json-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  25743957 11月 10 16:32 flink-oss-fs-hadoop-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  21043317 11月 13 12:54 flink-scala_2.12-1.17.2.jar</span><br><span class="line">-rw-rw-r-- 1 dev dev  59604787 8月  11 2023 flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  28440546 4月  13 2023 flink-sql-connector-elasticsearch7-3.0.1-1.17.jar</span><br><span class="line">-rw-rw-r-- 1 dev dev   5566107 10月 26 04:26 flink-sql-connector-kafka-3.0.1-1.17.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  23715175 2月  20 16:47 flink-sql-connector-mysql-cdc-3.0.1.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  15407408 11月 13 12:55 flink-table-api-java-uber-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev  21333608 2月  22 16:19 flink-table-planner_2.12-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev   3146303 11月 13 12:27 flink-table-runtime-1.17.2.jar</span><br><span class="line">-rw-r--r-- 1 dev dev   2515447 2月  20 13:40 mysql-connector-j-8.0.31.jar</span><br></pre></td></tr></table></figure>
<p>Build and push to registry:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker build --build-arg FLINK_BIG_VERSION=1.17 --build-arg DINKY_VERSION=1.17-1.0.0-rc4 -t &quot;registry.zerofinance.net/flink/dinky-flink:1.17-1.0.0-rc4&quot; .</span><br><span class="line">docker push registry.zerofinance.net/flink/dinky-flink:1.17-1.0.0-rc4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Run</span><br><span class="line">docker run \</span><br><span class="line">-d \</span><br><span class="line">--restart=always \</span><br><span class="line">-p 8888:8888 \</span><br><span class="line">-e FLINK_BIG_VERSION=1.17 \</span><br><span class="line">-e DB_ACTIVE=mysql \</span><br><span class="line">-e MYSQL_ADDR=rm-xxxxxx.mysql.rds.aliyuncs.com:3306 \</span><br><span class="line">-e MYSQL_DATABASE=dinky_test \</span><br><span class="line">-e MYSQL_USERNAME=dinky_test \</span><br><span class="line">-e MYSQL_PASSWORD=xxxxxx \</span><br><span class="line">--name dinky-server \</span><br><span class="line">registry.zerofinance.net/flink/dinky-flink:1.17-1.0.0-rc4</span><br></pre></td></tr></table></figure>
<p>flink-dinky-template.yml:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flink-dinky</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flink-dinky-test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">flink-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flink-dinky</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flink-dinky</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">imagePullSecrets:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">registry-private-secret</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">registry.zerofinance.net/flink/dinky-flink:1.17-1.0.0-rc4</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">flink-dinky</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">FLINK_BIG_VERSION</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">"1.17"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DB_ACTIVE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">mysql</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ADDR</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">rm-xxx.mysql.rds.aliyuncs.com:3306</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_DATABASE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">dinky_test</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_USERNAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">dinky_test</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_PASSWORD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">xxx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dinky-port</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">8888</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">"1024Mi"</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">"1000m"</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">        <span class="attr">livenessProbe:</span></span><br><span class="line">          <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">httpGet:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">port:</span> <span class="number">8888</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">          <span class="comment">#successThreshold: 1</span></span><br><span class="line">          <span class="attr">timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">readinessProbe:</span></span><br><span class="line">          <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">httpGet:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">port:</span> <span class="number">8888</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">30</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">          <span class="comment">#successThreshold: 1</span></span><br><span class="line">          <span class="attr">timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-config</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/root/.kube</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-config</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/data/data/kube-config</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flink-dinky-test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">flink-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flink-dinky</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8888</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="comment">#nodePort: 32323</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flink-dinky</span></span><br><span class="line">  <span class="comment">#type:  NodePort </span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flink-dinky-ingress</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">flink-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span> <span class="string">[]</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">flink-dinky-test.zerofinance.net</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">flink-dinky-test</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">8888</span></span><br></pre></td></tr></table></figure>
<h4 id="On-Application"><a href="#On-Application" class="headerlink" title="On Application"></a>On Application</h4><p>Must build your own image:</p>
<p>DinkyFlinkDockerfile(1.0.0):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用来构建dinky环境</span></span><br><span class="line">ARG FLINK_VERSION=1.17.2</span><br><span class="line">ARG FLINK_BIG_VERSION=1.17</span><br><span class="line"></span><br><span class="line"><span class="comment">#FROM flink:$&#123;FLINK_VERSION&#125;</span></span><br><span class="line">FROM registry.zerofinance.net/library/flink:<span class="variable">$&#123;FLINK_VERSION&#125;</span></span><br><span class="line"></span><br><span class="line">ARG FLINK_VERSION</span><br><span class="line">ARG FLINK_BIG_VERSION</span><br><span class="line">ENV PYTHON_HOME /opt/miniconda3</span><br><span class="line"></span><br><span class="line">USER root</span><br><span class="line">RUN wget <span class="string">"https://s3.jcloud.sjtu.edu.cn/899a892efef34b1b944a19981040f55b-oss01/anaconda/miniconda/Miniconda3-py38_4.9.2-Linux-x86_64.sh"</span> -O <span class="string">"miniconda.sh"</span> &amp;&amp; chmod +x miniconda.sh</span><br><span class="line">RUN ./miniconda.sh -b -p <span class="variable">$PYTHON_HOME</span> &amp;&amp; chown -R flink <span class="variable">$PYTHON_HOME</span> &amp;&amp; ls <span class="variable">$PYTHON_HOME</span></span><br><span class="line"></span><br><span class="line">USER flink</span><br><span class="line"></span><br><span class="line">ENV PATH <span class="variable">$PYTHON_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">RUN pip install <span class="string">"apache-flink==<span class="variable">$&#123;FLINK_VERSION&#125;</span>"</span> -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com</span><br><span class="line"></span><br><span class="line"><span class="comment">#RUN cp /opt/flink/opt/flink-python_* /opt/flink/lib/</span></span><br><span class="line">RUN cp /opt/flink/opt/flink-python-* /opt/flink/lib/</span><br><span class="line"></span><br><span class="line"><span class="comment">#RUN wget -O dinky-app-$&#123;FLINK_BIG_VERSION&#125;.jar - $&#123;DINKY_HTTP&#125;/downloadAppJar/$&#123;FLINK_BIG_VERSION&#125; | mv dinky-app-$&#123;FLINK_BIG_VERSION&#125;.jar</span></span><br><span class="line">COPY ./dinky-lib/* /opt/flink/lib/</span><br><span class="line"><span class="comment">#Replace flink-table-planner-loader as flink-table-planner(Already included in dinky-lib folder, so need to delete)</span></span><br><span class="line">RUN rm -fr /opt/flink/lib/flink-table-planner-loader-1.17.2.jar</span><br></pre></td></tr></table></figure>
<p>All jars in dinky-lib:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ll dinky-lib/</span><br><span class="line">总用量 49444</span><br><span class="line">-rwxrwxr-x 1 dev dev 28586238 1月  29 14:43 dinky-app-1.17-1.0.0-rc4-jar-with-dependencies.jar</span><br><span class="line">-rwxrwxr-x 1 dev dev    94360 1月  29 14:42 dinky-client-1.17-1.0.0-rc4.jar</span><br><span class="line">-rwxrwxr-x 1 dev dev    78413 1月  29 14:44 dinky-client-base-1.0.0-rc4.jar</span><br><span class="line">-rwxrwxr-x 1 dev dev   269936 1月  29 14:44 dinky-common-1.0.0-rc4.jar</span><br><span class="line">-rw-rw-r-- 1 dev dev   251405 1月  19 11:57 flink-cdc-common-3.0.1.jar</span><br><span class="line">-rw-r--r-- 1 dev dev 21333608 2月  22 16:19 flink-table-planner_2.12-1.17.2.jar</span><br></pre></td></tr></table></figure>
<p>Build and push to registry:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t registry.zerofinance.net/flink/dinky-flink-application:1.17.2-1.0.0-rc4 . -f DinkyFlinkDockerfile</span><br><span class="line">docker push registry.zerofinance.net/flink/dinky-flink-application:1.17.2-1.0.0-rc4</span><br></pre></td></tr></table></figure>
<p>“提交FlinkSQL的jar文件路径”为打包到镜像registry.zerofinance.net/flink/dinky-flink-application:1.17.2-1.0.0-rc4中的路径，而不是dinky中的路径。</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240222165123099.png" alt="image-20240222165123099"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240222165153627.png" alt="image-20240222165153627"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240222165214472.png" alt="image-20240222165214472"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20240222165256791.png" alt="image-20240222165256791"></p>
<h4 id="DataSource"><a href="#DataSource" class="headerlink" title="DataSource"></a>DataSource</h4><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20231229175659553.png" alt="image-20231229175659553"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20231229175620829.png" alt="image-20231229175620829"></p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20231229175739306.png" alt="image-20231229175739306"></p>
<h3 id="User-defined-Functions"><a href="#User-defined-Functions" class="headerlink" title="User-defined Functions"></a>User-defined Functions</h3><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/functions/udfs/" target="_blank" rel="noopener">User-defined Functions | Apache Flink</a></p>
<p>User-defined functions (UDFs) are extension points to call frequently used logic or custom logic that cannot be expressed otherwise in queries.</p>
<p>User-defined functions can be implemented in a JVM language (such as Java or Scala) or Python. An implementer can use arbitrary third party libraries within a UDF. This page will focus on JVM-based languages, please refer to the PyFlink documentation for details on writing <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/python/table/udfs/python_udfs/" target="_blank" rel="noopener">general</a> and <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/python/table/udfs/vectorized_python_udfs/" target="_blank" rel="noopener">vectorized</a> UDFs in Python.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">#https://yangyichao-mango.github.io/2021/11/15/wechat-blog/01_%E5%A4%A7%E6%95%B0%E6%8D%AE/01_%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/01_%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/02_%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%E5%BB%BA%E8%AE%BE/03_one-engine/01_%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E/01_flink/01_flink-sql/20_%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E5%B9%B2%E8%B4%A7%EF%BC%81FlinkSQL%E6%88%90%E7%A5%9E%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%85%A8%E6%96%876%E4%B8%87%E5%AD%97%E3%80%81110%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%E3%80%81160%E5%BC%A0%E5%9B%BE%EF%BC%89/</span><br><span class="line">#https://www.cnblogs.com/wxm2270/p/17275442.html</span><br><span class="line">#https://juejin.cn/post/7103196993232568328</span><br><span class="line">#https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/functions/udfs/</span><br><span class="line"></span><br><span class="line">#第一步，自定义数据类型</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 基础类型，Flink 可以通过反射类型信息自动把数据类型获取到</span></span><br><span class="line">    <span class="comment">// 关于 SQL 类型和 Java 类型之间的映射见：https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/table/types/#data-type-extraction</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 复杂类型，用户可以通过 @DataTypeHint("DECIMAL(10, 2)") 注解标注此字段的数据类型</span></span><br><span class="line">    <span class="keyword">public</span> <span class="meta">@DataTypeHint</span>(<span class="string">"DECIMAL(10, 2)"</span>) BigDecimal totalBalance;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#第二步，在 UDF 中使用此数据类型</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserScalarFunction</span> <span class="keyword">extends</span> <span class="title">ScalarFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 自定义数据类型作为输出参数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">eval</span><span class="params">(<span class="keyword">long</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; <span class="number">0</span> &amp;&amp; i &lt;= <span class="number">5</span>) &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = (<span class="keyword">int</span>) i;</span><br><span class="line">            u.name = <span class="string">"name1"</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">1.1</span>d);</span><br><span class="line">            <span class="keyword">return</span> u;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = (<span class="keyword">int</span>) i;</span><br><span class="line">            u.name = <span class="string">"name2"</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">2.2</span>d);</span><br><span class="line">            <span class="keyword">return</span> u;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 自定义数据类型作为输入参数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">eval</span><span class="params">(User i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (i.age &gt; <span class="number">0</span> &amp;&amp; i.age &lt;= <span class="number">5</span>) &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = <span class="number">1</span>;</span><br><span class="line">            u.name = <span class="string">"name1"</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">1.1</span>d);</span><br><span class="line">            <span class="keyword">return</span> u.name;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            User u = <span class="keyword">new</span> User();</span><br><span class="line">            u.age = <span class="number">2</span>;</span><br><span class="line">            u.name = <span class="string">"name2"</span>;</span><br><span class="line">            u.totalBalance = <span class="keyword">new</span> BigDecimal(<span class="number">2.2</span>d);</span><br><span class="line">            <span class="keyword">return</span> u.name;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">#Upload the packaged jar to /usr/bigtop/current/flink-client/lib/ of all machines and restart yarn-session instance.</span><br><span class="line"></span><br><span class="line">#第三步，在 Flink SQL 中使用</span><br><span class="line">-- <span class="number">1</span>. 创建 UDF</span><br><span class="line">CREATE FUNCTION user_scalar_func AS <span class="string">'flink.examples.sql._12_data_type._02_user_defined.UserScalarFunction'</span>;</span><br><span class="line"></span><br><span class="line">-- <span class="number">2</span>. 创建数据源表</span><br><span class="line"><span class="function">CREATE TABLE <span class="title">source_table</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    user_id BIGINT NOT NULL COMMENT <span class="string">'用户 id'</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="string">'rows-per-second'</span> = <span class="string">'1'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="string">'fields.user_id.max'</span> = <span class="string">'10'</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line">-- <span class="number">3</span>. 创建数据汇表</span><br><span class="line"><span class="function">CREATE TABLE <span class="title">sink_table</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    result_row_1 ROW&lt;age INT, name STRING, totalBalance DECIMAL(<span class="number">10</span>, <span class="number">2</span>)</span>&gt;,</span></span><br><span class="line"><span class="function">    result_row_2 STRING</span></span><br><span class="line"><span class="function">) <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="string">'connector'</span> = <span class="string">'print'</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line">-- <span class="number">4</span>. SQL 查询语句</span><br><span class="line">INSERT INTO sink_table</span><br><span class="line">select</span><br><span class="line">    -- <span class="number">4</span>.a. 用户自定义类型作为输出</span><br><span class="line">    user_scalar_func(user_id) as result_row_1,</span><br><span class="line">    -- <span class="number">4</span>.b. 用户自定义类型作为输出及输入</span><br><span class="line">    user_scalar_func(user_scalar_func(user_id)) as result_row_2</span><br><span class="line">from source_table;</span><br><span class="line"></span><br><span class="line">-- <span class="number">5</span>. 查询结果</span><br><span class="line">+I[+I[<span class="number">9</span>, name2, <span class="number">2.20</span>], name2]</span><br><span class="line">+I[+I[<span class="number">1</span>, name1, <span class="number">1.10</span>], name1]</span><br><span class="line">+I[+I[<span class="number">5</span>, name1, <span class="number">1.10</span>], name1]</span><br></pre></td></tr></table></figure>
<h3 id="Hive-Catalog"><a href="#Hive-Catalog" class="headerlink" title="Hive Catalog"></a>Hive Catalog</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://nightlies.apache.org/flink/flink-docs-release-1.17/zh/docs/connectors/table/hive/hive_catalog/</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">CATALOG</span> myhive <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'type'</span> = <span class="string">'hive'</span>,</span><br><span class="line">  <span class="string">'hive-conf-dir'</span> = <span class="string">'/usr/bigtop/current/hive-client/conf'</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">show</span> catalogs;</span><br><span class="line"><span class="keyword">use</span> <span class="keyword">catalog</span> myhive;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">databases</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> mykafka (</span><br><span class="line">    <span class="keyword">id</span> <span class="keyword">STRING</span>,</span><br><span class="line">    use_rname <span class="keyword">STRING</span>,</span><br><span class="line">    age <span class="built_in">integer</span>,</span><br><span class="line">    gender <span class="keyword">STRING</span>,</span><br><span class="line">    goods_no <span class="keyword">STRING</span>,</span><br><span class="line">    goods_price <span class="built_in">Float</span>,</span><br><span class="line">    store_id <span class="built_in">integer</span>,</span><br><span class="line">    shopping_type <span class="keyword">STRING</span>,</span><br><span class="line">    tel <span class="keyword">STRING</span>,</span><br><span class="line">    email <span class="keyword">STRING</span>,</span><br><span class="line">    shopping_date <span class="built_in">Date</span></span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'earliest-offset'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'csv'</span>,</span><br><span class="line">    <span class="string">'csv.ignore-parse-errors'</span> = <span class="string">'true'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESCRIBE</span> mykafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mykafka;</span><br></pre></td></tr></table></figure>
<h3 id="Flink-Streaming-Platform-Web"><a href="#Flink-Streaming-Platform-Web" class="headerlink" title="Flink Streaming Platform Web"></a>Flink Streaming Platform Web</h3><p><a href="https://github.com/zhp8341/flink-streaming-platform-web" target="_blank" rel="noopener">flink-streaming-platform-web</a></p>
<p>Prerequisite:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#https://github.com/zhp8341/flink-streaming-platform-web/blob/master/docs/deploy.md</span><br><span class="line">#https://www.cnblogs.com/data-magnifier/p/16943527.html</span><br><span class="line">sudo su - hadoop</span><br><span class="line"></span><br><span class="line">mkdir /usr/bigtop/3.2.0/usr/lib/</span><br><span class="line">cd /usr/bigtop/3.2.0/usr/lib/</span><br><span class="line">wget https://github.com/zhp8341/flink-streaming-platform-web/releases/download/tagV20230610(flink1.16.2)/flink-streaming-platform-web.tar.gz</span><br><span class="line">tar zxf flink-streaming-platform-web.tar.gz</span><br><span class="line">cd /usr/bigtop/current/</span><br><span class="line">ln -s /usr/bigtop/3.2.0/usr/lib/flink-streaming-platform-web flink-streaming-platform-web</span><br><span class="line"></span><br><span class="line">cd /usr/bigtop/current/flink-streaming-platform-web</span><br><span class="line">wget https://github.com/zhp8341/flink-streaming-platform-web/blob/master/docs/sql/flink_web.sql</span><br><span class="line"></span><br><span class="line">mysql -uroot -h127.0.0.1 -p</span><br><span class="line">&gt; source /usr/bigtop/current/flink-streaming-platform-web/flink_web.sql;</span><br><span class="line">&gt; exit;</span><br></pre></td></tr></table></figure>
<p>config/application.properties:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">####jdbc信息</span><br><span class="line">server.port=9084</span><br><span class="line">spring.datasource.url=jdbc:mysql://192.168.63.102:3306/flink_web?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false</span><br><span class="line">spring.datasource.username=flink_web</span><br><span class="line">spring.datasource.password=Aa123456</span><br></pre></td></tr></table></figure>
<p>Build docker image:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">FROM  centos:7</span><br><span class="line"></span><br><span class="line">RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">RUN echo &apos;Asia/Shanghai&apos; &gt;/etc/timezone</span><br><span class="line"></span><br><span class="line">RUN yum -y install kde-l10n-Chinese &amp;&amp; yum -y reinstall glibc-common </span><br><span class="line">RUN localedef -c -f UTF-8 -i zh_CN zh_CN.utf8 </span><br><span class="line">ENV LC_ALL zh_CN.utf8</span><br><span class="line">RUN export LANG=zh_CN.UTF-8</span><br><span class="line"></span><br><span class="line">RUN  yum install java-1.8.0-openjdk* -y</span><br><span class="line"></span><br><span class="line">RUN  mkdir  /data/</span><br><span class="line">RUN  mkdir  /data/projects</span><br><span class="line">RUN  mkdir  /data/projects/flink-1.15.3</span><br><span class="line">WORKDIR /data/projects/</span><br><span class="line"></span><br><span class="line">ADD  flink-streaming-platform-web.tar.gz  /data/projects/</span><br><span class="line">#ADD flink-1.15.3-bin-scala_2.12.tgz /data/projects/</span><br><span class="line">COPY flink-1.15.3 /data/projects/flink-1.15.3</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [&quot;sh&quot;, &quot;-c&quot;, &quot;java -jar flink-streaming-platform-web/lib/flink-streaming-web-1.5.0.RELEASE.jar --spring.profiles.active=prod --spring.config.additional-location=flink-streaming-platform-web/conf/application.properties&quot;]</span><br><span class="line"></span><br><span class="line">EXPOSE  9084 5007 8081</span><br></pre></td></tr></table></figure>
<p>build and push to registry:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t registry.zerofinance.net/library/flink-streaming-platform-web:1.16.2 . -f Dockerfile.web</span><br><span class="line">docker push registry.zerofinance.net/library/flink-streaming-platform-web:1.16.2</span><br></pre></td></tr></table></figure>
<p>Starting a new instance:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name flink-streaming-platform-web --restart=always \</span><br><span class="line">-p 9084:9084 \</span><br><span class="line">-v /works/app/flink/flink-streaming-platform-web/conf:/data/projects/flink-streaming-platform-web/conf \</span><br><span class="line">registry.zerofinance.net/library/flink-streaming-platform-web:1.16.2</span><br><span class="line"></span><br><span class="line">http://192.168.64.102:32061</span><br><span class="line"></span><br><span class="line"><span class="comment">#/data/projects/flink-1.15.3/bin/flink run -d -m 192.168.63.102:8081 -c com.flink.streaming.core.JobApplication /data/projects/flink-streaming-platform-web/lib/flink-streaming-core-1.5.0.RELEASE.jar -sql /data/projects/flink-streaming-platform-web/sql/job_sql_6.sql -type 0</span></span><br></pre></td></tr></table></figure>
<p>On K8s:</p>
<p>flink-streaming-platform-web.yml:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: application-properties</span><br><span class="line">data:</span><br><span class="line">  application.properties: |</span><br><span class="line">    server.port=9084</span><br><span class="line">    spring.datasource.url=jdbc:mysql://192.168.63.102:3306/flink_fspw?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false</span><br><span class="line">    spring.datasource.username=flink_fspw</span><br><span class="line">    spring.datasource.password=Aa123456</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: flink-streaming-platform-web</span><br><span class="line">  namespace: flink-test</span><br><span class="line">  labels:</span><br><span class="line">    app: flink-streaming-platform-web</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: flink-streaming-platform-web</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: flink-streaming-platform-web</span><br><span class="line">    spec:</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">      - name: registry-private-secret</span><br><span class="line">      containers:</span><br><span class="line">      - name: flink-streaming-platform-web</span><br><span class="line">        image: registry.zerofinance.net/library/flink-streaming-platform-web:1.16.2</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        ports:</span><br><span class="line">        - name: fspw-9084</span><br><span class="line">          containerPort: 9084</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - name: fspw-5007</span><br><span class="line">          containerPort: 5007</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - name: fspw-8081</span><br><span class="line">          containerPort: 8081</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: &quot;1024Mi&quot;</span><br><span class="line">            cpu: &quot;1000m&quot;</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 500m</span><br><span class="line">            memory: 500Mi</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /static/ui/index.html</span><br><span class="line">            port: 9084</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          #successThreshold: 1</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /static/ui/index.html</span><br><span class="line">            port: 9084</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          #successThreshold: 1</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: application-properties-volume</span><br><span class="line">          mountPath: /data/projects/flink-streaming-platform-web/conf/</span><br><span class="line">      volumes:</span><br><span class="line">      - name: application-properties-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: application-properties</span><br><span class="line">          items:</span><br><span class="line">          - key: application.properties</span><br><span class="line">            path: application.properties</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: flink-streaming-platform-web</span><br><span class="line">  namespace: flink-test</span><br><span class="line">  labels:</span><br><span class="line">    app: flink-streaming-platform-web</span><br><span class="line">spec:</span><br><span class="line">  #type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: kafka</span><br><span class="line">    port: 9084</span><br><span class="line">    targetPort: 9084</span><br><span class="line">    #nodePort: 30900</span><br><span class="line">  selector:</span><br><span class="line">    app: flink-streaming-platform-web</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: flink-streaming-platform-web</span><br><span class="line">  namespace: flink-test</span><br><span class="line">spec:</span><br><span class="line">  tls: []</span><br><span class="line">  rules:</span><br><span class="line">    - host: fspw-test.zerofinance.net</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">          - backend:</span><br><span class="line">              serviceName: flink-streaming-platform-web</span><br><span class="line">              servicePort: 9084</span><br></pre></td></tr></table></figure>
<p>Or:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim conf/application.properties</span><br><span class="line"><span class="comment">####jdbc信息</span></span><br><span class="line">server.port=9084</span><br><span class="line">spring.datasource.url=jdbc:mysql://192.168.80.225:3306/flink_web?serverTimezone=UTC&amp;useUnicode=<span class="literal">true</span>&amp;characterEncoding=utf-8&amp;useSSL=<span class="literal">false</span></span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=xxxxxx</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> bin</span><br><span class="line">./deploy.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment">#http://192.168.80.226:9084/</span></span><br><span class="line">admin/123456</span><br></pre></td></tr></table></figure>
<h4 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h4><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20230914181613864.png" alt="image-20230914181613864"></p>
<h4 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h4><p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20230914181838644.png" alt="image-20230914181838644"></p>
<h3 id="Flink-SQL-CDC"><a href="#Flink-SQL-CDC" class="headerlink" title="Flink SQL CDC"></a>Flink SQL CDC</h3><p><a href="http://www.dreamwu.com/post-1594.html" target="_blank" rel="noopener">基于 Flink SQL CDC的实时数据同步方案 (dreamwu.com)</a></p>
<p><a href="https://gitee.com/zhuhuipei/flink-streaming-platform-web/blob/master/docs/sql_demo/demo_6.md" target="_blank" rel="noopener">docs/sql_demo/demo_6.md · 朱慧培/flink-streaming-platform-web - Gitee.com</a></p>
<p><a href="https://ververica.github.io/flink-cdc-connectors/release-2.4/content/about.html" target="_blank" rel="noopener">Overview — CDC Connectors for Apache Flink® documentation (ververica.github.io)</a></p>
<p>Enable mysql bin-log function:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">#temporary password：</span><br><span class="line">grep &apos;temporary password&apos; /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">mysql -uroot -p</span><br><span class="line">set global validate_password_policy=0;</span><br><span class="line">alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;Aa123456&apos;;</span><br><span class="line">CREATE USER &apos;flink_web&apos;@&apos;%&apos; IDENTIFIED BY &apos;Aa123456&apos;;</span><br><span class="line">GRANT ALL PRIVILEGES ON flink_web.* TO &apos;flink_web&apos;@&apos;%&apos;;</span><br><span class="line"></span><br><span class="line">CREATE USER &apos;demo_db&apos;@&apos;%&apos; IDENTIFIED BY &apos;Aa123456&apos;;</span><br><span class="line">GRANT ALL PRIVILEGES ON demo_db.* TO &apos;demo_db&apos;@&apos;%&apos;;</span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO demo_db@&apos;%&apos;;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line">mysql-cdc:</span><br><span class="line">#https://support.huaweicloud.com/trouble-rds/rds_12_0040.html</span><br><span class="line">Access denied; you need (at least one of) the SUPER, REPLICATION CLIENT privilege(s) for this operation</span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO demo_db@&apos;%&apos;;</span><br><span class="line">FLUSH PRIVILEGES;</span><br><span class="line"></span><br><span class="line">#https://blog.csdn.net/wochunyang/article/details/132210928?spm=1001.2014.3001.5501</span><br><span class="line">Cannot read the binlog filename and position via &apos;SHOW MASTER STATUS&apos;. Make sure your server is correctly configured</span><br><span class="line"></span><br><span class="line">vim /etc/my.cnf</span><br><span class="line">server_id = 1</span><br><span class="line">binlog_format = ROW</span><br><span class="line">log-bin = mysql_log_bin</span><br><span class="line"></span><br><span class="line">systemctl restart mysqld</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo su - hadoop</span><br><span class="line"></span><br><span class="line">&gt; mysql -uroot -h127.0.0.1 -p</span><br><span class="line">-- MySQL</span><br><span class="line">CREATE DATABASE mydb;</span><br><span class="line">USE mydb;</span><br><span class="line">CREATE TABLE products (</span><br><span class="line">  id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">  name VARCHAR(255) NOT NULL,</span><br><span class="line">  description VARCHAR(512)</span><br><span class="line">);</span><br><span class="line">ALTER TABLE products AUTO_INCREMENT = 101;</span><br><span class="line"></span><br><span class="line">INSERT INTO products</span><br><span class="line">VALUES (default,<span class="string">"scooter"</span>,<span class="string">"Small 2-wheel scooter"</span>),</span><br><span class="line">       (default,<span class="string">"car battery"</span>,<span class="string">"12V car battery"</span>),</span><br><span class="line">       (default,<span class="string">"12-pack drill bits"</span>,<span class="string">"12-pack of drill bits with sizes ranging from #40 to #3"</span>),</span><br><span class="line">       (default,<span class="string">"hammer"</span>,<span class="string">"12oz carpenter's hammer"</span>),</span><br><span class="line">       (default,<span class="string">"hammer"</span>,<span class="string">"14oz carpenter's hammer"</span>),</span><br><span class="line">       (default,<span class="string">"hammer"</span>,<span class="string">"16oz carpenter's hammer"</span>),</span><br><span class="line">       (default,<span class="string">"rocks"</span>,<span class="string">"box of assorted rocks"</span>),</span><br><span class="line">       (default,<span class="string">"jacket"</span>,<span class="string">"water resistent black wind breaker"</span>),</span><br><span class="line">       (default,<span class="string">"spare tire"</span>,<span class="string">"24 inch spare tire"</span>);</span><br><span class="line"></span><br><span class="line">CREATE TABLE orders (</span><br><span class="line">  order_id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY,</span><br><span class="line">  order_date DATETIME NOT NULL,</span><br><span class="line">  customer_name VARCHAR(255) NOT NULL,</span><br><span class="line">  price DECIMAL(10, 5) NOT NULL,</span><br><span class="line">  product_id INTEGER NOT NULL,</span><br><span class="line">  order_status BOOLEAN NOT NULL -- Whether order has been placed</span><br><span class="line">) AUTO_INCREMENT = 10001;</span><br><span class="line"></span><br><span class="line">INSERT INTO orders</span><br><span class="line">VALUES (default, <span class="string">'2020-07-30 10:08:22'</span>, <span class="string">'Jark'</span>, 50.50, 102, <span class="literal">false</span>),</span><br><span class="line">       (default, <span class="string">'2020-07-30 10:11:09'</span>, <span class="string">'Sally'</span>, 15.00, 105, <span class="literal">false</span>),</span><br><span class="line">       (default, <span class="string">'2020-07-30 12:00:30'</span>, <span class="string">'Edward'</span>, 25.25, 106, <span class="literal">false</span>);</span><br><span class="line">       </span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">Flink SQL&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line">-- checkpoint every 3000 milliseconds                       </span><br><span class="line">Flink SQL&gt; SET <span class="string">'execution.checkpointing.interval'</span> = <span class="string">'3s'</span>;  </span><br><span class="line"></span><br><span class="line"><span class="comment">#Create in flinksql</span></span><br><span class="line">-- Flink SQL</span><br><span class="line"><span class="comment">#Mysql source</span></span><br><span class="line">Flink SQL&gt; CREATE TABLE products (</span><br><span class="line">    id INT,</span><br><span class="line">    name STRING,</span><br><span class="line">    description STRING,</span><br><span class="line">    PRIMARY KEY (id) NOT ENFORCED</span><br><span class="line">  ) WITH (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">    <span class="string">'hostname'</span> = <span class="string">'192.168.80.225'</span>,</span><br><span class="line">    <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">    <span class="string">'username'</span> = <span class="string">'root'</span>,</span><br><span class="line">    <span class="string">'password'</span> = <span class="string">'Aa123#@!'</span>,</span><br><span class="line">    <span class="string">'database-name'</span> = <span class="string">'mydb'</span>,</span><br><span class="line">    <span class="string">'table-name'</span> = <span class="string">'products'</span></span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">Flink SQL&gt; CREATE TABLE orders (</span><br><span class="line">   order_id INT,</span><br><span class="line">   order_date TIMESTAMP(0),</span><br><span class="line">   customer_name STRING,</span><br><span class="line">   price DECIMAL(10, 5),</span><br><span class="line">   product_id INT,</span><br><span class="line">   order_status BOOLEAN,</span><br><span class="line">   PRIMARY KEY (order_id) NOT ENFORCED</span><br><span class="line"> ) WITH (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">   <span class="string">'hostname'</span> = <span class="string">'192.168.80.225'</span>,</span><br><span class="line">   <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'root'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'Aa123#@!'</span>,</span><br><span class="line">   <span class="string">'database-name'</span> = <span class="string">'mydb'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'orders'</span></span><br><span class="line"> );</span><br><span class="line"></span><br><span class="line"><span class="comment">#Kafka sink</span></span><br><span class="line">CREATE TABLE enriched_orders(</span><br><span class="line">   order_id INT,</span><br><span class="line">   order_date TIMESTAMP(0),</span><br><span class="line">   customer_name STRING,</span><br><span class="line">   price DECIMAL(10, 5),</span><br><span class="line">   product_id INT,</span><br><span class="line">   order_status BOOLEAN,</span><br><span class="line">   product_name STRING,</span><br><span class="line">   product_description STRING,</span><br><span class="line">   PRIMARY KEY (order_id) NOT ENFORCED</span><br><span class="line">) WITH (</span><br><span class="line"> <span class="string">'connector'</span> = <span class="string">'upsert-kafka'</span>,</span><br><span class="line"> <span class="string">'topic'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line"> <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092'</span>,</span><br><span class="line"> <span class="string">'key.format'</span> = <span class="string">'csv'</span>,</span><br><span class="line"> <span class="string">'value.format'</span> = <span class="string">'csv'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink</span></span><br><span class="line">INSERT INTO enriched_orders</span><br><span class="line"> SELECT o.*, p.name, p.description</span><br><span class="line"> FROM orders AS o</span><br><span class="line"> LEFT JOIN products AS p ON o.product_id = p.id;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Monitoring the changed data streams</span></span><br><span class="line">kafka-console-consumer.sh --topic fludesc --bootstrap-server datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092 --from-beginning</span><br></pre></td></tr></table></figure>
<p>The connector named kafka doesn’t support flink-sql-cdc, using ‘upset-kafka’ instead.  </p>
<p>The error as blow:</p>
<p><img src="/images/2023-08-25-hadoop-Ecosystem/image-20230915163923171.png" alt="image-20230915163923171"></p>
<h4 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h4><h5 id="kafka-to-mysql-Demo"><a href="#kafka-to-mysql-Demo" class="headerlink" title="kafka to mysql  Demo"></a>kafka to mysql  Demo</h5><p>This demo illustrate how to sink data from Kafka to MySQL:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#https://www.jianshu.com/p/266449b9a0f4</span></span><br><span class="line"></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="comment">#Create table in mysql</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> demo_db <span class="built_in">character</span> <span class="keyword">set</span> utf8mb4;</span><br><span class="line"><span class="keyword">use</span> demo_db;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> fludesc (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    use_rname <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    age <span class="built_in">int</span>,</span><br><span class="line">    gender <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    goods_no <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    goods_price <span class="built_in">Float</span>,</span><br><span class="line">    store_id <span class="built_in">int</span>,</span><br><span class="line">    shopping_type <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    tel <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    email <span class="built_in">varchar</span>(<span class="number">32</span>),</span><br><span class="line">    shopping_date <span class="built_in">date</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create in flinksql</span></span><br><span class="line">Flink SQL&gt; create table kafka_source (</span><br><span class="line">    id STRING,</span><br><span class="line">    use_rname STRING,</span><br><span class="line">    age integer,</span><br><span class="line">    gender STRING,</span><br><span class="line">    goods_no STRING,</span><br><span class="line">    goods_price Float,</span><br><span class="line">    store_id integer,</span><br><span class="line">    shopping_type STRING,</span><br><span class="line">    tel STRING,</span><br><span class="line">    email STRING,</span><br><span class="line">    shopping_date Date</span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'testGroup'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'earliest-offset'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'csv'</span>,</span><br><span class="line">    <span class="string">'csv.ignore-parse-errors'</span> = <span class="string">'true'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">Flink SQL&gt; CREATE TABLE mysql_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    use_rname STRING,</span><br><span class="line">    age integer,</span><br><span class="line">    gender STRING,</span><br><span class="line">    goods_no STRING,</span><br><span class="line">    goods_price Float,</span><br><span class="line">    store_id integer,</span><br><span class="line">    shopping_type STRING,</span><br><span class="line">    tel STRING,</span><br><span class="line">    email STRING,</span><br><span class="line">    shopping_date Date</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'jdbc'</span>,</span><br><span class="line">   <span class="string">'url'</span> = <span class="string">'jdbc:mysql://192.168.80.225:3306/demo_db'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'root'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'Aa123#@!'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">Flink SQL&gt; insert into mysql_sink select * from kafka_source;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Mock data from kafka:</span></span><br><span class="line">kafka-console-producer.sh <span class="comment">--broker-list datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092 --topic fludesc</span></span><br><span class="line">&gt;511653962048,Zomfq,53,woman,532120,534.61,313020,cart,15926130785,UyxghCpKMD@huawei.com,2019-08-03</span><br><span class="line">&gt;751653962048,Qvtil,27,man,532120,655.7,313023,cart,13257423096,cJfbNhRYow@163.com,2019-08-05</span><br><span class="line">&gt;121653962048,Spdwh,35,woman,480071,97.35,313018,cart,18825789463,LkVYmpcWXC@qq.com,2019-08-05</span><br><span class="line">&gt;871653962048,Fdhpc,18,man,650012,439.40,313012,cart,15059872140,sfzuPWvNEe@qq.com,2019-08-06</span><br><span class="line">&gt;841653962048,Iqoyh,51,woman,152121,705.6,313012,buy,13646513897,jISbcYdxZO@126.com,2019-08-04</span><br><span class="line">&gt;761653962048,Xgzhy,29,woman,480071,329.60,313013,cart,15069315824,NtTDRlAdeZ@qq.com,2019-08-04</span><br><span class="line"></span><br><span class="line"><span class="comment">#kafka-console-consumer.sh --topic fludesc --bootstrap-server datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092 --from-beginning</span></span><br></pre></td></tr></table></figure>
<h5 id="kafka-to-hdfs-Demo"><a href="#kafka-to-hdfs-Demo" class="headerlink" title="kafka to hdfs Demo"></a>kafka to hdfs Demo</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create in flinksql</span></span><br><span class="line">Flink SQL&gt; create table kafka_source (</span><br><span class="line">    id STRING,</span><br><span class="line">    use_rname STRING,</span><br><span class="line">    age integer,</span><br><span class="line">    gender STRING,</span><br><span class="line">    goods_no STRING,</span><br><span class="line">    goods_price Float,</span><br><span class="line">    store_id integer,</span><br><span class="line">    shopping_type STRING,</span><br><span class="line">    tel STRING,</span><br><span class="line">    email STRING,</span><br><span class="line">    shopping_date Date</span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092,datanode01-test.zerofinance.net:9092'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'testGroup'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'earliest-offset'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'csv'</span>,</span><br><span class="line">    <span class="string">'csv.ignore-parse-errors'</span> = <span class="string">'true'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hadoop_sink (</span><br><span class="line">    <span class="keyword">id</span> <span class="keyword">STRING</span>,</span><br><span class="line">    use_rname <span class="keyword">STRING</span>,</span><br><span class="line">    age <span class="built_in">integer</span>,</span><br><span class="line">    gender <span class="keyword">STRING</span>,</span><br><span class="line">    goods_no <span class="keyword">STRING</span>,</span><br><span class="line">    goods_price <span class="built_in">Float</span>,</span><br><span class="line">    store_id <span class="built_in">integer</span>,</span><br><span class="line">    shopping_type <span class="keyword">STRING</span>,</span><br><span class="line">    tel <span class="keyword">STRING</span>,</span><br><span class="line">    email <span class="keyword">STRING</span>,</span><br><span class="line">    shopping_date <span class="built_in">Date</span></span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (<span class="keyword">id</span>) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'filesystem'</span>,</span><br><span class="line">  <span class="string">'path'</span> = <span class="string">'hdfs:///works/test/hadoop_sink'</span>,</span><br><span class="line">  <span class="string">'format'</span> = <span class="string">'csv'</span>,</span><br><span class="line">  <span class="string">'partition.default-name'</span> = <span class="string">'9999'</span>,</span><br><span class="line">  <span class="string">'sink.shuffle-by-partition.enable'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hadoop_sink <span class="keyword">select</span> * <span class="keyword">from</span> kafka_source;</span><br></pre></td></tr></table></figure>
<h5 id="Mysql-to-hdfs-Demo"><a href="#Mysql-to-hdfs-Demo" class="headerlink" title="Mysql to hdfs Demo"></a>Mysql to hdfs Demo</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create in flinksql</span></span><br><span class="line">Flink SQL&gt; CREATE TABLE mysql_source (</span><br><span class="line">    id STRING,</span><br><span class="line">    use_rname STRING,</span><br><span class="line">    age integer,</span><br><span class="line">    gender STRING,</span><br><span class="line">    goods_no STRING,</span><br><span class="line">    goods_price Float,</span><br><span class="line">    store_id integer,</span><br><span class="line">    shopping_type STRING,</span><br><span class="line">    tel STRING,</span><br><span class="line">    email STRING,</span><br><span class="line">    shopping_date Date</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'jdbc'</span>,</span><br><span class="line">   <span class="string">'url'</span> = <span class="string">'jdbc:mysql://192.168.80.225:3306/demo_db'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'fludesc'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'root'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'Aa123#@!'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hadoop_sink (</span><br><span class="line">    <span class="keyword">id</span> <span class="keyword">STRING</span>,</span><br><span class="line">    use_rname <span class="keyword">STRING</span>,</span><br><span class="line">    age <span class="built_in">integer</span>,</span><br><span class="line">    gender <span class="keyword">STRING</span>,</span><br><span class="line">    goods_no <span class="keyword">STRING</span>,</span><br><span class="line">    goods_price <span class="built_in">Float</span>,</span><br><span class="line">    store_id <span class="built_in">integer</span>,</span><br><span class="line">    shopping_type <span class="keyword">STRING</span>,</span><br><span class="line">    tel <span class="keyword">STRING</span>,</span><br><span class="line">    email <span class="keyword">STRING</span>,</span><br><span class="line">    shopping_date <span class="built_in">Date</span></span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (<span class="keyword">id</span>) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'filesystem'</span>,</span><br><span class="line">  <span class="string">'path'</span> = <span class="string">'hdfs:///works/test/hadoop_sink'</span>,</span><br><span class="line">  <span class="string">'format'</span> = <span class="string">'csv'</span>,</span><br><span class="line">  <span class="string">'partition.default-name'</span> = <span class="string">'9999'</span>,</span><br><span class="line">  <span class="string">'sink.shuffle-by-partition.enable'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hadoop_sink <span class="keyword">select</span> * <span class="keyword">from</span> mysql_source;</span><br></pre></td></tr></table></figure>
<h5 id="Mysql-to-ES-Demo"><a href="#Mysql-to-ES-Demo" class="headerlink" title="Mysql to ES Demo"></a>Mysql to ES Demo</h5><p>ONE TO ONE:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Create in flinksql</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> products (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">STRING</span>,</span><br><span class="line">    description <span class="keyword">STRING</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line">  ) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">    <span class="string">'hostname'</span> = <span class="string">'192.168.63.102'</span>,</span><br><span class="line">    <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">    <span class="string">'username'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">    <span class="string">'password'</span> = <span class="string">'Aa123456'</span>,</span><br><span class="line">    <span class="string">'database-name'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">    <span class="string">'table-name'</span> = <span class="string">'products'</span></span><br><span class="line">  );</span><br><span class="line">  </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders (</span><br><span class="line">   order_id <span class="built_in">INT</span>,</span><br><span class="line">   order_date <span class="built_in">TIMESTAMP</span>(<span class="number">0</span>),</span><br><span class="line">   customer_name <span class="keyword">STRING</span>,</span><br><span class="line">   price <span class="built_in">DECIMAL</span>(<span class="number">10</span>, <span class="number">5</span>),</span><br><span class="line">   product_id <span class="built_in">INT</span>,</span><br><span class="line">   order_status <span class="built_in">BOOLEAN</span>,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (order_id) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line"> ) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">   <span class="string">'hostname'</span> = <span class="string">'192.168.63.102'</span>,</span><br><span class="line">   <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'Aa123456'</span>,</span><br><span class="line">   <span class="string">'database-name'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'orders'</span></span><br><span class="line"> );</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> enriched_orders (</span><br><span class="line">   order_id <span class="built_in">INT</span>,</span><br><span class="line">   order_date <span class="built_in">TIMESTAMP</span>(<span class="number">0</span>),</span><br><span class="line">   customer_name <span class="keyword">STRING</span>,</span><br><span class="line">   price <span class="built_in">DECIMAL</span>(<span class="number">10</span>, <span class="number">5</span>),</span><br><span class="line">   product_id <span class="built_in">INT</span>,</span><br><span class="line">   order_status <span class="built_in">BOOLEAN</span>,</span><br><span class="line">   product_name <span class="keyword">STRING</span>,</span><br><span class="line">   product_description <span class="keyword">STRING</span>,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (order_id) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line"> ) <span class="keyword">WITH</span> (</span><br><span class="line">     <span class="string">'connector'</span> = <span class="string">'elasticsearch-7'</span>,</span><br><span class="line">     <span class="string">'hosts'</span> = <span class="string">'http://192.168.63.102:9200'</span>,</span><br><span class="line">     <span class="string">'index'</span> = <span class="string">'enriched_orders_1'</span></span><br><span class="line"> );</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> enriched_orders</span><br><span class="line"> <span class="keyword">SELECT</span> o.*, p.name, p.description</span><br><span class="line"> <span class="keyword">FROM</span> orders <span class="keyword">AS</span> o</span><br><span class="line"> <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> products <span class="keyword">AS</span> p <span class="keyword">ON</span> o.product_id = p.id;</span><br></pre></td></tr></table></figure>
<p>ONE TO MANY</p>
<p>UDF:</p>
<p>#<a href="https://www.decodable.co/blog/array-aggregation-with-flink-sql-data-streaming" target="_blank" rel="noopener">https://www.decodable.co/blog/array-aggregation-with-flink-sql-data-streaming</a></p>
<p>#<a href="https://github.com/decodableco/examples/blob/main/flink-learn/3-array-agg/src/main/java/co/decodable/demos/arrayagg/ArrayAggr.java" target="_blank" rel="noopener">https://github.com/decodableco/examples/blob/main/flink-learn/3-array-agg/src/main/java/co/decodable/demos/arrayagg/ArrayAggr.java</a></p>
<p>ArrayAccumulator:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zerofinance.function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Objects;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.dataview.ListView;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * https://github.com/decodableco/examples/blob/main/flink-learn/3-array-agg/src/main/java/co/decodable/demos/arrayagg/ArrayAccumulator.java</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayAccumulator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> ListView&lt;T&gt; values = <span class="keyword">new</span> ListView&lt;T&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hash(values);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span> == obj)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (obj == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (getClass() != obj.getClass())</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        ArrayAccumulator&lt;?&gt; other = (ArrayAccumulator&lt;?&gt;) obj;</span><br><span class="line">        <span class="keyword">return</span> Objects.equals(values, other.values);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ArrayAggr:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zerofinance.function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Array;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Optional;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.dataview.ListView;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.catalog.DataTypeFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.functions.AggregateFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.types.DataType;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.types.inference.InputTypeStrategies;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.types.inference.TypeInference;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * https://github.com/decodableco/examples/blob/main/flink-learn/3-array-agg/src/main/java/co/decodable/demos/arrayagg/ArrayAggr.java</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;T&gt;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">public class ArrayAggr &lt;T&gt; extends AggregateFunction&lt;T[], ArrayAccumulator&lt;T&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">6560271654419701770L</span>;</span><br><span class="line">    <span class="keyword">private</span> DataType elementType;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayAccumulator&lt;T&gt; <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ArrayAccumulator&lt;T&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> T[] getValue(ArrayAccumulator&lt;T&gt; acc) &#123;</span><br><span class="line">        <span class="keyword">if</span> (acc.values.getList().isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            List&lt;T&gt; values = <span class="keyword">new</span> ArrayList&lt;T&gt;(acc.values.getList());</span><br><span class="line">            <span class="keyword">return</span> values.toArray((T[]) Array.newInstance(elementType.getConversionClass(), values.size()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accumulate</span><span class="params">(ArrayAccumulator&lt;T&gt; acc, T o)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">            acc.values.add(o);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">retract</span><span class="params">(ArrayAccumulator&lt;T&gt; acc, T o)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">            acc.values.remove(o);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetAccumulator</span><span class="params">(ArrayAccumulator&lt;T&gt; acc)</span> </span>&#123;</span><br><span class="line">        acc.values.clear();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInference <span class="title">getTypeInference</span><span class="params">(DataTypeFactory typeFactory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TypeInference.newBuilder()</span><br><span class="line">                .inputTypeStrategy(InputTypeStrategies.sequence(InputTypeStrategies.ANY))</span><br><span class="line">                .accumulatorTypeStrategy(ctx -&gt; &#123;</span><br><span class="line">                    <span class="keyword">return</span> Optional.of(</span><br><span class="line">                            DataTypes.STRUCTURED(</span><br><span class="line">                                    ArrayAccumulator<span class="class">.<span class="keyword">class</span>,</span></span><br><span class="line">                                    DataTypes.FIELD("values",ListView.newListViewDataType(ctx.getArgumentDataTypes().get(0)))//,</span><br><span class="line">                            ));</span><br><span class="line">                &#125;)</span><br><span class="line">                .outputTypeStrategy(ctx -&gt; &#123;</span><br><span class="line">                    <span class="keyword">this</span>.elementType = ctx.getArgumentDataTypes().get(<span class="number">0</span>);</span><br><span class="line">                    <span class="keyword">return</span> Optional.of(DataTypes.ARRAY(elementType));</span><br><span class="line">                &#125;).build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> ARRAY_AGGR <span class="keyword">AS</span> <span class="string">'com.zerofinance.function.ArrayAggr'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> products (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">STRING</span>,</span><br><span class="line">    description <span class="keyword">STRING</span>,</span><br><span class="line">    PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line">  ) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">    <span class="string">'hostname'</span> = <span class="string">'192.168.63.102'</span>,</span><br><span class="line">    <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">    <span class="string">'username'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">    <span class="string">'password'</span> = <span class="string">'Aa123456'</span>,</span><br><span class="line">    <span class="string">'database-name'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">    <span class="string">'table-name'</span> = <span class="string">'products'</span></span><br><span class="line">  );</span><br><span class="line">  </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders (</span><br><span class="line">   order_id <span class="built_in">INT</span>,</span><br><span class="line">   order_date <span class="built_in">TIMESTAMP</span>(<span class="number">0</span>),</span><br><span class="line">   customer_name <span class="keyword">STRING</span>,</span><br><span class="line">   price <span class="built_in">DECIMAL</span>(<span class="number">10</span>, <span class="number">5</span>),</span><br><span class="line">   product_id <span class="built_in">INT</span>,</span><br><span class="line">   order_status <span class="built_in">BOOLEAN</span>,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (order_id) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line"> ) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'mysql-cdc'</span>,</span><br><span class="line">   <span class="string">'hostname'</span> = <span class="string">'192.168.63.102'</span>,</span><br><span class="line">   <span class="string">'port'</span> = <span class="string">'3306'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'Aa123456'</span>,</span><br><span class="line">   <span class="string">'database-name'</span> = <span class="string">'demo_db'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'orders'</span></span><br><span class="line"> );</span><br><span class="line"> </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> enriched_orders (</span><br><span class="line">   product_id <span class="built_in">INT</span>,</span><br><span class="line">   product_name <span class="keyword">STRING</span>,</span><br><span class="line">   product_description <span class="keyword">STRING</span>,</span><br><span class="line">   <span class="keyword">lines</span> <span class="built_in">ARRAY</span>&lt;<span class="keyword">ROW</span>&lt;order_id <span class="built_in">INT</span>,order_date <span class="built_in">TIMESTAMP</span>(<span class="number">0</span>),customer_name <span class="keyword">STRING</span>,price <span class="built_in">DECIMAL</span>(<span class="number">10</span>, <span class="number">5</span>),order_status <span class="built_in">BOOLEAN</span>&gt;&gt;,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (product_id) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line"> ) <span class="keyword">WITH</span> (</span><br><span class="line">     <span class="string">'connector'</span> = <span class="string">'elasticsearch-7'</span>,</span><br><span class="line">     <span class="string">'hosts'</span> = <span class="string">'http://192.168.63.102:9200'</span>,</span><br><span class="line">     <span class="string">'index'</span> = <span class="string">'enriched_orders_0'</span></span><br><span class="line"> );</span><br><span class="line"> </span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> enriched_orders</span><br><span class="line">  <span class="keyword">SELECT</span> p.id <span class="keyword">AS</span> product_id, p.name <span class="keyword">AS</span> product_name, p.description <span class="keyword">AS</span> product_description,</span><br><span class="line"> (<span class="keyword">select</span> ARRAY_AGGR(<span class="keyword">ROW</span>(order_id,order_date,customer_name,price,order_status)) </span><br><span class="line">   <span class="keyword">from</span> orders o </span><br><span class="line">   <span class="keyword">where</span> o.product_id=p.id) <span class="keyword">as</span> <span class="keyword">lines</span></span><br><span class="line"> <span class="keyword">FROM</span> products <span class="keyword">AS</span> p;</span><br></pre></td></tr></table></figure>
<p>Another way is put sub data to a single string filed:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> enriched_orders (</span><br><span class="line">   product_id <span class="built_in">INT</span>,</span><br><span class="line">   product_name <span class="keyword">STRING</span>,</span><br><span class="line">   product_description <span class="keyword">STRING</span>,</span><br><span class="line">   <span class="keyword">lines</span> <span class="keyword">STRING</span>,</span><br><span class="line">   PRIMARY <span class="keyword">KEY</span> (product_id) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line"> ) <span class="keyword">WITH</span> (</span><br><span class="line">     <span class="string">'connector'</span> = <span class="string">'elasticsearch-7'</span>,</span><br><span class="line">     <span class="string">'hosts'</span> = <span class="string">'http://192.168.63.102:9200'</span>,</span><br><span class="line">     <span class="string">'index'</span> = <span class="string">'enriched_orders_0'</span></span><br><span class="line"> );</span><br><span class="line"> </span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> enriched_orders</span><br><span class="line"> <span class="keyword">SELECT</span> p.id <span class="keyword">AS</span> product_id, p.name <span class="keyword">AS</span> product_name, p.description <span class="keyword">AS</span> product_description,</span><br><span class="line"> (<span class="keyword">select</span> JSON_ARRAYAGG(</span><br><span class="line">  JSON_OBJECT(<span class="string">'order_id'</span> <span class="keyword">VALUE</span> o.order_id,<span class="string">'order_date'</span> <span class="keyword">VALUE</span> o.order_date,<span class="string">'customer_name'</span> <span class="keyword">VALUE</span> o.customer_name,<span class="string">'price'</span> <span class="keyword">VALUE</span> o.price,<span class="string">'order_status'</span> <span class="keyword">VALUE</span> o.order_status)) </span><br><span class="line">   <span class="keyword">from</span> orders o <span class="keyword">where</span> o.product_id=p.id) <span class="keyword">as</span> <span class="keyword">lines</span></span><br><span class="line"> <span class="keyword">FROM</span> products <span class="keyword">AS</span> p;</span><br></pre></td></tr></table></figure>
<h3 id="Window-Aggregation"><a href="#Window-Aggregation" class="headerlink" title="Window Aggregation"></a>Window Aggregation</h3><h4 id="TUMBLE"><a href="#TUMBLE" class="headerlink" title="TUMBLE"></a>TUMBLE</h4><h5 id="Windowing-TVF"><a href="#Windowing-TVF" class="headerlink" title="Windowing TVF"></a>Windowing TVF</h5><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sql/queries/window-tvf/" target="_blank" rel="noopener">Windowing TVF | Apache Flink</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TUMBLE(TABLE data, DESCRIPTOR(timecol), size [, offset ])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>data</code>: is a table parameter that can be any relation with a time attribute column.</li>
<li><code>timecol</code>: is a column descriptor indicating which time attributes column of data should be mapped to tumbling windows.</li>
<li><code>size</code>: is a duration specifying the width of the tumbling windows.</li>
<li><code>offset</code>: is an optional parameter to specify the offset which window start would be shifted by.</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#简单且常见的分维度分钟级别同时在线用户数、总销售额</span></span><br><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="keyword">cast</span>(<span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="built_in">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span><br><span class="line">  <span class="string">'rows-per-second'</span> = <span class="string">'10'</span>,</span><br><span class="line">  <span class="string">'fields.dim.length'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.max'</span> = <span class="string">'100000'</span>,</span><br><span class="line">  <span class="string">'fields.price.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.price.max'</span> = <span class="string">'100000'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    pv <span class="built_in">BIGINT</span>,</span><br><span class="line">    sum_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    max_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    min_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    uv <span class="built_in">BIGINT</span>,</span><br><span class="line">    window_start <span class="built_in">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'print'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    dim,</span><br><span class="line">    <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">CAST</span>(window_start <span class="keyword">AS</span> <span class="keyword">STRING</span>)) * <span class="number">1000</span> <span class="keyword">as</span> window_start,</span><br><span class="line">    <span class="keyword">count</span>(*) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="keyword">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="keyword">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="keyword">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(TUMBLE(</span><br><span class="line">        <span class="keyword">TABLE</span> source_table</span><br><span class="line">        , <span class="keyword">DESCRIPTOR</span>(row_time)</span><br><span class="line">        , <span class="built_in">INTERVAL</span> <span class="string">'60'</span> <span class="keyword">SECOND</span>))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> window_start, </span><br><span class="line">      window_end,</span><br><span class="line">      dim;</span><br></pre></td></tr></table></figure>
<h5 id="Group-Window-Aggregation"><a href="#Group-Window-Aggregation" class="headerlink" title="Group Window Aggregation"></a>Group Window Aggregation</h5><p><strong>Deprecated</strong>: Group Window Aggregation, supported both batch and streaming.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="keyword">cast</span>(<span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="built_in">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span><br><span class="line">  <span class="string">'rows-per-second'</span> = <span class="string">'10'</span>,</span><br><span class="line">  <span class="string">'fields.dim.length'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.max'</span> = <span class="string">'100000'</span>,</span><br><span class="line">  <span class="string">'fields.price.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.price.max'</span> = <span class="string">'100000'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    pv <span class="built_in">BIGINT</span>,</span><br><span class="line">    sum_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    max_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    min_price <span class="built_in">BIGINT</span>,</span><br><span class="line">    uv <span class="built_in">BIGINT</span>,</span><br><span class="line">    window_start <span class="built_in">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'print'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    dim,</span><br><span class="line">    <span class="keyword">count</span>(*) <span class="keyword">as</span> pv,</span><br><span class="line">    <span class="keyword">sum</span>(price) <span class="keyword">as</span> sum_price,</span><br><span class="line">    <span class="keyword">max</span>(price) <span class="keyword">as</span> max_price,</span><br><span class="line">    <span class="keyword">min</span>(price) <span class="keyword">as</span> min_price,</span><br><span class="line">    <span class="comment">-- 计算 uv 数</span></span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv,</span><br><span class="line">    <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">CAST</span>(tumble_start(row_time, <span class="built_in">interval</span> <span class="string">'1'</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> <span class="keyword">STRING</span>)) * <span class="number">1000</span>  <span class="keyword">as</span> window_start</span><br><span class="line"><span class="keyword">from</span> source_table</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    dim,</span><br><span class="line">    tumble(row_time, <span class="built_in">interval</span> <span class="string">'1'</span> <span class="keyword">minute</span>);</span><br></pre></td></tr></table></figure>
<h4 id="HOP"><a href="#HOP" class="headerlink" title="HOP"></a>HOP</h4><h5 id="Windowing-TVF-1"><a href="#Windowing-TVF-1" class="headerlink" title="Windowing TVF"></a>Windowing TVF</h5><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/table/sql/queries/window-tvf/#hop" target="_blank" rel="noopener">Windowing TVF | Apache Flink</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HOP(TABLE data, DESCRIPTOR(timecol), slide, size [, offset ])</span><br></pre></td></tr></table></figure>
<ul>
<li><code>data</code>: is a table parameter that can be any relation with an time attribute column.</li>
<li><code>timecol</code>: is a column descriptor indicating which time attributes column of data should be mapped to hopping windows.</li>
<li><code>slide</code>: is a duration specifying the duration between the start of sequential hopping windows</li>
<li><code>size</code>: is a duration specifying the width of the hopping windows.</li>
<li><code>offset</code>: is an optional parameter to specify the offset which window start would be shifted by.</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#简单且常见的分维度分钟级别同时在线用户数，1 分钟输出一次，计算最近 5 分钟的数据</span></span><br><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="keyword">cast</span>(<span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="built_in">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span><br><span class="line">  <span class="string">'rows-per-second'</span> = <span class="string">'10'</span>,</span><br><span class="line">  <span class="string">'fields.dim.length'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.max'</span> = <span class="string">'100000'</span>,</span><br><span class="line">  <span class="string">'fields.price.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.price.max'</span> = <span class="string">'100000'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    uv <span class="built_in">BIGINT</span>,</span><br><span class="line">    window_start <span class="built_in">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'print'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> dim,</span><br><span class="line">    <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">CAST</span>(hop_start(row_time, <span class="built_in">interval</span> <span class="string">'1'</span> <span class="keyword">minute</span>, <span class="built_in">interval</span> <span class="string">'5'</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> <span class="keyword">STRING</span>)) * <span class="number">1000</span> <span class="keyword">as</span> window_start, </span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> user_id) <span class="keyword">as</span> uv</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> dim</span><br><span class="line">    , hop(row_time, <span class="built_in">interval</span> <span class="string">'1'</span> <span class="keyword">minute</span>, <span class="built_in">interval</span> <span class="string">'5'</span> <span class="keyword">minute</span>);</span><br></pre></td></tr></table></figure>
<h5 id="Group-Window-Aggregation-1"><a href="#Group-Window-Aggregation-1" class="headerlink" title="Group Window Aggregation"></a>Group Window Aggregation</h5><p>Deprecated.</p>
<h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><h5 id="Windowing-TVF-2"><a href="#Windowing-TVF-2" class="headerlink" title="Windowing TVF"></a>Windowing TVF</h5><p>TVF doesn’t support Session mode, using group window aggregation instread.</p>
<h5 id="Group-Window-Aggregation-2"><a href="#Group-Window-Aggregation-2" class="headerlink" title="Group Window Aggregation"></a>Group Window Aggregation</h5><table>
<thead>
<tr>
<th style="text-align:left">Group Window Function</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">SESSION(time_attr, interval)</td>
<td style="text-align:left">Defines a session time window. Session time windows do not have a fixed duration but their bounds are defined by a time <code>interval</code> of inactivity, i.e., a session window is closed if no event appears for a defined gap period. For example a session window with a 30 minute gap starts when a row is observed after 30 minutes inactivity (otherwise the row would be added to an existing window) and is closed if no row is added within 30 minutes. Session windows can work on event-time (stream + batch) or processing-time (stream).</td>
</tr>
</tbody>
</table>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Session 时间窗口和滚动、滑动窗口不一样，其没有固定的持续时间，如果在定义的间隔期（Session Gap）内没有新的数据出现，则 Session 就会窗口关闭</span></span><br><span class="line"><span class="comment">#计算每个用户在活跃期间（一个 Session）总共购买的商品数量，如果用户 5 分钟没有活动则视为 Session 断开</span></span><br><span class="line"><span class="comment">#Group Window Aggregation </span></span><br><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据源表，用户购买行为记录表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 维度数据</span></span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    user_id <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    price <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="keyword">cast</span>(<span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="built_in">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span><br><span class="line">  <span class="string">'rows-per-second'</span> = <span class="string">'10'</span>,</span><br><span class="line">  <span class="string">'fields.dim.length'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.max'</span> = <span class="string">'100000'</span>,</span><br><span class="line">  <span class="string">'fields.price.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.price.max'</span> = <span class="string">'100000'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    dim <span class="keyword">STRING</span>,</span><br><span class="line">    pv <span class="built_in">BIGINT</span>, <span class="comment">-- 购买商品数量</span></span><br><span class="line">    window_start <span class="built_in">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'print'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    dim,</span><br><span class="line">    <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">CAST</span>(session_start(row_time, <span class="built_in">interval</span> <span class="string">'5'</span> <span class="keyword">minute</span>) <span class="keyword">AS</span> <span class="keyword">STRING</span>)) * <span class="number">1000</span> <span class="keyword">as</span> window_start, </span><br><span class="line">    <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">as</span> pv</span><br><span class="line"><span class="keyword">FROM</span> source_table</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> dim</span><br><span class="line">      , <span class="keyword">session</span>(row_time, <span class="built_in">interval</span> <span class="string">'5'</span> <span class="keyword">minute</span>);</span><br><span class="line">      </span><br><span class="line"><span class="comment">#上述 SQL 任务是在整个 Session 窗口结束之后才会把数据输出。Session 窗口即支持 处理时间 也支持 事件时间。但是处理时间只支持在 Streaming 任务中运行，Batch 任务不支持。</span></span><br></pre></td></tr></table></figure>
<h4 id="CUMULATE"><a href="#CUMULATE" class="headerlink" title="CUMULATE"></a>CUMULATE</h4><h5 id="Windowing-TVF-3"><a href="#Windowing-TVF-3" class="headerlink" title="Windowing TVF"></a>Windowing TVF</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUMULATE(TABLE data, DESCRIPTOR(timecol), step, size)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>data</code>: is a table parameter that can be any relation with an time attribute column.</li>
<li><code>timecol</code>: is a column descriptor indicating which time attributes column of data should be mapped to cumulating windows.</li>
<li><code>step</code>: is a duration specifying the increased window size between the end of sequential cumulating windows.</li>
<li><code>size</code>: is a duration specifying the max width of the cumulating windows. <code>size</code> must be an integral multiple of <code>step</code>.</li>
<li><code>offset</code>: is an optional parameter to specify the offset which window start would be shifted by.</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每天的截止当前分钟的累计 money（sum(money)），去重 id 数（count(distinct id)）。每天代表渐进式窗口大小为 1 天，分钟代表渐进式窗口移动步长为分钟级别</span></span><br><span class="line">&gt; sudo su - hadoop</span><br><span class="line">&gt; yarn-session.sh -jm 2048MB -tm 2048MB -nm flink-sql-test -d</span><br><span class="line"></span><br><span class="line">&gt; sql-client.sh embedded -s yarn-session</span><br><span class="line">&gt; SET sql-client.execution.result-mode = tableau;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据源表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> source_table (</span><br><span class="line">    <span class="comment">-- 用户 id</span></span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 用户</span></span><br><span class="line">    money <span class="built_in">BIGINT</span>,</span><br><span class="line">    <span class="comment">-- 事件时间戳</span></span><br><span class="line">    row_time <span class="keyword">AS</span> <span class="keyword">cast</span>(<span class="keyword">CURRENT_TIMESTAMP</span> <span class="keyword">as</span> <span class="built_in">timestamp</span>(<span class="number">3</span>)),</span><br><span class="line">    <span class="comment">-- watermark 设置</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> row_time <span class="keyword">AS</span> row_time - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'datagen'</span>,</span><br><span class="line">  <span class="string">'rows-per-second'</span> = <span class="string">'10'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.user_id.max'</span> = <span class="string">'100000'</span>,</span><br><span class="line">  <span class="string">'fields.price.min'</span> = <span class="string">'1'</span>,</span><br><span class="line">  <span class="string">'fields.price.max'</span> = <span class="string">'100000'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据汇表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> sink_table (</span><br><span class="line">    window_end <span class="built_in">bigint</span>,</span><br><span class="line">    window_start <span class="built_in">bigint</span>,</span><br><span class="line">    sum_money <span class="built_in">BIGINT</span>,</span><br><span class="line">    count_distinct_id <span class="built_in">bigint</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">'connector'</span> = <span class="string">'print'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 数据处理逻辑</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">    <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">CAST</span>(window_end <span class="keyword">AS</span> <span class="keyword">STRING</span>)) * <span class="number">1000</span> <span class="keyword">as</span> window_end, </span><br><span class="line">    window_start, </span><br><span class="line">    <span class="keyword">sum</span>(money) <span class="keyword">as</span> sum_money,</span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">id</span>) <span class="keyword">as</span> count_distinct_id</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">TABLE</span>(CUMULATE(</span><br><span class="line">       <span class="keyword">TABLE</span> source_table</span><br><span class="line">       , <span class="keyword">DESCRIPTOR</span>(row_time)</span><br><span class="line">       , <span class="built_in">INTERVAL</span> <span class="string">'60'</span> <span class="keyword">SECOND</span></span><br><span class="line">       , <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">DAY</span>))</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">    window_start, </span><br><span class="line">    window_end;</span><br><span class="line">    </span><br><span class="line"><span class="comment">#You will get wrong with: </span></span><br><span class="line">[ERROR] Could not <span class="keyword">execute</span> <span class="keyword">SQL</span> statement. Reason:</span><br><span class="line">org.apache.flink.table.api.ValidationException: Unsupported options <span class="keyword">found</span> <span class="keyword">for</span> <span class="string">'datagen'</span>.</span><br></pre></td></tr></table></figure>
<h5 id="Group-Window-Aggregation-3"><a href="#Group-Window-Aggregation-3" class="headerlink" title="Group Window Aggregation"></a>Group Window Aggregation</h5><p>Deprecated.</p>
<h3 id="Troubleshooting-1"><a href="#Troubleshooting-1" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><p>#<a href="https://www.cnblogs.com/yeyuzhuanjia/p/17942445" target="_blank" rel="noopener">https://www.cnblogs.com/yeyuzhuanjia/p/17942445</a></p>
<p>Web UI cannot be visited by external:</p>
<p>vim conf/flink-conf.yaml:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rest.address: 0.0.0.0</span><br><span class="line">rest.bind-address: 0.0.0.0</span><br></pre></td></tr></table></figure>
<h3 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High-Availability"></a>High-Availability</h3><p>Recommend working on Yarn</p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/resource-providers/yarn/#high-availability-on-yarn" target="_blank" rel="noopener">High-Availability on YARN</a></p>
<p>High-Availability on YARN is achieved through a combination of YARN and a <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/overview/" target="_blank" rel="noopener">high availability service</a>.</p>
<p>Once a HA service is configured, it will persist JobManager metadata and perform leader elections.</p>
<p>YARN is taking care of restarting failed JobManagers. The maximum number of JobManager restarts is defined through two configuration parameters. First Flink’s <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/config/#yarn-application-attempts" target="_blank" rel="noopener">yarn.application-attempts</a> configuration will default 2. This value is limited by YARN’s <a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml" target="_blank" rel="noopener">yarn.resourcemanager.am.max-attempts</a>, which also defaults to 2.</p>
<p>Note that Flink is managing the <code>high-availability.cluster-id</code> configuration parameter when deploying on YARN. Flink sets it per default to the YARN application id. <strong>You should not overwrite this parameter when deploying an HA cluster on YARN</strong>. The cluster ID is used to distinguish multiple HA clusters in the HA backend (for example Zookeeper). Overwriting this configuration parameter can lead to multiple YARN clusters affecting each other.</p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/ha/zookeeper_ha/" target="_blank" rel="noopener">ZooKeeper HA Services</a></p>
<p>Configure high availability mode and ZooKeeper quorum in <code>conf/flink-conf.yaml</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">high-availability: zookeeper</span><br><span class="line">high-availability.zookeeper.quorum: datanode03-test.zerofinance.net:2181,datanode01-test.zerofinance.net:2181,datanode02-test.zerofinance.net:2181</span><br><span class="line">high-availability.zookeeper.path.root: /flink</span><br><span class="line">high-availability.storageDir: hdfs:///flink/ha/</span><br></pre></td></tr></table></figure>
<h3 id="Histroy-Server"><a href="#Histroy-Server" class="headerlink" title="Histroy Server"></a>Histroy Server</h3><p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/advanced/historyserver/" target="_blank" rel="noopener">History Server | Apache Flink</a></p>
<p>Flink has a history server that can be used to query the statistics of completed jobs after the corresponding Flink cluster has been shut down.</p>
<p>By default, this server binds to <code>localhost</code> and listens at port <code>8082</code>.</p>
<h3 id="Troubleshooting-2"><a href="#Troubleshooting-2" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h3><p>#<a href="https://www.jianshu.com/p/877868b6f829" target="_blank" rel="noopener">https://www.jianshu.com/p/877868b6f829</a></p>
<p>NoResourceAvailableException: Could not acquire the minimum required resources</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">taskmanager.memory.process.size: 6048m</span><br><span class="line">jobmanager.memory.process.size: 6048m</span><br></pre></td></tr></table></figure>
<h2 id="Seatunnel"><a href="#Seatunnel" class="headerlink" title="Seatunnel"></a>Seatunnel</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/profile.d/hadoop.sh    </span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/bigtop/current/hadoop-client</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/bigtop/current/hadoop-client/etc/hadoop/</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/bigtop/current/spark-client</span><br><span class="line"><span class="built_in">export</span> PYTHON_HOME=/usr</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/bigtop/current/hive-client</span><br><span class="line"><span class="built_in">export</span> FLINK_HOME=/usr/bigtop/current/flink-client</span><br><span class="line"><span class="built_in">export</span> SEATUNNEL_HOME=/works/app/apache-seatunnel-2.3.3</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/bigtop/current/zookeeper-client</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$FLINK_HOME</span>/bin:<span class="variable">$SEATUNNEL_HOME</span>/bin:<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Bigdata/" rel="tag"># Bigdata</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/08/Linux-Shell-Script.html" rel="next" title="Linux Shell Script">
                <i class="fa fa-chevron-left"></i> Linux Shell Script
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2023/09/CD.html" rel="prev" title="CD">
                CD <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MTc1MS8xODI5Nw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">zhaoxunyong</p>
              <p class="site-description motion-element" itemprop="description">平时工作中所遇到的一些问题的总结</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://subblogzhaoxunyongm70.lofter.com/" title="lofter" target="_blank">lofter</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bigtop"><span class="nav-number">2.</span> <span class="nav-text">Bigtop</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#build-package-from-source"><span class="nav-number">2.1.</span> <span class="nav-text">build package from source</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bigtop-Repositories"><span class="nav-number">2.2.</span> <span class="nav-text">bigtop Repositories</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ambari"><span class="nav-number">3.</span> <span class="nav-text">Ambari</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Build-package-from-source"><span class="nav-number">3.1.</span> <span class="nav-text">Build  package from source</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Installing-Ambari"><span class="nav-number">3.2.</span> <span class="nav-text">Installing Ambari</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Vagrant-Docker"><span class="nav-number">3.2.1.</span> <span class="nav-text">Vagrant Docker</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Dockerfile-centos"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">Dockerfile.centos</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#docker-entrypoint-sh"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">docker-entrypoint.sh</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#script-sh"><span class="nav-number">3.2.1.3.</span> <span class="nav-text">script.sh</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#buildImages-sh"><span class="nav-number">3.2.1.4.</span> <span class="nav-text">buildImages.sh</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Push-image"><span class="nav-number">3.2.1.5.</span> <span class="nav-text">Push image</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Vagrantfile"><span class="nav-number">3.2.1.6.</span> <span class="nav-text">Vagrantfile</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Vagrant-start"><span class="nav-number">3.2.1.7.</span> <span class="nav-text">Vagrant start</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Initiation"><span class="nav-number">3.2.2.</span> <span class="nav-text">Initiation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#SSH-Without-Password"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">SSH Without Password</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Optional-Docker-CentOS"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">Optional: Docker CentOS</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NTP"><span class="nav-number">3.2.2.3.</span> <span class="nav-text">NTP</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Environment-variables"><span class="nav-number">3.2.2.4.</span> <span class="nav-text">Environment variables</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Installation"><span class="nav-number">3.2.2.5.</span> <span class="nav-text">Installation</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#MySQL"><span class="nav-number">3.2.2.5.1.</span> <span class="nav-text">MySQL</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Ambari-Server"><span class="nav-number">3.2.2.5.2.</span> <span class="nav-text">Ambari Server</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Ambari-Agent"><span class="nav-number">3.2.2.5.3.</span> <span class="nav-text">Ambari Agent</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#bigtop-repo"><span class="nav-number">3.2.2.5.4.</span> <span class="nav-text">bigtop repo</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Install-Hadoop-Ecosystem"><span class="nav-number">3.2.2.5.5.</span> <span class="nav-text">Install Hadoop Ecosystem</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Troubleshooting"><span class="nav-number">3.2.2.5.6.</span> <span class="nav-text">Troubleshooting</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dolphinscheduler"><span class="nav-number">4.</span> <span class="nav-text">dolphinscheduler</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop"><span class="nav-number">5.</span> <span class="nav-text">Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Windows-Client"><span class="nav-number">5.1.</span> <span class="nav-text">Windows Client</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Configuation"><span class="nav-number">5.2.</span> <span class="nav-text">Configuation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#core-site-xml"><span class="nav-number">5.2.1.</span> <span class="nav-text">core-site.xml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#hdfs-site-xml"><span class="nav-number">5.2.2.</span> <span class="nav-text">hdfs-site.xml</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive"><span class="nav-number">6.</span> <span class="nav-text">Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#internal-table"><span class="nav-number">6.1.</span> <span class="nav-text">internal table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#external-table"><span class="nav-number">6.2.</span> <span class="nav-text">external table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Partition"><span class="nav-number">6.3.</span> <span class="nav-text">Partition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Insert-Directory"><span class="nav-number">6.4.</span> <span class="nav-text">Insert Directory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Insert-Table"><span class="nav-number">6.5.</span> <span class="nav-text">Insert Table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Date-Type"><span class="nav-number">6.6.</span> <span class="nav-text">Date Type</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#STRUCT"><span class="nav-number">6.6.1.</span> <span class="nav-text">STRUCT</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ARRAY"><span class="nav-number">6.6.2.</span> <span class="nav-text">ARRAY</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MAP"><span class="nav-number">6.6.3.</span> <span class="nav-text">MAP</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ES"><span class="nav-number">7.</span> <span class="nav-text">ES</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink"><span class="nav-number">8.</span> <span class="nav-text">Flink</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-SQL"><span class="nav-number">8.1.</span> <span class="nav-text">Flink SQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deployment-Modes"><span class="nav-number">8.2.</span> <span class="nav-text">Deployment Modes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Standalone"><span class="nav-number">8.2.1.</span> <span class="nav-text">Standalone</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Session-Mode"><span class="nav-number">8.2.1.1.</span> <span class="nav-text">Session Mode</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Application-Mode"><span class="nav-number">8.2.1.2.</span> <span class="nav-text">Application Mode</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#YARN"><span class="nav-number">8.2.2.</span> <span class="nav-text">YARN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Session-Mode-1"><span class="nav-number">8.2.2.1.</span> <span class="nav-text">Session Mode</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Application-Mode-1"><span class="nav-number">8.2.2.2.</span> <span class="nav-text">Application Mode</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Native-kubernetes"><span class="nav-number">8.2.3.</span> <span class="nav-text">Native_kubernetes</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#K8s-On-Session"><span class="nav-number">8.2.3.1.</span> <span class="nav-text">K8s On Session</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K8s-On-Application"><span class="nav-number">8.2.3.2.</span> <span class="nav-text">K8s On Application</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sql-Client"><span class="nav-number">8.2.4.</span> <span class="nav-text">Sql Client</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Standalone-1"><span class="nav-number">8.2.4.1.</span> <span class="nav-text">Standalone</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#On-yarn-Session"><span class="nav-number">8.2.4.2.</span> <span class="nav-text">On yarn Session</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Connectors"><span class="nav-number">8.2.4.3.</span> <span class="nav-text">Connectors</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Restore-job"><span class="nav-number">8.2.4.4.</span> <span class="nav-text">Restore job</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Optimize"><span class="nav-number">8.2.4.5.</span> <span class="nav-text">Optimize</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#StreamPark"><span class="nav-number">8.3.</span> <span class="nav-text">StreamPark</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Installation-1"><span class="nav-number">8.3.1.</span> <span class="nav-text">Installation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Standalone-2"><span class="nav-number">8.3.1.1.</span> <span class="nav-text">Standalone</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Docker"><span class="nav-number">8.3.1.2.</span> <span class="nav-text">Docker</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K8s"><span class="nav-number">8.3.1.3.</span> <span class="nav-text">K8s</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Configuration"><span class="nav-number">8.3.2.</span> <span class="nav-text">Configuration</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#System-Setting"><span class="nav-number">8.3.2.1.</span> <span class="nav-text">System Setting</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Flink-Cluster"><span class="nav-number">8.3.2.2.</span> <span class="nav-text">Flink Cluster</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Flink-Home"><span class="nav-number">8.3.2.3.</span> <span class="nav-text">Flink Home</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Application"><span class="nav-number">8.3.3.</span> <span class="nav-text">Application</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#application-sql-Job"><span class="nav-number">8.3.3.1.</span> <span class="nav-text">application sql Job</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#session-sql-job"><span class="nav-number">8.3.3.2.</span> <span class="nav-text">session sql job</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#application-jar-job"><span class="nav-number">8.3.3.3.</span> <span class="nav-text">application jar job</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pod-template"><span class="nav-number">8.3.4.</span> <span class="nav-text">Pod template</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Pod-Template"><span class="nav-number">8.3.4.1.</span> <span class="nav-text">Pod Template</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Dynamic-Properties"><span class="nav-number">8.3.4.2.</span> <span class="nav-text">Dynamic Properties</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Clean-all-Jobs"><span class="nav-number">8.3.4.3.</span> <span class="nav-text">Clean all Jobs</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#UDF"><span class="nav-number">8.3.5.</span> <span class="nav-text">UDF</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dinky"><span class="nav-number">8.4.</span> <span class="nav-text">Dinky</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linux-Install"><span class="nav-number">8.4.1.</span> <span class="nav-text">Linux Install</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Docker-1"><span class="nav-number">8.4.2.</span> <span class="nav-text">Docker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#On-Application"><span class="nav-number">8.4.3.</span> <span class="nav-text">On Application</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DataSource"><span class="nav-number">8.4.4.</span> <span class="nav-text">DataSource</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#User-defined-Functions"><span class="nav-number">8.5.</span> <span class="nav-text">User-defined Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Catalog"><span class="nav-number">8.6.</span> <span class="nav-text">Hive Catalog</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-Streaming-Platform-Web"><span class="nav-number">8.7.</span> <span class="nav-text">Flink Streaming Platform Web</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Settings"><span class="nav-number">8.7.1.</span> <span class="nav-text">Settings</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job"><span class="nav-number">8.7.2.</span> <span class="nav-text">Job</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-SQL-CDC"><span class="nav-number">8.8.</span> <span class="nav-text">Flink SQL CDC</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Demo"><span class="nav-number">8.8.1.</span> <span class="nav-text">Demo</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#kafka-to-mysql-Demo"><span class="nav-number">8.8.1.1.</span> <span class="nav-text">kafka to mysql  Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#kafka-to-hdfs-Demo"><span class="nav-number">8.8.1.2.</span> <span class="nav-text">kafka to hdfs Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Mysql-to-hdfs-Demo"><span class="nav-number">8.8.1.3.</span> <span class="nav-text">Mysql to hdfs Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Mysql-to-ES-Demo"><span class="nav-number">8.8.1.4.</span> <span class="nav-text">Mysql to ES Demo</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Window-Aggregation"><span class="nav-number">8.9.</span> <span class="nav-text">Window Aggregation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#TUMBLE"><span class="nav-number">8.9.1.</span> <span class="nav-text">TUMBLE</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Windowing-TVF"><span class="nav-number">8.9.1.1.</span> <span class="nav-text">Windowing TVF</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Group-Window-Aggregation"><span class="nav-number">8.9.1.2.</span> <span class="nav-text">Group Window Aggregation</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HOP"><span class="nav-number">8.9.2.</span> <span class="nav-text">HOP</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Windowing-TVF-1"><span class="nav-number">8.9.2.1.</span> <span class="nav-text">Windowing TVF</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Group-Window-Aggregation-1"><span class="nav-number">8.9.2.2.</span> <span class="nav-text">Group Window Aggregation</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Session"><span class="nav-number">8.9.3.</span> <span class="nav-text">Session</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Windowing-TVF-2"><span class="nav-number">8.9.3.1.</span> <span class="nav-text">Windowing TVF</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Group-Window-Aggregation-2"><span class="nav-number">8.9.3.2.</span> <span class="nav-text">Group Window Aggregation</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CUMULATE"><span class="nav-number">8.9.4.</span> <span class="nav-text">CUMULATE</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Windowing-TVF-3"><span class="nav-number">8.9.4.1.</span> <span class="nav-text">Windowing TVF</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Group-Window-Aggregation-3"><span class="nav-number">8.9.4.2.</span> <span class="nav-text">Group Window Aggregation</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Troubleshooting-1"><span class="nav-number">8.10.</span> <span class="nav-text">Troubleshooting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#High-Availability"><span class="nav-number">8.11.</span> <span class="nav-text">High-Availability</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Histroy-Server"><span class="nav-number">8.12.</span> <span class="nav-text">Histroy Server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Troubleshooting-2"><span class="nav-number">8.13.</span> <span class="nav-text">Troubleshooting</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Seatunnel"><span class="nav-number">9.</span> <span class="nav-text">Seatunnel</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhaoxunyong</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("jozwrL8uJ20tiwfpIlilQEvx-gzGzoHsz", "DrpiYQlTyseBEjF9Ujr0SVKk");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
